#!/bin/bash
export VISIT_VERSION=${VISIT_VERSION:-"3.4.2"}
export TRUNK_BUILD="yes"
export RC_BUILD="no"
export TAGGED_BUILD="no"
export INITIAL_PWD=$PWD
export bv_PATH=src/tools/dev/scripts
export bv_PREFIX=$bv_PATH/bv_support/
export build_version=""
export visitroot="https://github.com/visit-dav/visit/releases/download/"
export thirdpartyroot="https://github.com/visit-dav/third-party/releases/download/"
export thirdpartyroot_dev="https://github.com/visit-dav/third-party/raw/master/lib"
declare -a reqlibs
declare -a optlibs
declare -a explicitlibs
declare -a grouplibs_name
declare -a grouplibs_deps
declare -a grouplibs_comment
declare -a grouplibs_enabled
declare -a defaultLicenses
declare -a args
quick_check_for_help () 
{ 
    for arg in "$@";
    do
        if [[ "$arg" == "-h" || "$arg" == "--help" ]]; then
            echo 0;
            return;
        fi;
    done;
    echo 1
}
check_for_versioning () 
{ 
    local next_arg="no";
    for arg in "$@";
    do
        if [[ "$next_arg" == "build-version" ]]; then
            build_version="$arg";
            next_arg="no";
        else
            if [[ "$arg" == "--build-version" ]]; then
                next_arg="build-version";
            else
                args[${#args[*]}]="$arg";
            fi;
        fi;
    done;
    if [[ "$build_version" != "" ]]; then
        VISIT_VERSION="$build_version";
        webaddr="${webroot}/tags/$VISIT_VERSION/src/tools/dev/scripts/build_visit";
        echo "using $webaddr for source";
    fi
}
call_build_visit () 
{ 
    if [[ "${build_version}" == "" ]]; then
        return;
    fi;
    build_visit_ver="build_visit${build_version}";
    if [[ -e "$build_visit_ver" ]]; then
        echo "Found $build_visit_ver";
        exec bash $build_visit_ver "${args[@]}";
    fi;
    for choice in `echo "curl wget"`;
    do
        echo "Trying to fetch $build_visit_ver using: $choice";
        tmp_choice=`which $choice`;
        if [ $? != 0 ]; then
            continue;
        fi;
        if [[ $choice == "curl" ]]; then
            curl -s ${webaddr} -o $build_visit_ver;
            if [ $? != 0 ]; then
                continue;
            fi;
        else
            if [[ $choice == "wget" ]]; then
                wget -q ${webaddr} -O $build_visit_ver;
                if [ $? != 0 ]; then
                    continue;
                fi;
            fi;
        fi;
        if [[ -e "$build_visit_ver" ]]; then
            echo "Success using $choice";
            break;
        fi;
    done;
    if [[ -e "$build_visit_ver" ]]; then
        if [[ -d bv_support ]]; then
            echo "Removing previous support directory...";
            rm -fR bv_support;
        fi;
        bv_PREFIX=$PWD/bv_support;
        webaddr="$webroot/tags/$build_version/src/tools/dev/scripts/bv_support/";
        echo "rerouting support from $webaddr";
        configure_support_files;
        declare -f download_file >> bv_support/helper_funcs.sh;
        echo "Executing $build_visit_ver";
        exec bash $build_visit_ver "${args[@]}";
    else
        echo "Failed to execute another version of VisIt";
        exit 2;
    fi
}
configure_support_files () 
{ 
    if [ ! -d $bv_PREFIX ]; then
        bv_PREFIX=$PWD/bv_support/;
        if [ ! -d $bv_PREFIX ]; then
            for choice in `echo "curl wget svn"`;
            do
                echo "Trying to fetch support files using: $choice";
                tmp_choice=`which $choice`;
                if [ $? != 0 ]; then
                    continue;
                fi;
                if [[ $choice == "curl" ]]; then
                    tmp_curl=`curl -s ${webaddr}/ | grep 'sh\|xml' | grep li|sed s/.*bv_/bv_/g | sed -e s/\.sh.*/\.sh/g | sed -e s/.*href\=\"//g | sed -e s/\".*//g;`;
                    if [ $? != 0 ]; then
                        continue;
                    fi;
                    mkdir -p bv_support_tmp;
                    is_successful=1;
                    for curl_files in `echo $tmp_curl`;
                    do
                        curl -s ${webaddr}/${curl_files} -o bv_support_tmp/$curl_files;
                        if [ $? != 0 ]; then
                            echo "failed to download ${curl_files}";
                            is_successful=0;
                            break;
                        fi;
                    done;
                    if [ $is_successful == 0 ]; then
                        rm -fR bv_support_tmp;
                    else
                        mv bv_support_tmp bv_support;
                    fi;
                else
                    if [[ $choice == "wget" ]]; then
                        wget -r -nH --cut-dirs=6 --no-parent --reject="index.html,robots.txt" -q ${webaddr};
                    else
                        svn -q co ${webaddr} bv_support;
                    fi;
                fi;
                if [ ! -d $bv_PREFIX ]; then
                    echo "$choice failed to retrieve support files";
                else
                    echo "Success. downloaded support, continuing";
                    break;
                fi;
            done;
        fi;
        if [ ! -d $bv_PREFIX ]; then
            echo "Failed to detect or fetch support files. Quitting...";
            exit 2;
        fi;
    fi
}
# --------------------------------------------------------------------------- #
#   checking compiler minimum version                                         #
# --------------------------------------------------------------------------- #
function vercomp ()
{
    if [[ $1 == $2 ]]
    then
        return 0
    fi
    local IFS=.
    local i ver1=($1) ver2=($2)
    # fill empty fields in ver1 with zeros
    for ((i=${#ver1[@]}; i<${#ver2[@]}; i++))
    do
        ver1[i]=0
    done
    for ((i=0; i<${#ver1[@]}; i++))
    do
        if [[ -z ${ver2[i]} ]]
        then
            # fill empty fields in ver2 with zeros
            ver2[i]=0
        fi
        if [[ 10#${ver1[i]} -gt 10#${ver2[i]} ]]
        then
            return 1
        fi
        if [[ 10#${ver1[i]} -lt 10#${ver2[i]} ]]
        then
            return 2
        fi
    done
    return 0
}

function testvercomp ()
{
    vercomp $1 $2
    case $? in
        0) op='=';;
        1) op='>';;
        2) op='<';;
    esac
    if [[ $op != $3 ]]
    then
        return 1
    else
        return 0
    fi
}

#
# Way to get version digits from compiler output which is much less
# sensitive to variations in how compiler vendors choose to output
# this information...
#   1. The $(...) runs all the intervening commands in a subshell.
#   2. The $1 -v runs the compiler with -v command-line option which
#      should print version information (along with potentially a
#      lot of other stuff).
#   3. The 2>&1 sends stderr to the same pipe as stdout so that all
#      output produced is seen by the rest of the commands.
#   4. The grep -i version matches only lines that have the word 
#      'version' (case-insensitive) in them so only lines with that
#      word in them go on to the next step. So far, all compilers
#      we've seen include that word in the line that includes the
#      version number itself.
#   5. The tr ' -' '\n\n' does a mapping of all spaces and dashes
#      to newlines. This has the effect of putting every word of
#      output (from the line(s) that had the word version in them
#      from the preceding step) on its own line.
#   6. The grep '\.' matches non-blank lines so only non-blank lines
#      get passed onto the next step.
#   7. The grep '^[0-9\.]\{5,\}$' matches a line that BEGINs (^) with
#      any digit and has at least 5 matches for only digits and dots in
#      it before the line ENDs ($) (e.g. 4.7.5 or 13.2.12).
#   If all of the above produces an empty string, try it all again looking
#   for at least 3 digits and dots (e.g. 4.7)
#
function get_version_digits()
{
    retval=$($1 -v 2>&1 | grep -i version | tr ' -' '\n\n' | grep '\.' | grep '^[0-9\.]\{5,\}$')
    if [[ -z "$retval" ]] ; then
        retval=$($1 -v 2>&1 | grep -i version | tr ' -' '\n\n' | grep '\.' | grep '^[0-9\.]\{3,\}$')
    fi
    echo $retval
}

function check_minimum_compiler_version()
{
   if [[ "$CXX_COMPILER" == "g++" ]] ; then
        VERSION=$(get_version_digits g++)
        echo "g++ version $VERSION"
        gccv=8.1
        testvercomp $VERSION $gccv '<'
        if [[ $? == 0 ]] ; then
            echo "Need g++ version >= $gccv"
            exit 1
        fi
    elif [[ "$OPSYS" == "Darwin"  &&  "$CXX_COMPILER" == "clang++" ]] ; then 
        VERSION=$(get_version_digits clang++)
        echo "apple clang version $VERSION"
        testvercomp $VERSION 5.0 '<'
        if [[ $? == 0 ]] ; then
            echo "Need clang++ version >= 5.0"
            exit 1
        fi
    elif [[ "$CXX_COMPILER" == "clang++" ]] ; then 
        VERSION=$(get_version_digits clang++)
        echo "clang version $VERSION"
        testvercomp $VERSION 3.3 '<'
        if [[ $? == 0 ]] ; then
            echo "Need clang++ version >= 3.3"
            exit 1
        fi
    elif [[ "$CXX_COMPILER" == "icpc" ]] ; then 
        VERSION=$(get_version_digits icpc)
        if [[ $VERSION == "" ]] ; then
            VERSION=$(icpc -v 2>&1 | grep "icpc.orig version" | cut -d' ' -f3 )
        fi
        echo "icpc version $VERSION"
        testvercomp $VERSION 14.0 '<'
        if [[ $? == 0 ]] ; then
            echo "Need icpc version >= 14.0"
            exit 1
        fi
    fi
}

# --------------------------------------------------------------------------- #
#   checking opengl context creation (minimum required is 3.2)
#
#   Modifications:
#     Kathleen Biagas, Fri Jul 11, 2025
#     First try to compile with libOpenGL, fallback to libGL.
#
# --------------------------------------------------------------------------- #

function check_opengl_context()
{
    # Check if we can create a 3.2 context with system gl
    echo "#include <GL/gl.h>" >> checkogl.cpp
    echo "#include <GL/glx.h>" >> checkogl.cpp
    echo "#include <cstring>" >> checkogl.cpp
    echo "#include <cstdlib>" >> checkogl.cpp
    echo "#define GLX_CONTEXT_MAJOR_VERSION_ARB       0x2091" >> checkogl.cpp
    echo "#define GLX_CONTEXT_MINOR_VERSION_ARB       0x2092" >> checkogl.cpp
    echo "typedef GLXContext (*glXCreateContextAttribsARBProc)(Display*, GLXFBConfig, GLXContext, Bool, const int*);" >> checkogl.cpp
    echo "static bool isExtensionSupported(const char *extList, const char *extension) {" >> checkogl.cpp
    echo "  const char *start;" >> checkogl.cpp
    echo "  const char *where, *terminator;" >> checkogl.cpp
    echo "  where = strchr(extension, ' ');" >> checkogl.cpp
    echo "  if (where || *extension == '\0')" >> checkogl.cpp
    echo "    return false;" >> checkogl.cpp
    echo "  for (start=extList;;) {" >> checkogl.cpp
    echo "    where = strstr(start, extension);" >> checkogl.cpp
    echo "    if (!where)" >> checkogl.cpp
    echo "      break;" >> checkogl.cpp
    echo "    terminator = where + strlen(extension);" >> checkogl.cpp
    echo "    if ( where == start || *(where - 1) == ' ' )" >> checkogl.cpp
    echo "      if ( *terminator == ' ' || *terminator == '\0' )" >> checkogl.cpp
    echo "        return true;" >> checkogl.cpp
    echo "    start = terminator;" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  return false;" >> checkogl.cpp
    echo "}" >> checkogl.cpp
    echo "static bool ctxErrorOccurred = false;" >> checkogl.cpp
    echo "static int ctxErrorHandler( Display *dpy, XErrorEvent *ev )" >> checkogl.cpp
    echo "{" >> checkogl.cpp
    echo "    ctxErrorOccurred = true;" >> checkogl.cpp
    echo "    return 0;" >> checkogl.cpp
    echo "}" >> checkogl.cpp
    echo "int main(int argc, char* argv[])" >> checkogl.cpp
    echo "{" >> checkogl.cpp
    echo "  Display *display = XOpenDisplay(NULL);" >> checkogl.cpp
    echo "  if (!display)" >> checkogl.cpp
    echo " {" >> checkogl.cpp
    echo "    exit(1);" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  static int visual_attribs[] =" >> checkogl.cpp
    echo "    {" >> checkogl.cpp
    echo "      GLX_X_RENDERABLE    , True," >> checkogl.cpp
    echo "      GLX_DRAWABLE_TYPE   , GLX_WINDOW_BIT," >> checkogl.cpp
    echo "      GLX_RENDER_TYPE     , GLX_RGBA_BIT," >> checkogl.cpp
    echo "      GLX_X_VISUAL_TYPE   , GLX_TRUE_COLOR," >> checkogl.cpp
    echo "      GLX_RED_SIZE        , 8," >> checkogl.cpp
    echo "      GLX_GREEN_SIZE      , 8," >> checkogl.cpp
    echo "      GLX_BLUE_SIZE       , 8," >> checkogl.cpp
    echo "      GLX_ALPHA_SIZE      , 8," >> checkogl.cpp
    echo "      GLX_DEPTH_SIZE      , 24," >> checkogl.cpp
    echo "      GLX_STENCIL_SIZE    , 8," >> checkogl.cpp
    echo "      GLX_DOUBLEBUFFER    , True," >> checkogl.cpp
    echo "      //GLX_SAMPLE_BUFFERS  , 1," >> checkogl.cpp
    echo "      //GLX_SAMPLES         , 4," >> checkogl.cpp
    echo "      None" >> checkogl.cpp
    echo "    };" >> checkogl.cpp
    echo "  int glx_major, glx_minor;" >> checkogl.cpp
    echo "  if ( !glXQueryVersion( display, &glx_major, &glx_minor ) || ( ( glx_major == 1 ) && ( glx_minor < 3 ) ) || ( glx_major < 1 ) )" >> checkogl.cpp
    echo "  {" >> checkogl.cpp
    echo "    exit(1);" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  int fbcount;" >> checkogl.cpp
    echo "  GLXFBConfig* fbc = glXChooseFBConfig(display, DefaultScreen(display), visual_attribs, &fbcount);" >> checkogl.cpp
    echo "  if (!fbc)" >> checkogl.cpp
    echo "  {" >> checkogl.cpp
    echo "    exit(1);" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  int best_fbc = -1, worst_fbc = -1, best_num_samp = -1, worst_num_samp = 999;" >> checkogl.cpp
    echo "  int i;" >> checkogl.cpp
    echo "  for (i=0; i<fbcount; ++i)" >> checkogl.cpp
    echo "  {" >> checkogl.cpp
    echo "    XVisualInfo *vi = glXGetVisualFromFBConfig( display, fbc[i] );" >> checkogl.cpp
    echo "    if ( vi )" >> checkogl.cpp
    echo "    {" >> checkogl.cpp
    echo "      int samp_buf, samples;" >> checkogl.cpp
    echo "      glXGetFBConfigAttrib( display, fbc[i], GLX_SAMPLE_BUFFERS, &samp_buf );" >> checkogl.cpp
    echo "      glXGetFBConfigAttrib( display, fbc[i], GLX_SAMPLES       , &samples  );" >> checkogl.cpp
    echo "      if ( best_fbc < 0 || samp_buf && samples > best_num_samp )" >> checkogl.cpp
    echo "        best_fbc = i, best_num_samp = samples;" >> checkogl.cpp
    echo "      if ( worst_fbc < 0 || !samp_buf || samples < worst_num_samp )" >> checkogl.cpp
    echo "        worst_fbc = i, worst_num_samp = samples;" >> checkogl.cpp
    echo "    }" >> checkogl.cpp
    echo "    XFree( vi );" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  GLXFBConfig bestFbc = fbc[ best_fbc ];" >> checkogl.cpp
    echo "  XFree( fbc );" >> checkogl.cpp
    echo "  XVisualInfo *vi = glXGetVisualFromFBConfig( display, bestFbc );" >> checkogl.cpp
    echo "  XSetWindowAttributes swa;" >> checkogl.cpp
    echo "  Colormap cmap;" >> checkogl.cpp
    echo "  swa.colormap = cmap = XCreateColormap( display, RootWindow( display, vi->screen ), vi->visual, AllocNone );" >> checkogl.cpp
    echo "  swa.background_pixmap = None ;" >> checkogl.cpp
    echo "  swa.border_pixel      = 0;" >> checkogl.cpp
    echo "  swa.event_mask        = StructureNotifyMask;" >> checkogl.cpp
    echo "  Window win = XCreateWindow( display, RootWindow( display, vi->screen ), 0, 0, 100, 100, 0, vi->depth, InputOutput, vi->visual, CWBorderPixel|CWColormap|CWEventMask, &swa );" >> checkogl.cpp
    echo "  if ( !win )" >> checkogl.cpp
    echo "  {" >> checkogl.cpp
    echo "    exit(1);" >> checkogl.cpp
    echo " }" >> checkogl.cpp
    echo "  XFree( vi );" >> checkogl.cpp
    echo "  XStoreName( display, win, \"GL 3.0 Window\" );" >> checkogl.cpp
    echo "  XMapWindow( display, win );" >> checkogl.cpp
    echo "  const char *glxExts = glXQueryExtensionsString( display, DefaultScreen( display ) );" >> checkogl.cpp
    echo "  glXCreateContextAttribsARBProc glXCreateContextAttribsARB = 0;" >> checkogl.cpp
    echo "  glXCreateContextAttribsARB = (glXCreateContextAttribsARBProc) glXGetProcAddressARB( (const GLubyte *) \"glXCreateContextAttribsARB\" );" >> checkogl.cpp
    echo "  GLXContext ctx = 0;" >> checkogl.cpp
    echo "  ctxErrorOccurred = false;" >> checkogl.cpp
    echo "  int (*oldHandler)(Display*, XErrorEvent*) = XSetErrorHandler(&ctxErrorHandler);" >> checkogl.cpp
    echo "  if ( !isExtensionSupported( glxExts, \"GLX_ARB_create_context\" ) || !glXCreateContextAttribsARB )" >> checkogl.cpp
    echo "  {" >> checkogl.cpp
    echo "      exit(1);" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  else" >> checkogl.cpp
    echo "  {" >> checkogl.cpp
    echo "    int context_attribs[] =" >> checkogl.cpp
    echo "      {" >> checkogl.cpp
    echo "        GLX_CONTEXT_MAJOR_VERSION_ARB, 3," >> checkogl.cpp
    echo "        GLX_CONTEXT_MINOR_VERSION_ARB, 2," >> checkogl.cpp
    echo "        //GLX_CONTEXT_FLAGS_ARB        , GLX_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB," >> checkogl.cpp
    echo "        None};" >> checkogl.cpp
    echo "    ctx = glXCreateContextAttribsARB( display, bestFbc, 0, True, context_attribs );" >> checkogl.cpp
    echo "    XSync( display, False );" >> checkogl.cpp
    echo "    if ( ctxErrorOccurred || !ctx ){" >> checkogl.cpp
    echo "        exit(1);" >> checkogl.cpp
    echo "    }" >> checkogl.cpp
    echo "  }" >> checkogl.cpp
    echo "  XCloseDisplay( display );" >> checkogl.cpp
    echo "  return 0;" >> checkogl.cpp
    echo "}" >> checkogl.cpp

    # first try to compile with libOpenGL
    $CXX_COMPILER checkogl.cpp -Wl,-lOpenGL -lGLX -lSM -lICE -lX11 -lXext
    if [[ $? != 0 ]]; then
        echo "failed to compile checkogl.cpp with libOpenGL, trying lGL"
        rm -f a.out
        # if libOpenGL not available, compile with libGL.
        $CXX_COMPILER checkogl.cpp -Wl,-lGL -lSM -lICE -lX11 -lXext
        if [[ $? != 0 ]]; then
            echo "failed to compile checkogl.cpp"
            rm -f checkogl.cpp
            rm -f a.out
            exit 1
        fi
    fi
    ./a.out 
    if [[ $? != 0 ]]; then
        echo "Could not obtain a 3.2 context with system GL."
        echo "You may want to add --mesagl to the command line."
        echo "To disable this check use --skip-opengl-context-check"
        rm -f checkogl.cpp
        rm -f a.out
        exit 1
    fi
    rm -f checkogl.cpp
    rm -f a.out
}


# *************************************************************************** 
#                       Section 1, setting up inputs                          
# --------------------------------------------------------------------------- 
# This section sets up the inputs to the VisIt script.  This is where you can 
# specify which compiler to use, which versions of the third party libraries, 
# etc.  Note that this script is really only known to work with gcc.          
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Process all groups in one loop when feasible, instead of duplicating
#   logic for 'reqlibs' and 'optlibs' separately.
#
# *************************************************************************** 


function initialize_build_visit()
{
    # This env. variable is NOT to be overriden by user. It is intended to
    # contain user's env. just prior to running build_visit.
    export BUILD_VISIT_ENV=$(env | cut -d'=' -f1 | sort | uniq)

    # allow users to set an external hostname for output filename
    export EXTERNAL_HOSTNAME=""

    # Can cause problems in some build systems.
    unset CDPATH

    # Some systems tar command does not support the deep directory hierarchies
    # used in Qt, such as AIX. Gnu tar is a good alternative.
    ### export TAR=/usr/local/bin/tar # Up and Purple
    export TAR=tar

    #
    # we have logic that assumes lib dirs are named "lib", not "lib64". On 
    # openSuSe some of the autoconf based 3rd party libs will install to "lib64"
    # unless the "CONFIG_SITE" env var is cleared  
    #
    export CONFIG_SITE=""


    # Determine if gfortran is present. This overly complex coding is to prevent
    # the "which" command from echoing failure to the user.
    which gfortran >& /dev/null
    if [[ $? == 0 ]]; then
        export GFORTRAN=`which gfortran | grep '^/'`
    else
        export GFORTRAN=""
    fi

    export OPSYS=${OPSYS:-$(uname -s)}
    export PROC=${PROC:-$(uname -p)}
    export REL=${REL:-$(uname -r)}
    # Determine architecture
    if [[ "$OPSYS" == "Darwin" ]]; then
        export ARCH=${ARCH:-"${PROC}-apple-darwin${REL%%.*}"}
        #  export VISITARCH=${VISITARCH-${ARCH}}
        export SO_EXT="dylib"
        VER=$(uname -r)
    
        # Used http://en.wikipedia.org/wiki/Darwin_(operating_system)
        # to map Darwin Kernel versions to OSX version numbers.  Other
        # options for dealing with MACOSX_DEPLOYMENT_TARGET didn't
        # work See issue https://github.com/visit-dav/visit/issues/1506

    VER_MAJOR=${VER%%.*}

    # bash script educational note:
    # The less than sign "<" is an arithmetic expression and
    # as such one must use parenthesis (( .. )) and not square brackets.
    # i.e. if (( ${VER_MAJOR} < 8 )) ; then

    # Square brackets are for conditionals only. To make it a
    # conditional one must use "-lt"
        # i.e. if [[ ${VER_MAJOR} -lt 8 ]] ; then
        
        if [[ ${VER_MAJOR} -lt 18 ]] ; then
            echo "Unsupported Darwin major version, ${VER_MAJOR}."
            exit 1
        elif [[ ${VER_MAJOR} == 18 ]] ; then
            export MACOSX_DEPLOYMENT_TARGET=10.14
        elif [[ ${VER_MAJOR} == 19 ]] ; then
            export MACOSX_DEPLOYMENT_TARGET=10.15
        elif [[ ${VER_MAJOR} == 20 ]] ; then
            export MACOSX_DEPLOYMENT_TARGET=11.0
        elif [[ ${VER_MAJOR} == 21 ]] ; then
            export MACOSX_DEPLOYMENT_TARGET=12.0
        elif [[ ${VER_MAJOR} == 22 ]] ; then
            export MACOSX_DEPLOYMENT_TARGET=13.0
        elif [[ ${VER_MAJOR} == 23 ]] ; then
            # keep 13 (ventura)
            export MACOSX_DEPLOYMENT_TARGET=13.0 
        elif [[ ${VER_MAJOR} == 24 ]] ; then
            # keep 13 (ventura)
            export MACOSX_DEPLOYMENT_TARGET=13.0
        else
            echo "Unsupported Darwin major version, ${VER_MAJOR}."
            echo "Maybe add a new case for MACOSX_DEPLOYMENT_TARGET"
            exit 1
        fi

        export C_COMPILER=${C_COMPILER:-"clang"}
        export CXX_COMPILER=${CXX_COMPILER:-"clang++"}
        export FC_COMPILER=${FC_COMPILER:-$GFORTRAN}
        export C_OPT_FLAGS=${C_OPT_FLAGS:-"-O2"}
        export CFLAGS=${CFLAGS:-"-fno-common -fexceptions"}
        export CXX_OPT_FLAGS=${CXX_OPT_FLAGS:-"-O2"}
        export CXXFLAGS=${CXXFLAGS:-"-fno-common -fexceptions"}
        export FCFLAGS=${FCFLAGS:-$CFLAGS}
    
    elif [[ "$OPSYS" == "Linux" ]]; then
        export ARCH=${ARCH:-"linux-$(uname -m)"} # You can change this to say RHEL, SuSE, Fedora.
        export SO_EXT="so"
        if [[ "$(uname -m)" == "x86_64" ]] ; then
            CFLAGS="$CFLAGS -m64 -fPIC"
            FCFLAGS="$FCFLAGS -m64 -fPIC"
            C_OPT_FLAGS="$C_OPT_FLAGS -O2"
            CXXFLAGS="$CXXFLAGS -m64 -fPIC"
            CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
        elif [[ "$(uname -m)" == "ppc64" ]] ; then
            if [[ "$C_COMPILER" == "xlc" ]] ; then
                CFLAGS="$CFLAGS -qpic"
                FCFLAGS="$FCFLAGS -qpic"
                CXXFLAGS="$CXXFLAGS -qpic"
                export CXX_COMPILER=${CXX_COMPILER-"xlC"}
            elif [[ "$C_COMPILER" == "bgxlc" ]] ; then
                export CXX_COMPILER=${CXX_COMPILER-"bgxlC"}
            else
                CFLAGS="$CFLAGS -fPIC"
                FCFLAGS="$FCFLAGS -fPIC"
                C_OPT_FLAGS="$C_OPT_FLAGS -O2"
                CXXFLAGS="$CXXFLAGS -fPIC"
                CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
            fi
        elif [[ "$(uname -m)" == "ppc64le" ]] ; then
            if [[ "$C_COMPILER" == "xlc" ]] ; then
                CFLAGS="$CFLAGS -qpic"
                FCFLAGS="$FCFLAGS -qpic"
                CXXFLAGS="$CXXFLAGS -qpic"
                export CXX_COMPILER=${CXX_COMPILER-"xlC"}
                QT_PLATFORM="linux-xlc"
            else
                CFLAGS="$CFLAGS -fPIC"
                FCFLAGS="$FCFLAGS -fPIC"
                C_OPT_FLAGS="$C_OPT_FLAGS -O2"
                CXXFLAGS="$CXXFLAGS -fPIC"
                CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
                QT_PLATFORM="linux-g++"
            fi
        elif [[ "$(uname -m)" == "ia64" ]] ; then
            CFLAGS="$CFLAGS -fPIC"
            FCFLAGS="$FCFLAGS -fPIC"
            C_OPT_FLAGS="$C_OPT_FLAGS -O2"
            CXXFLAGS="$CXXFLAGS -fPIC"
            CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
        elif [[ "$(uname -m)" == "aarch64" ]] ; then
            CFLAGS="$CFLAGS -fPIC"
            FCFLAGS="$FCFLAGS -fPIC"
            C_OPT_FLAGS="$C_OPT_FLAGS -O2"
            CXXFLAGS="$CXXFLAGS -fPIC"
            CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
            QT_PLATFORM="linux-aarch64-gnu-g++"
        fi
        export C_COMPILER=${C_COMPILER:-"gcc"}
        export CXX_COMPILER=${CXX_COMPILER:-"g++"}
        export FC_COMPILER=${FC_COMPILER:-$GFORTRAN}
        export C_OPT_FLAGS=${C_OPT_FLAGS:-"-O2"}
        export CXX_OPT_FLAGS=${CXX_OPT_FLAGS:-"-O2"}
    else
        export ARCH=${ARCH:-"linux-$(uname -m)"} # You can change this to say RHEL, SuSE, Fedora.
        export SO_EXT="so"
        if [[ "$(uname -m)" == "x86_64" ]] ; then
            CFLAGS="$CFLAGS -m64 -fPIC"
            FCFLAGS="$FCFLAGS -m64 -fPIC"
            C_OPT_FLAGS="$C_OPT_FLAGS -O2"
            CXXFLAGS="$CXXFLAGS -m64 -fPIC"
            CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
        fi
        if [[ "$(uname -m)" == "ia64" ]] ; then
            CFLAGS="$CFLAGS -fPIC"
            FCFLAGS="$FCFLAGS -fPIC"
            C_OPT_FLAGS="$C_OPT_FLAGS -O2"
            CXXFLAGS="$CXXFLAGS -fPIC"
            CXX_OPT_FLAGS="$CXX_OPT_FLAGS -O2"
        fi
        export C_COMPILER=${C_COMPILER:-"gcc"}
        export FC_COMPILER=${FC_COMPILER:-$GFORTRAN}
        export CXX_COMPILER=${CXX_COMPILER:-"g++"}
        export C_OPT_FLAGS=${C_OPT_FLAGS:-"-O2"}
        export CXX_OPT_FLAGS=${CXX_OPT_FLAGS:-"-O2"}
    fi

    export MAKE=${MAKE:-"make"}
    export THIRD_PARTY_PATH=${THIRD_PARTY_PATH:-"./third_party"}
    export GROUP=${GROUP:-"visit"}
    #export LOG_FILE=${LOG_FILE:-"${0##*/}_log"}
    export GITREVISION=${GITREVISION:-"HEAD"}
    # Created a temporary value because the user can override most of
    # the components, which for the GUI happens at a later time.
    # the tmp value is useful for user feedback.
    if [[ $VISITARCH == "" ]] ; then
        export VISITARCHTMP=${ARCH}_${C_COMPILER}
        if [[ "$CXX_COMPILER" == "g++" ]] ; then
            VERSION=$(g++ -v 2>&1 | grep "gcc version" | cut -d' ' -f3 | cut -d'.' -f1-2)
            VISITARCHTMP=${VISITARCHTMP}-${VERSION}
        fi
    else
        # use environment variable value
        export VISITARCHTMP=$VISITARCH
    fi

    REDIRECT_ACTIVE="no"
    ANY_ERRORS="no"

    #initialize VisIt
    bv_visit_initialize "$@"

    #
    # OPTIONS
    #
    #initialize all libraries..

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            initializeFunc="bv_${lib}_initialize"
            $initializeFunc
        done
    done

    export DO_HOSTCONF="yes"
    export DO_QT_SILENT="yes"

    export DO_DEBUG="no"
    export DO_GROUP="no"
    export DO_LOG="no"
    parallel="no"
    export DO_GIT="no"
    export DO_GIT_ANON="no"
    export DO_REVISION="no"
    USE_VISIT_FILE="no"
    export DO_PATH="no"
    export DO_VERSION="no"
    export DO_VERBOSE="no"
    export DO_JAVA="no"
    export DO_FORTRAN="no"
    export DO_PARADIS="no"
    export PREVENT_ICET="no"
    verify="no"
    export DO_DBIO_ONLY="no"
    export DO_ENGINE_ONLY="no"
    export DO_SERVER_COMPONENTS_ONLY="no"
    export DO_STATIC_BUILD="no"
    export DO_THREAD_BUILD="no"
    export USE_VISIBILITY_HIDDEN="no"
    export VISIT_INSTALL_PREFIX=""
    export VISIT_BUILD_MODE="Release"
    export VISIT_SELECTED_DATABASE_PLUGINS=""
    export DO_XDB="no"
    export CREATE_RPM="no"
    export DO_CONTEXT_CHECK="yes"
    export VISIT_INSTALL_NETWORK=""
    export DO_VTK94="no"
    DOWNLOAD_ONLY="no"
    LIST_TPS="no"


    if [[ "$CXX_COMPILER" == "g++" ]] ; then
        VERSION=$(g++ -v 2>&1 | grep "gcc version" | cut -d' ' -f3 | cut -d'.' -f1-1)
        if [[ ${VERSION} -ge 4 ]] ; then
            export USE_VISIBILITY_HIDDEN="yes"
        fi
    fi


    # Setup git path
    export GIT_ANON_ROOT_PATH="http://github.com/visit-dav/visit.git"
    export GIT_REPO_ROOT_PATH="ssh://git@github.com/visit-dav/visit.git"


    if [[ "$OPSYS" != "Darwin" ]]; then
        WGET_MINOR_VERSION=$(wget --version| head -n 1|cut -d. -f 2)
        # version 1.7 pre-dates ssl integration
        if [[ "${WGET_MINOR_VERSION}" == "8" ]] ; then
            export WGET_OPTS=${WGET_OPTS=""}
        elif [[ "${WGET_MINOR_VERSION}" == "9" ]] ; then
            export WGET_OPTS=${WGET_OPTS:="--sslcheckcert=0"}
        else
            export WGET_OPTS=${WGET_OPTS:-"--no-check-certificate"}
        fi
    fi


    #
    # Check the command line arguments for any arguments that need to be
    # handled before calling the bv_XXX_info methods. This would mainly
    # be arguments that affect the version of a package being built.
    #
    for arg in "$@" ; do
        case $arg in
            --vtk94) DO_VTK94="yes"; DO_VTK="yes";;
        esac
    done

    #get visit information..
    bv_visit_info

    #
    # TARBALL LOCATIONS AND VERSIONS
    #
    if [[ "$VISIT_FILE" != "" ]] ; then
        USE_VISIT_FILE="yes"
    fi
    export VISIT_FILE=${VISIT_FILE:-"visit${VISIT_VERSION}.tar.gz"}

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            initializeFunc="bv_${lib}_info"
            $initializeFunc
        done
    done

    WRITE_UNIFIED_FILE=""
    VISIT_INSTALLATION_BUILD_DIR=""
    DO_SUPER_BUILD="no"
    DO_MANGLED_LIBRARIES="no"
}




# *************************************************************************** #
# Function: starts_with_quote                                                 #
#                                                                             #
# Purpose: Meant to be used in `if $(starts_with_quote "$var") ; then`        #
#          conditionals.                                                      #
#                                                                             #
# Programmer: Tom Fogal                                                       #
# Date: Thu Oct  9 15:24:04 MDT 2008                                          #
#                                                                             #
# *************************************************************************** #

function starts_with_quote
{
    if test "${1:0:1}" = "\""; then #"
        return 0
    fi
    if test "${1:0:1}" = "'" ; then
        return 0
    fi
    return 1
}

# *************************************************************************** #
# Function: ends_with_quote                                                   #
#                                                                             #
# Purpose: Meant to be used `if $(ends_with_quote "$var") ; then`             #
#          conditionals.                                                      #
#                                                                             #
# Programmer: Tom Fogal                                                       #
# Date: Thu Oct  9 15:24:13 MDT 2008                                          #
#                                                                             #
# *************************************************************************** #

function ends_with_quote
{
    if test "${1: -1:1}" = "\""; then #"
        return 0
    fi
    if test "${1: -1:1}" = "'"; then
        return 0
    fi
    return 1
}

# *************************************************************************** #
# Function: strip_quotes                                                      #
#                                                                             #
# Purpose: Removes all quotes from the given argument.  Meant to be used in   #
#          $(strip_quotes "$some_string") expressions.                        #
#                                                                             #
# Programmer: Tom Fogal                                                       #
# Date: Thu Oct  9 16:04:25 MDT 2008                                          #
#                                                                             #
# *************************************************************************** #

function strip_quotes
{
    local arg="$@"
    str=""
    while test -n "$arg" ; do
        if test "${arg:0:1}" != "\"" ; then
            str="${str}${arg:0:1}"
        fi
        arg="${arg:1}"
    done
    echo "${str}"
}


# *************************************************************************** 
# Function: bv_enable_group
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Modified to test for actual group names and return early if possible.
#   Don't allow 'explicit' group to be 'enabled'. Print message and exit if so.
#   Remove test for 'dbio-only'.
#
#   Kathleen Biagas, Monday May 19, 2025
#   Allow --no-thirdparty as a way to disable required group. This preserves
#   the purpose of the option even though the '--no-thirdparty' group no
#   longer exists.
#
# *************************************************************************** 

function bv_enable_group
{
    local name=${1/--}
    local match=0

    # don't want to allow enablement of 'explicit' group.
    if [[ "$name" == "explicit" ]] ; then
        info "Libraries in group 'explicit' cannot be enabled via '--explicit'. Each desired 'explicit' library should be added separately, e.g. '--llvm --osmesa'."
        exit
    fi

    if [[ "$name" == "no-thirdparty" ]] ; then
        name="no-required"
    fi

    # can terminate early if $name isn't 'optional' or 'required'.
    if [[ "$name" != "optional" && "$name" != "required" &&
          "$name" != "no-required" ]] ; then
        return 0
    fi

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        #replace | with space
        group_flag=${grouplibs_name[$bv_i]}
        group_flag=${group_flag//\|/ }
        for group in `echo $group_flag`;
        do
            if [[ "$group" == "$name" ]]; then
                echo "executing group $name"
                match=1
                for group_dep in `echo ${grouplibs_deps[$bv_i]}`;
                do
                    info "bv_enable_group enabling $group_dep"
                    initializeFunc="bv_${group_dep}_enable"
                    $initializeFunc
                done
            elif [[ "no-$group" == "$name" ]]; then
                match=1
                for group_dep in `echo ${grouplibs_deps[$bv_i]}`;
                do
                   info "bv_enable_group disabling $group_dep"
                   initializeFunc="bv_${group_dep}_disable"
                   $initializeFunc
                done
            fi
        done
    done

    return $match
}

# *************************************************************************** 
# Function: enable_dependent_libraries
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Process all groups in one loop, instead of duplicating
#   logic for 'reqlibs' and 'optlibs' separately.
#
# *************************************************************************** 

function enable_dependent_libraries
{
    local depends_on=""

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            $"bv_${lib}_is_enabled"

            #if not enabled then skip
            if [[ $? == 0 ]]; then
                continue
            fi

            #enabled library, check dependencies..
            depends_on=$("bv_${lib}_depends_on")

            #replace commas with spaces if there are any..
            depends_on=${depends_on//,/ }

            for depend_lib in `echo $depends_on`;
            do
                $"bv_${depend_lib}_is_enabled"
                if [[ $? == 0 ]]; then
                    error "ERROR: library ${depend_lib} was not set ${lib} depends on it, please enable"
                    #echo "library ${depend_lib} was not set but another library depends on it, enabling it"
                    #$"bv_${depend_lib}_enable"
                fi
            done
        done
    done
}

# *************************************************************************** 
# Function: initialize_module_variables
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Process all groups in one loop, instead of duplicating
#   logic for 'reqlibs' and 'optlibs' separately.
#
# *************************************************************************** 
#TODO: enable this feature and remove this from ensure..
function initialize_module_variables
{
    info "initializing module variables"

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        groupname=${grouplibs_name[$bv_i]}
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            $"bv_${lib}_is_enabled"

            #if not enabled then skip
            if [[ $? == 0 ]]; then
                continue
            fi

            declare -F "bv_${lib}_initialize_vars" &>/dev/null

            if [[ $? == 0 ]]; then
                info "initialize module variables for ${lib}"
                $"bv_${lib}_initialize_vars"
            fi
        done
    done
}


function build_library
{
    local build_lib=$1
    local depends_on=""

    #check if library is already installed..
    $"bv_${build_lib}_is_installed"

    if [[ $? == 1 ]]; then
        info "$build_lib is already installed, skipping"
        return
    fi

    #Make sure that the recursive enable feature is working properly
    $"bv_${build_lib}_is_enabled"

    if [[ $? == 0 ]]; then
        error "$build_lib was disabled, but seems that another library requires it "
    fi

    depends_on=$("bv_${build_lib}_depends_on")

    if [[ $depends_on != "" ]]; then
        info "library $build_lib depends on $depends_on"
    fi

    #replace commas with spaces if there are any..
    depends_on=${depends_on//,/ }

    for depend_lib in `echo $depends_on`;
    do
        build_library $depend_lib
    done

    #build ..
    $"bv_${build_lib}_build"
}

# *************************************************************************** 
# Function: build_libraries_serial
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Process all groups in one loop, instead of duplicating
#   logic for 'reqlibs' and 'optlibs' separately.
#
# *************************************************************************** 

function build_libraries_serial
{
    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        groupname=${grouplibs_name[$bv_i]}
        info "Building ${groupname} libraries"
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            $"bv_${lib}_is_enabled"

            if [[ $? == 0 ]]; then
                continue
            fi

            $"bv_${lib}_is_installed"

            if [[ $? == 0 ]]; then
                cd "$START_DIR"
                build_library ${lib}
            else
                info "${lib} already installed, skipping"
            fi
        done
    done
}

# *************************************************************************** 
# Function: build_libraries_parallel
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Process all groups in one loop, instead of duplicating
#   logic for 'reqlibs' and 'optlibs' separately.
#
# *************************************************************************** 

function build_libraries_parallel
{
    #launch all non dependent libraries in parallel..

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        groupname=${grouplibs_name[$bv_i]}
        info "Building parallel ${groupname} libraries"
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            $"bv_${lib}_is_enabled"

            if [[ $? == 0 ]]; then
                continue
            fi

            $"bv_${lib}_is_installed"
            if [[ $? == 0 ]]; then
                depends_on=$("bv_${lib}_depends_on")
                if [[ "$depends_on" == "" ]]; then
                    (cd "$START_DIR" && build_library ${lib}) &
                fi
            else
                info "${lib} already installed, skipping"
            fi
        done

        wait

        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            $"bv_${lib}_is_enabled"

            if [[ $? == 0 ]]; then
                continue
            fi

            $"bv_${lib}_is_installed"

            if [[ $? == 0 ]]; then
                cd "$START_DIR"
                build_library ${lib}
            else
                info "${lib} already installed, skipping"
            fi
        done
    done
}

# *************************************************************************** #
#                       Section 2, building VisIt                             #
# --------------------------------------------------------------------------- #
# This section does some set up for building VisIt, and then calls the        #
# functions to build the third party libraries and VisIt itself.              #
# *************************************************************************** #
function run_build_visit()
{
    declare -a arguments

    # Will be set if the next argument is an argument to an argument (I swear that
    # makes sense).  Make sure to unset it after pulling the argument!
    next_arg=""
    # If the user gives any deprecated options, we'll append command line options
    # we think they should use here.
    deprecated=""
    # A few options require us to perform some action before we start building
    # things, but we'd like to finish option parsing first.  We'll set this
    # variable in those cases, and test it when we finish parsing.
    next_action=""

    #handle groups first since they affect multiple libraries..
    for arg in "$@" ;
    do
        bv_enable_group "$arg"
        #not part of a group, add to argument list..
        if [[ $? == 0 ]]; then
            local match=0

            #suppress licenses from argument list
            for license in `echo $defaultLicenses`
            do
                if [[ "${arg/--}" == "$license" ]]; then
                    match=1
                    break
                fi
            done

            #suppress licenses as well..
            if [[ $match == 0 ]]; then
                arguments[${#arguments[*]}]="$arg"
            fi
        fi
    done

    for arg in "${arguments[@]}" ; do

        # Was the last option something that took an argument?
        if test -n "$next_arg" ; then
            # Yep.  Which option was it?
            case $next_arg in
                extra_commandline_arg) $EXTRA_COMMANDLINE_ARG_CALL "$arg";;
                visit-build-hostname) EXTERNAL_HOSTNAME="$arg";;
                installation-build-dir) VISIT_INSTALLATION_BUILD_DIR="$arg";;
                write-unified-file) WRITE_UNIFIED_FILE="$arg";;
                append-cflags) C_OPT_FLAGS="${C_OPT_FLAGS} ${arg}";;
                append-cxxflags) CXX_OPT_FLAGS="${CXX_OPT_FLAGS} ${arg}";;
                arch) VISITARCH="${arg}";;
                build-mode) VISIT_BUILD_MODE="${arg}";;
                cflags) C_OPT_FLAGS="${arg}";;
                cxxflags) CXX_OPT_FLAGS="${arg}";;
                cc) C_COMPILER="${arg}";;
                cxx) CXX_COMPILER="${arg}";;
                database-plugins) VISIT_SELECTED_DATABASE_PLUGINS="${arg}";;
                fc) FC_COMPILER="${arg}"; DO_FORTRAN="yes";;
                log-file) LOG_FILE="${arg}";;
                makeflags) MAKE_OPT_FLAGS="${arg}";;
                prefix) VISIT_INSTALL_PREFIX="${arg}";;
                install-network) VISIT_INSTALL_NETWORK="${arg}";;
                group) GROUP="${arg}";;
                git) GITREVISION="${arg}";;
                tarball) VISIT_FILE="${arg}";;
                thirdparty-path) THIRD_PARTY_PATH="${arg}";;
                version) VISIT_VERSION="${arg}"
                         VISIT_FILE="visit${VISIT_VERSION}.tar.gz";;
                *) error "Unknown next_arg value '$next_arg'!"
            esac
            # Make sure we process the next option as an option and not an
            # argument to an option.
            next_arg=""
            continue
        fi

        if [[ ${#arg} -gt 2 ]] ; then #has --

            #one module at a time
            resolve_arg=${arg:2} #remove --
            declare -F "bv_${resolve_arg}_enable" &>/dev/null

            if [[ $? == 0 ]] ; then
                #echo "enabling $resolve_arg"
                initializeFunc="bv_${resolve_arg}_enable"
                $initializeFunc
                continue
            elif [[ ${#resolve_arg} -gt 3 ]] ; then #in case it is --no-
                resolve_arg_no_opt=${resolve_arg:3}
                #disable library if it does not exist..
                declare -F "bv_${resolve_arg_no_opt}_disable" &>/dev/null
                if [[ $? == 0 ]] ; then
                    #echo "disabling ${resolve_arg_no_opt}"
                    initializeFunc="bv_${resolve_arg_no_opt}_disable"
                    $initializeFunc
                    #if disabling icet, prevent it as well
                    if [[ ${resolve_arg_no_opt} == "icet" ]]; then
                        echo "preventing icet from starting"
                        PREVENT_ICET="yes"
                    fi
                    continue
                fi
            fi

            #command line arguments created by modules
            #checking to see if additional command line arguments were requested
            resolve_arg=${arg:2} #remove --
            local match=0
            for (( bv_i=0; bv_i<${#extra_commandline_args[*]}; bv_i += 5 ))
            do
                local module_name=${extra_commandline_args[$bv_i]}
                local command=${extra_commandline_args[$bv_i+1]}
                local args=${extra_commandline_args[$bv_i+2]}
                local comment=${extra_commandline_args[$bv_i+3]}
                local fp=${extra_commandline_args[$bv_i+4]}
                if [[ "$command" == "$resolve_arg" ]]; then
                    if [ $args -eq 0 ] ; then
                        #call function immediately
                        $fp
                    else
                        #call function with next argument
                        next_arg="extra_commandline_arg"
                        EXTRA_COMMANDLINE_ARG_CALL="$fp"
                    fi
                    match=1
                    break;
                fi
            done

            #found a match in the modules..
            if [[ $match -eq 1 ]]; then
                continue
            fi
        fi


        case $arg in
            --visit-build-hostname) next_arg="visit-build-hostname";;
            --installation-build-dir) next_arg="installation-build-dir";;
            --write-unified-file) next_arg="write-unified-file";;
            --parallel-build) DO_SUPER_BUILD="yes";;
            --arch) next_arg="arch";;
            --build-mode) next_arg="build-mode";;
            --cflag) next_arg="append-cflags";;
            --cflags) next_arg="cflags";;
            --cxxflag) next_arg="append-cxxflags";;
            --cxxflags) next_arg="cxxflags";;
            --cc) next_arg="cc";;
            --cxx) next_arg="cxx";;
            --create-rpm) CREATE_RPM="yes";;
            --log-file) next_arg="log-file";;
            --database-plugins) next_arg="database-plugins";;
            --bv-debug) set -vx;;
            --download-only) DOWNLOAD_ONLY="yes";;
            --engine-only) DO_ENGINE_ONLY="yes";;
            --gdal) DO_GDAL="yes";;
            --fc) next_arg="fc";;
            --fortran) DO_FORTRAN="yes";;
            --group) next_arg="group"; DO_GROUP="yes";;
            -h|--help) next_action="help";;
            --install-network) next_arg="install-network";;
            --java) DO_JAVA="yes";;
            --list-tpls) LIST_TPLS="yes";;
            --makeflags) next_arg="makeflags";;
            --no-hostconf) DO_HOSTCONF="no";;
            --no-boost) DO_BOOST="no";;
            --no-qt-silent) DO_QT_SILENT="no";;
            --parallel) parallel="yes"; DO_ICET="yes";;
            --prefix) next_arg="prefix";;
            --print-vars) next_action="print-vars";;
            --server-components-only) DO_SERVER_COMPONENTS_ONLY="yes";;
            --paradis) DO_PARADIS="yes";;
            --static) DO_STATIC_BUILD="yes"
                      export USE_VISIBILITY_HIDDEN="no"
                      CXXFLAGS=$(echo $CXXFLAGS | sed "s/-fPIC//g")
                      CFLAGS=$(echo $CFLAGS | sed "s/-fPIC//g")
                      ;;
            --thread) DO_THREAD_BUILD="yes";;
            --stdout) LOG_FILE="/dev/tty";;
            --git) DO_GIT="yes"; export GIT_ROOT_PATH=$GIT_REPO_ROOT_PATH;;
            --git-anon) DO_GIT="yes"; DO_GIT_ANON="yes" ; export GIT_ROOT_PATH=$GIT_ANON_ROOT_PATH ;;
            --git-anonymous) DO_GIT="yes"; DO_GIT_ANON="yes" ; export GIT_ROOT_PATH=$GIT_ANON_ROOT_PATH ;;
            --git-revision) next_arg="git"; DO_GIT="yes"; DO_REVISION="yes"; DO_GIT_ANON="yes" ; export GIT_ROOT_PATH=$GIT_ANON_ROOT_PATH ;;
            --tarball) next_arg="tarball"
                       USE_VISIT_FILE="yes";;
            --thirdparty-path) next_arg="thirdparty-path";;
            --version) next_arg="version";;
            --xdb) DO_XDB="yes";;
            --skip-opengl-context-check) DO_CONTEXT_CHECK="no";;
            *)
                echo "Unrecognized option '${arg}'."
                ANY_ERRORS="yes";;
        esac
    done

    #error check to make sure that next arg is not left blank..
    if [[ $next_arg != "" ]] ; then
        echo "command line arguments are used incorrectly: argument $next_arg not fullfilled"
        exit 1
    fi

    if [[ "$ANY_ERRORS" == "yes" ]] ; then
        echo "command line arguments are used incorrectly. see above..."
        exit 1
    fi

    if test -n "${deprecated}" ; then
        summary="You are using some deprecated options to $0.  Please re-run"
        summary="${summary} $0 with a command line similar to:"
        echo "$summary"
        echo ""
        echo "$0 ${deprecated}"
        exit 1
    fi

    if test -n "${next_action}" ; then
        case ${next_action} in
            print-vars) printvariables; exit 2;;
            help) usage; exit 2;;
        esac
    fi

    #
    # Echo the current invocation command line to the log file
    #
    info "[build_visit invocation arguments] $@"


    #
    # Write a unified file
    #
    if [[ $WRITE_UNIFIED_FILE != "" ]] ; then
        bv_write_unified_file $WRITE_UNIFIED_FILE
        exit 0
    fi

    #
    # If we doing a trunk or RC build then make sure we are using GIT
    #
    if [[ "$TRUNK_BUILD" == "yes" || "$RC_BUILD" == "yes" ]]; then
        if [[ "$DO_GIT" == "no" ]]; then
            DO_GIT="yes"
            DO_GIT_ANON="yes"
            export GIT_ROOT_PATH=$GIT_ANON_ROOT_PATH
        fi
    fi

    #
    # Add -g if we are doing a debug build
    #
    info "[build_visit build mode ] $VISIT_BUILD_MODE"
    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        C_OPT_FLAGS="${C_OPT_FLAGS} -g"
        CXX_OPT_FLAGS="${CXX_OPT_FLAGS} -g"
    fi

    check_minimum_compiler_version

    if [[ "$OPSYS" != "Darwin" && $DO_MESAGL == "no" && $DO_CONTEXT_CHECK != "no"  && $DO_DBIO_ONLY == "no" ]] ; then 
        if [[ $DO_VTK == "yes" || $DO_VISIT == "yes" ]] ; then
            check_opengl_context
        fi
    fi

    # Disable fortran support unless --fortran specified and a fortran compiler
    # was specified or found.
    if [[ $DO_FORTRAN == "no" || $FC_COMPILER == "" ]]; then
        export FC_COMPILER="no";
        warn "Fortran support for thirdparty libraries disabled."
    fi

    # make all VisIt related builds in its own directory..
    if [[ $VISIT_INSTALLATION_BUILD_DIR != "" ]] ; then
        if [[ -d $VISIT_INSTALLATION_BUILD_DIR ]]; then
            echo "Using already existing directory: $VISIT_INSTALLATION_BUILD_DIR"
        else
            mkdir -p $VISIT_INSTALLATION_BUILD_DIR
        fi

        if [[ ! -d $VISIT_INSTALLATION_BUILD_DIR ]]; then
            echo "Directory does not exist or I do not have permission to create it. Quitting"
            exit 0
        fi
        cd $VISIT_INSTALLATION_BUILD_DIR
    fi

    #
    # Log build_visit invocation w/ arguments & the start time.
    # Especially helpful if there are multiple starts dumped into the
    # same log.
    #
    LINES="------------------------------------------------------------"
    touch $LOG_FILE
    log $LINES
    log $0 $@
    log "Started:" $(date)
    log $LINES

    if [[ "$DO_GIT" == "yes" ]] ; then
        check_git_client
        if [[ $? != 0 ]]; then
            error "Fatal Error: GIT mode selected, but git client is not available."
        fi
    fi

    if [[ "$LIST_TPLS" == "yes" ]] ; then
      info $LINES
      info "build_visit Third-party Libraries:"
      for var in $(set -o posix; set | grep _FILE=; set +o posix); do
          var=$(echo $var | cut -d '=' -f1)
          info $var ${!var}
      done
      info $LINES
      exit 0
    fi

    #enabling any dependent libraries, handles both dependers and dependees..
    #TODO: handle them separately
    info "enabling any dependent libraries"
    enable_dependent_libraries

    START_DIR="$PWD"

    if [[ "$DOWNLOAD_ONLY" == "no" ]] ; then
        if [[ ! -d "$THIRD_PARTY_PATH" ]] ; then
            if [[ "$THIRD_PARTY_PATH" == "./visit" ]] ; then
                mkdir "$THIRD_PARTY_PATH"
                if [[ $? != 0 ]] ; then
                    error "Unable to write files to the third party library location." \
                          "Bailing out."
                fi
            else
                info "The third party library location, \"$THIRD_PARTY_PATH\"" \
                     "does not exist. Create it? [yes/no]"
                read RESPONSE
                if [[ "$RESPONSE" != "yes" ]] ; then
                    error "The third party library location does not exist." \
                          "Bailing out."
                else
                    mkdir "$THIRD_PARTY_PATH"
                    if [[ $? != 0 ]] ; then
                        error "Unable to write files to the third party library location." \
                              "Bailing out."
                    fi
                fi
            fi
        fi

        cd "$THIRD_PARTY_PATH"
        if [[ $? != 0 ]] ; then
            error "Unable to access the third party location. Bailing out."
        fi
    fi

    if [[ $VISITARCH == "" ]] ; then
        C_COMPILER_BASENAME=$(basename ${C_COMPILER})
        CXX_COMPILER_BASENAME=$(basename ${CXX_COMPILER})
        export VISITARCH=${ARCH}_${C_COMPILER_BASENAME}
        if [[ "$CXX_COMPILER_BASENAME" == "g++" ]] ; then
            VERSION=$(${CXX_COMPILER} -v 2>&1 | grep "gcc version" | cut -d' ' -f3 | cut -d'.' -f1-2)
            VISITARCH=${VISITARCH}-${VERSION}
        elif [[ "$CXX_COMPILER_BASENAME" == "icpc" ]] ; then
            VERSION=$(${CXX_COMPILER} --version | cut -d' ' -f3 | head -n1)
            VISITARCH=${VISITARCH}-${VERSION}
        fi
    fi

    export VISITDIR=${VISITDIR:-$(pwd)}
    cd "$START_DIR"

    #
    # See if the user wants to build a parallel version.
    #
    check_parallel
    if [[ $? != 0 ]] ; then
        error "Stopping build because necessary parallel options are not set."
    fi

    if [[ "$DO_ICET" == "yes" && "$PREVENT_ICET" != "yes" ]] ; then
        DO_CMAKE="yes"
    fi

    # initialize module variables, since all of VisIt's variables should
    # be set by now..
    initialize_module_variables


    # OSMESA is on by default (required), so that it can serve as fallback
    # at runtime for offscreen rendering if VTK cannot otherwise generate
    # a good context.  However, if user needs MESAGL for on-screen context
    # (opengl_context_check tests this), then we want to turn off OSMESA
    # since it will be available with the MESGL build.
    if [[ "$DO_MESAGL" == "yes" && "$DO_OSMESA" == "yes" ]] ; then
        bv_osmesa_disable
    fi

    # LLVM is on by default (since OSMESA is required),
    # If neither OSMESA nor MESAGL are being used, disable LLVM
    if [[ "$DO_MESAGL" == "no" &&  "$DO_OSMESA" == "no" ]] ; then
        bv_llvm_disable
    fi

    #
    # Disable qt,qwt if it is not needed
    #
    if [[ "$DO_ENGINE_ONLY" == "yes" || "$DO_DBIO_ONLY" == "yes" || "$DO_SERVER_COMPONENTS_ONLY" == "yes" ]] ; then
        if [[ "$DO_ENGINE_ONLY" == "yes" ]] ; then
           info "disabling qt, qwt because --engine-only used"
        elif [[ "$DO_DBIO_ONLY" == "yes" ]] ; then
           info "disabling qt, qwt because --dbio-only used"
        elif [[ "$DO_SERVER_COMPONENTS_ONLY" == "yes" ]] ; then
           info "disabling qt, qwt because --server-components-only used"
        fi
        bv_qt_disable
        bv_qwt_disable
    fi

    #
    # Save stdout as stream 3, redirect stdout and stderr to the log file.
    # After this maks sure to use the info/warn/error functions to display
    # messages to the user
    #

    if [[ "${LOG_FILE}" != "/dev/tty" ]] ; then
        exec 3>&1 >> ${LOG_FILE} 2>&1
        REDIRECT_ACTIVE="yes"
    else
        exec 2>&1
    fi

    #
    #
    # Now make sure that we have everything we need to build VisIt, so we can bail
    # out early if we are headed for failure.
    #
    check_files
    if [[ $? != 0 ]] ; then
        error "Stopping build because necessary files aren't available."
    fi

    #
    # Exit if we were told to only download the files.
    #
    if [[ "$DOWNLOAD_ONLY" == "yes" ]] ; then
        info "Successfully downloaded the specified files."
        exit 0
    fi

    if [[ $DO_MANGLED_LIBRARIES == "yes" ]]; then
        info "Mangling libraries while building"
        info "Any libraries that support mangling will do so"
    fi

    if [[ "$DO_SUPER_BUILD" == "yes" ]]; then
        build_libraries_parallel
    else
        build_libraries_serial
    fi

    #
    # Create the host.conf file
    #

    if [[ "$DO_HOSTCONF" == "yes" ]] ; then
        info "Creating host.conf"
        build_hostconf
    fi

    #build visit itself..
    bv_visit_build
}
export LOG_FILE=${LOG_FILE:-"$(pwd)/${0##*/}_log"}

# *************************************************************************** #
# Purpose: Flexible comparison function for version strings                   #
#                                                                             #
#   - Converts version string "4.101.3" to bash array (4 101 3)               #
#   - Appends zeros to operand with fewer array members (4)==>(4 000 0)       #
#   - Ensures appended zeros have same length as counterparts                 #
#   - Prepends zeros to digit strings with fewer digits (4 9 3)==>(4 09 3)    #
#   - Forms integer values from arrays (4 101 3)==>41013                      #
#   - Compares integers using specified operator                              #
#   - Sets status using test operator                                         #
#                                                                             #
# *************************************************************************** #
function compare_version_strings
{   
    # default op is -lt and separator char is .
    op=${3:-'-lt'}
    sep=${4:-'.'}

    # create array variables of digits from version string
    vldigitarr=($(echo $1 | tr $sep ' '))
    vrdigitarr=($(echo $2 | tr $sep ' '))

    # append strings of zeros of equal length of missing digits
    # "5"==>"0", "10"==>"00", "101"==>"000"
    i=0
    while [[ ${#vldigitarr[@]} -lt ${#vrdigitarr[@]} ]]; do
        zeros=$(echo ${vrdigitarr[$i]} | tr '1234567890' '0000000000')
        vldigitarr+=($zeros)
        i=$((i+1))
    done
    while [[ ${#vrdigitarr[@]} -lt ${#vldigitarr[@]} ]]; do
        zeros=$(echo ${vldigitarr[$i]} | tr '1234567890' '0000000000')
        vrdigitarr+=($zeros)
        i=$((i+1))
    done

    # prepend zeros to digit entries with fewer characters
    i=0
    while [[ $i -lt ${#vldigitarr[@]} ]]; do
        vlndigits=$(echo ${vldigitarr[$i]} | wc -c)
        vrndigits=$(echo ${vrdigitarr[$i]} | wc -c)
        if [[ $vlndigits -lt $vrndigits ]]; then
           ((vrndigits--))
           zeros=$(printf '0%.0s' $(seq $vlndigits $vrndigits))
           vldigitarr[$i]="${zeros}${vldigitarr[$i]}"
        elif [[ $vrndigits -lt $vlndigits ]]; then
           ((vlndigits--))
           zeros=$(printf '0%.0s' $(seq $vrndigits $vlndigits))
           vrdigitarr[$i]="${zeros}${vrdigitarr[$i]}"
        fi
        i=$((i+1))
    done

    # Turn arrays of digit strings into integers
    # "4 10 3" ==> 4103
    vlval=$(echo ${vldigitarr[@]} | tr -d ' ')
    vrval=$(echo ${vrdigitarr[@]} | tr -d ' ')

    test $vlval $op $vrval
}

function test_compare_version_strings
{
    # Test different operators
    compare_version_strings 4.0.0 4.0.0 -eq
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4.0.1 4.0.0 -gt
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4.0.0 4.0.1 -lt
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4.0.0 4.0.1 -ne
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }

    # Test different sep chars
    compare_version_strings 4-0-0 4-0-0 -eq -
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4%0%0 4%0%0 -eq %
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }

    # Test implied zero digits
    compare_version_strings 4.0.0 4 -eq
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4 4.0.0 -eq
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }

    # Test digits that cross order of magnitude boundaries
    compare_version_strings 4.9.3 4.10.3 -lt
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4.10.3 4.9.3 -gt
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }

    # Test some combinations
    compare_version_strings 4.10 4.9.3 -gt
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }
    compare_version_strings 4.9.101.3.0 4.10.0.3 -lt
    test $? -eq 0 || { echo "compare_version_strings is failing"; exit 1; }

}

# *************************************************************************** #
# Function: errorFunc                                                         #
#                                                                             #
# Purpose: Error messages                                                     #
#                                                                             #
# *************************************************************************** #
function errorFunc
{
    echo $1
    exit 0
}

# *************************************************************************** #
# Function: log                                                               #
#                                                                             #
# Purpose: Log message for the log.                                           #
#                                                                             #
# Programmer: Tom Fogal                                                       #
# Date: Fri Oct  3 09:37:51 MDT 2008                                          #
#                                                                             #
# *************************************************************************** #
function log
{
    if [[ "${LOG_FILE}" != "/dev/tty" && -w "${LOG_FILE}" ]] ; then
        echo "$@" >> ${LOG_FILE}
    fi
}
 
# *************************************************************************** #
# Function: info                                                              #
#                                                                             #
# Purpose: Give an informative message to the user.                           #
#                                                                             #
# Programmer: Tom Fogal                                                       #
# Date: Fri Oct  3 09:41:50 MDT 2008                                          #
#                                                                             #
# *************************************************************************** #
function info
{
    if [[ "$REDIRECT_ACTIVE" == "yes" ]] ; then
        echo -e "$@" 1>&3
    else
        echo -e "$@"
    fi

    # write message to log as well
    log "$@"
}

# *************************************************************************** #
# Function: warn                                                              #
#                                                                             #
# Purpose: Echo to screen and log.                                            #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date: Tue Nov 18 15:09:47 PST 2008                                          #
#                                                                             #
# Modifications:                                                              #
#                                                                             #
#   Hank Childs, Fri Jan 28 10:32:06 PST 2011                                 #
#   Add -e to echo so tabs are printed.                                       #
#                                                                             #
# *************************************************************************** #
function warn
{
    info $@
}

# *************************************************************************** #
# Function: error                                                             #
#                                                                             #
# Purpose: Report an error message and exit.                                  #
#                                                                             #
# Programmer: Tom Fogal                                                       #
# Date: Fri Oct  3 09:37:51 MDT 2008                                          #
#                                                                             #
# Modifications:                                                              #
#    Jeremy Meredith, Fri Jul 22 10:36:20 EDT 2011                            #
#    Added a little more text to help users.                                  #
# *************************************************************************** #

function error
{
    warn "$@"
    if test "${LOG_FILE}" != "/dev/tty" ; then
        warn "Error in build process.  See ${LOG_FILE} for more information."\
             "If the error is unclear, please include ${LOG_FILE} and contact "\
             "the VisIt project via https://visit-help.llnl.gov. You may "\
             "need to compress the ${LOG_FILE} using a program like gzip "\
             "so it will fit within the size limits for attachments."
        info "Log file full path: " ${LOG_FILE}
    fi
    exit 1
}

# *************************************************************************** #
# Function: issue_command                                                     #
#                                                                             #
# Purpose: Print a command and execute it too.                                #
#                                                                             #
# Programmer: Brad Whitlock,                                                  #
# Date: Tue Feb 28 17:04:43 PST 2012                                          #
#                                                                             #
# Modifications:                                                              #
#
# *************************************************************************** #

function issue_command
{
    echo "$@"
    "$@"
    return $?
}

# *************************************************************************** #
# Function: add_extra_commandline_args                                        #
#                                                                             #
# Purpose: Allows modules to add extra arguments to VisIt                     #
#                                                                             #
# Programmer: Hari Krishnan,                                                  #
# Date: Thu Dec 15 14:38:36 PST 2011                                          #
#                                                                             #
# Modifications:                                                              #
#   Eric Brugger, Wed Jan 18 08:17:48 PST 2012                                #
#   I re-enabled the code that replaces dashes with underscores in the        #
#   name of the enable function.                                              #
#                                                                             #
# *************************************************************************** #
#global argument list for extra args..
declare -a extra_commandline_args
export EXTRA_COMMANDLINE_ARG_CALL=""

function add_extra_commandline_args
{

    if [[ $# != 4 ]]; then
        echo "extra command line usage requires 4 parameters"
        return
    fi

    #replace all occurrences of "-" with "_"
    local enable_func="bv_$1_${2//-/_}"

    #check if function exists..
    #maybe this should be moved to build_visit rather than here..
    #in case some bash consoles don't have declare -F capabilities?
    declare -F "$enable_func" &>/dev/null || errorFunc "function pointer $enable_func not found"

    #add parameters..
    for f in "$@"; do
        extra_commandline_args[${#extra_commandline_args[*]}]="$f"
    done

    #add function pointer..
    extra_commandline_args[${#extra_commandline_args[*]}]="$enable_func"
}

# *************************************************************************** 
#  Modifications: 
#    Kathleen Biagas, Monday May 12, 2025
#    Combined verify_required_module_exists and verify_optional_module_exists
#    into one method, verify_module_exists, to reduce code duplication
#                                                                            
# *************************************************************************** 

function verify_module_exists
{
    local alib=$1
    #check if required functions exist..
    declare -F "bv_${alib}_enable" &>/dev/null || errorFunc "${alib} enable not found"
    declare -F "bv_${alib}_disable" &>/dev/null || errorFunc "${alib} disable not found"
    declare -F "bv_${alib}_initialize" &>/dev/null || errorFunc "${alib} initialize not found"
    declare -F "bv_${alib}_info" &>/dev/null || errorFunc "${alib} info not found"
    declare -F "bv_${alib}_ensure" &>/dev/null || errorFunc "${alib} ensure not found"
    declare -F "bv_${alib}_build" &>/dev/null || errorFunc "${alib} build not found"
    declare -F "bv_${alib}_depends_on" &>/dev/null || errorFunc "${alib} depends_on not found"
    declare -F "bv_${alib}_print" &>/dev/null || errorFunc "${alib} print not found"
    declare -F "bv_${alib}_print_usage" &>/dev/null || errorFunc "${alib} print_usage not found"
    declare -F "bv_${alib}_is_installed" &>/dev/null || errorFunc "${alib} is_installed not found"
    declare -F "bv_${alib}_is_enabled" &>/dev/null || errorFunc "${alib} is_enabled not found"
}


# *************************************************************************** #
# Function: uncompress_untar
#                                                                             #
# Purpose: Uncompress and untar the file, checking if GNU tar can be used.    #
#                                                                             #
# Programmer: Thomas R. Treadway                                              #
# Date: Tue May 15 16:48:01 PDT 2007                                          #
#                                                                             #
# *************************************************************************** #

function uncompress_untar
{
    # Check if GNU tar
    if [[ $(echo $1 | egrep "\.gz$" ) != "" ]] ; then
        COMPRESSTYPE="gzip"
    elif [[ $(echo $1 | egrep "\.bz2$" ) != "" ]] ; then
        COMPRESSTYPE="bzip"
    elif [[ $(echo $1 | egrep "\.tgz$" ) != "" ]] ; then
        COMPRESSTYPE="targzip"
    elif [[ $(echo $1 | egrep "\.tar.gz$" ) != "" ]] ; then
        COMPRESSTYPE="targzip"
    elif [[ $(echo $1 | egrep "\.zip$" ) != "" ]] ; then
        COMPRESSTYPE="zip"
    elif [[ $(echo $1 | egrep "\.xz$" ) != "" ]] ; then
        COMPRESSTYPE="xz"
    else
        warn "unsupported decompression method"
        return 1
    fi
    TARVERSION=$($TAR --version >/dev/null 2>&1)
    if [[ $? == 0 ]] ; then
        case $COMPRESSTYPE in
            gzip|targzip) $TAR zxf $1;;
            bzip) $TAR jxf $1;;
            zip) unzip $1;;
            xz) $TAR xf $1;;
        esac

        if [[ $? != 0 ]]; then
            warn "error decompressing $1"
            return 1
        fi

    else
        case $COMPRESSTYPE in
            gzip)
                gunzip $1
                $TAR xf ${1%.gz}
                ;;
            targzip)
                gunzip $1
                $TAR xf "${1%.tgz}.tar"
                ;;
            bzip)
                bunzip2 $1
                $TAR xf ${1%.bz2}
                ;;
            zip)
                unzip $1
                ;;
        esac

        if [[ $? != 0 ]]; then
            warn "error decompressing $1"
            return 1
        fi
    fi
}

# *************************************************************************** #
# Function: verify_checksum                                                   #
#                                                                             #
# Purpose: Verify the checksum of the given file                              #
#                                                                             #
#          verify_sha_checksum: checks sha (256,512)                          #
#          verfiy_checksum_by_lookup: pick which checksum method to use       #
#                                     based on if they are defined giving     #
#                                     preference to the strongest checksums.  #
#                                                                             #
# Programmer: Hari Krishnan                                                   #
#                                                                             #
# Modifications:                                                              #
#   Eric Brugger, Thu Apr 11 15:51:25 PDT 2019                                #
#   Modified verify_checksum_by_lookup to also check that the checksum is     #
#   not blank in addition to being defined before using it.                   #
#                                                                             #
#   Cyrus Harrison, Thu, Jan 25, 2024  9:35:18 PM                             #
#   Removed md5 logic, standrize on sha256                                    #
# *************************************************************************** #

function verify_sha_checksum
{
    checksum_algo=$1
    checksum=$2
    dfile=$3

    tmp=`which shasum`
    if [[ $? != 0 ]]; then
        info "could not find shasum, disabling check"
        return 0
    fi

    if [[ $checksum_algo == 512 ]]; then
        tmp=`shasum -a $checksum_algo $dfile | tr ' ' '\n' | grep '^[0-9a-f]\{128\}'`
    else
        tmp=`shasum -a $checksum_algo $dfile | tr ' ' '\n' | grep '^[0-9a-f]\{64\}'`
    fi
    if [[ "$tmp" == "$checksum" ]]; then
        info "verified"
        return 0
    else
        info "shasum -a $checksum_algo failed: looking for $checksum got $tmp"
        return 1
    fi

    info "shasum does not support $checksum_algo, check disabled"
    return 0
}

function verify_checksum
{
    checksum_type=$1
    checksum=$2
    dfile=$3

    info "verifying $checksum_type checksum $checksum for $dfile . . ."

    if [[ $checksum_type = "SHA256" ]]; then
        verify_sha_checksum 256 $checksum $dfile
        return $?
    fi

    #since this is an optional check, all cases should pass if it gets here..
    info "checksum string not SHA256, check disabled"
    return 0
}

function verify_checksum_by_lookup
{
    dlfile=$(basename $1) # the downloaded file name

    # search for all shell vars with name of the form XXX_FILE defined
    # that have a value that is this file. The +-o posix stuff is to cull
    # out function names and definitions from the search
    for var in $(set -o posix; set | grep _FILE=; set +o posix); do
        var=$(echo $var | cut -d '=' -f1)
        if [[ ${!var} = $dlfile ]]; then
            varbase=$(echo $var | sed -e 's/_FILE$//')
            sha256_varname=${varbase}_SHA256_CHECKSUM
            if [ ! -z ${!sha256_varname} ]; then
                verify_checksum SHA256 ${!sha256_varname} $dlfile
                return $?
            fi
        fi
    done

    # since this is an optional check, all cases should pass if it gets here.
    info "unable to find a SHA256 checksum associated with $dlfile; check disabled"
    return 0
}

# *************************************************************************** #
# Function: download_file                                                     #
#                                                                             #
# Purpose: Downloads a file using wget and show a dialog screen.              #
#                                                                             #
# Programmer: Brad Whitlock,                                                  #
# Date: Thu Apr 5 14:38:36 PST 2007                                           #
#                                                                             #
# Modifications:                                                              #
#                                                                             #
#   Hank Childs, Mon Oct 15 15:55:22 PDT 2007                                 #
#   Fail gracefully if wget is not available.                                 #
#                                                                             #
#   Thomas R. Treadway, Tue Nov 27 16:37:21 PST 2007                          #
#   Deal with LLNL's invalid certificates                                     #
#                                                                             #
#   Cyrus Harrison, Mon Nov 17 16:22:54 PST 2008                              #
#   Check return value of svn cat or download for errors. Clean up a          #
#   partially downloaded file.                                                #
#                                                                             #
#   Hank Childs, Fri Dec 12 09:28:35 PST 2008                                 #
#   Add special logic for Ice-T.                                              #
#                                                                             #
#   Mark C. Miller, Thu Feb 19 09:16:46 PST 2009                              #
#   Added argument to specify a download_path. Removed special IceT coding.   #
#                                                                             #
#   Mark C. Miller, Thu Feb 19 12:21:55 PST 2009                              #
#   Changed to support multiple sites as well as default visit places.        #
#                                                                             #
#   Cyrus Harrison, Thu Feb 19 12:21:55 PST 2009                              #
#   Fixed problem where if a download path was given, svn mode was skipped    #
#                                                                             #
#   Cyrus Harrison, Thu Apr  9 19:21:13 PDT 2009                              #
#   Applied patch from Rick Wagner to fix curl downloads on OSX.              #
#                                                                             #
#   Mark C. Miller, Wed Feb  3 09:47:52 PST 2010                              #
#   Made it fall back to anon svn checkout                                    #
#                                                                             #
#   Eric Brugger, Mon Jan 10 16:00:13 PST 2011                                #
#   I made it always fall back to anonymous svn checkout.                     #
#                                                                             #
#   Eric Brugger, Tue Jul 19 10:19:50 PDT 2011                                #
#   I made it use the anonymous svn site as the fallback download site        #
#   instead of llnl's web site.                                               #
#                                                                             #
#   Eric Brugger, Fri Feb  1 14:56:58 PST 2019                                #
#   I modified it to work post git transition.                                #
#                                                                             #
#   Alister Maguire, Thu Jan  2 11:45:44 MST 2020                             #
#   Added download attempt for links that exclude the file name.              #
#                                                                             #
#   Eric Brugger, Wed Jan 29 09:52:20 PST 2020                                #
#   I modified the routine to download the visit tar file and third party     #
#   libraries from github.                                                    #
#                                                                             #
#   Kathleen Biagas, Monday May 12, 2025                                      #
#   Return early if file to be downloaded is already present.                 #
# *************************************************************************** #

function download_file
{
    # $1 is the file name to download
    # $2...$* [OPTIONAL] list of sites to obtain the file from

    typeset dfile=$1

    if [[ -e ${dfile} ]] ; then
        info "$dfile already downloaded."
        return
    fi
    info "Downloading $dfile . . ."
    shift

    # If the visit source code is requested, handle that now.
    site="${visitroot}v${VISIT_VERSION}"
    if [[ "$dfile" == "$VISIT_FILE" ]] ; then
        try_download_file $site/$dfile $dfile
        if [[ $? == 0 ]] ; then
            return 0
        fi
    fi

    # It must be a third party library, handle that now.
    #
    # First try GitHub. We only update the third party libraries when
    # doing a major release, so the patch is always 0. The fancy
    # parsing below grabs the major and minor version numbers.
    IFS="." read -r -a vers <<< "$VISIT_VERSION"
    major=${vers[0]}
    minor=${vers[1]}
    site="${thirdpartyroot}v${major}.${minor}.0"
    try_download_file $site/$dfile $dfile
    if [[ $? == 0 ]] ; then
        return 0
    fi

    # Now try the various places listed.
    if [[ "$1" != "" ]] ; then
        for site in $* ; do
            # check if we have a google shortened url that won't accept
            # the actual file name (we need this for mfem's urls)
            if [[ $site == *goo.gl* ]] ; then
                try_download_file_from_shortened_url $site $dfile
                if [[ $? == 0 ]] ; then
                    return 0
                fi
            else
                try_download_file $site/$dfile $dfile
                if [[ $? == 0 ]] ; then
                    return 0
                else
                    # Some download links exclude the file name.
                    try_download_file_from_shortened_url $site $dfile
                    if [[ $? == 0 ]] ; then
                        return 0
                    fi
                fi
            fi
        done
    fi

    # if all else has failed, and running develop version of build_visit,
    # then also check the master repo.
    if [[ "$TRUNK_BUILD" == "yes" ]]; then
        site="${thirdpartyroot_dev}"
        try_download_file $site/$dfile $dfile
        if [[ $? == 0 ]] ; then
            return 0
        fi
    fi

    return 1
}

# ***************************************************************************
# Function: try_download_file
#
# Purpose: DONT USE THIS FUNCTION. USE download_file.
# Downloads a file using wget or curl.
#
# Programmer: Refactored from other sources (Mark C. Miller)
# Creation: February 19, 2009
#
#   Cyrus Harrison, Tue 24 Mar 13:44:31 PST 2009
#   As an extra guard, check that the downloaded file actually exisits.
#   (Firewalls can cause strange files to be created.)
#
#   Cyrus Harrison, Thu Apr  9 19:21:13 PDT 2009
#   Applied patch from Rick Wagner to fix curl downloads on OSX.
#
#   Tom Fogal, Sun Jul 26 17:19:26 MDT 2009
#   Follow redirects.  Don't use a second argument.
#
#   Gunther H. Weber, Fri Oct 23 13:17:34 PDT 2009
#   Specify explicit path to system curl so that we do not use another
#   version without SSL support
#
#   Mark C. Miller, Thu Mar 21 10:39:14 PDT 2024
#   Use trap to prevent interruptions to downloads which can leave
#   corrupted tarballs.
# ***************************************************************************

function try_download_file
{
    no_download_tool=0

    trap '' SIGINT SIGTERM SIGHUP SIGQUIT

    if [[ "$OPSYS" == "Darwin" ]]; then
        # MaxOS X comes with curl
        /usr/bin/curl -ksfLO $1
    else
        check_wget
        if [[ $? != 0 ]] ; then
            no_download_tool=1
        else
            wget $WGET_OPTS -o /dev/null $1
        fi
    fi

    trap - SIGINT SIGTERM SIGHUP SIGQUIT

    if [[ ${no_download_tool} -ne 0 ]]; then
        error "Need to download $1, but \
               cannot locate a download utility to do so."
    fi

    verify_checksum_by_lookup `basename $1`
    if [[ $? == 0 && -e `basename $1` ]] ; then
        info "Download succeeded: $1"
        return 0
    else
        warn "Download attempt failed: $1"
        rm -f `basename $1`
        return 1
    fi

}

# ***************************************************************************
# Function: try_download_file_from_shortened_url
#
# Purpose: DONT USE THIS FUNCTION. USE download_file.
#
# New variant of try_download_file, downloads a file using wget or curl
# using an explicit file name. This is necessary for shortened urls.
#
# Programmer: Cyrus Harrison
# Creation: June 1, 2016
#
# ***************************************************************************

function try_download_file_from_shortened_url
{
    if [[ "$OPSYS" == "Darwin" ]]; then
        # MaxOS X comes with curl
        /usr/bin/curl -o $2 -ksfLO $1
    else
        check_wget
        if [[ $? != 0 ]] ; then
            error "Need to download $1, but \
                   cannot locate the wget utility to do so."
        fi
        wget $WGET_OPTS -O $2 -o /dev/null $1
    fi

    verify_checksum_by_lookup $2
    if [[ $? == 0 && -e $2 ]] ; then
        info "Download succeeded: $1"
        return 0
    else
        warn "Download attempt failed: $1"
        rm -f $2
        return 1
    fi
}



# *************************************************************************** #
# Function: check_git_client                                                  #
#                                                                             #
# Purpose: Helper that checks if a git client is available.                    #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date:  Mon Nov 17 14:52:37 PST 2008                                         #
#                                                                             #
# Modifications:
#   Eric Brugger, Fri Feb  1 14:56:58 PST 2019
#   I modified it to work post git transition.
#
# *************************************************************************** #

function check_git_client
{
    # check for git client
    GIT_CLIENT=$(which git)
    if [[ $GIT_CLIENT == "" ]] ; then
        return 1
    fi
    return 0
}

# *************************************************************************** #
# Function: check_wget                                                        #
#                                                                             #
# Purpose: Helper that checks if a wget is available.                         #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date:  Mon Nov 17 14:52:37 PST 2008                                         #
#                                                                             #
# *************************************************************************** #

function check_wget
{
    WGET_CLIENT=$(which wget)
    # check for wget
    if [[ $WGET_CLIENT == "" ]] ; then
        return 1
    fi
    return 0
}

# *************************************************************************** #
# Function: check_if_installed                                                #
#                                                                             #
# Purpose: Checks if $VISITDIR/$1/$2/$VISITARCH exists.                       #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date: Wed Nov 19 07:31:08 PST 2008                                          #
#                                                                             #
# *************************************************************************** #
function check_if_installed
{
    BUILD_NAME=$1
    BUILD_VERSION=""

    if [[ $# == 2 ]]; then
        BUILD_VERSION=$2
    fi

    if [[ $BUILD_VERSION != "" ]]; then
        INSTALL_DIR=$VISITDIR/$BUILD_NAME/$BUILD_VERSION/$VISITARCH
    else
        INSTALL_DIR=$VISITDIR/$BUILD_NAME/$VISITARCH
    fi

    if [[ -d ${INSTALL_DIR} ]] ; then
        return 0
    else
        return 1
    fi
}

# *************************************************************************** #
# Function: ensure_built_or_ready_component                                   #
#                                                                             #
# Purpose: Helper that checks if libs matching 'PATTERN' are installed.       #
# If not,  ensures the source tarball is downloaded.                          #
#                                                                             #
# Programmer: Kathleen Biagas                                                 #
# Date: Wed Mar 19 2025                                                       #
#                                                                             #
# *************************************************************************** #
function ensure_built_or_ready_component
{
    echo "ensure_built_or_ready_component $3"
    BUILD_NAME=$1
    BUILD_VERSION=$2
    SOURCE_FILE=$3
    PATTERN=$4
    DOWNLOAD_PATH=$5

    INSTALL_DIR=$VISITDIR/$BUILD_NAME/$BUILD_VERSION/$VISITARCH

    HAVE_TARBALL="NO"
    COMPONENT_INSTALLED="NO"

    if [[ -d ${INSTALL_DIR} ]] ; then
        if [[ -f ${PATTERN[0]} ]] ; then
            echo "found component for ${PATTERN}"
            COMPONENT_INSTALLED="YES"
        else
            echo "did not find component for ${PATTERN}"
        fi
    else
        echo "INSTALL_DIR does not exist: ${INSTALL_DIR}"
    fi

    if [[ -e ${SOURCE_FILE%.gz} || -e ${SOURCE_FILE} ]] ; then
        echo "Have tarball: $SOURCE_FILE}"
        HAVE_TARBALL="YES"
    fi

    if [[ "$COMPONENT_INSTALLED" == "NO" && "$HAVE_TARBALL" == "NO" ]] ; then
        echo "downloading ${SOURCE_FILE}"
        download_file ${SOURCE_FILE} ${DOWNLOAD_PATH}
        if [[ $? != 0 ]] ; then
            warn "Error: Cannot obtain source for $BUILD_NAME."
            return 1
        fi
    fi

    return 0
}

# *************************************************************************** #
# Function: ensure_built_or_ready                                             #
#                                                                             #
# Purpose: Helper that checks for proper installed version. If this doesn't   #
#  exist, makes sure the source file is avalaible for building.               #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date: Fri Nov 14 08:23:26 PST 2008                                          #
#                                                                             #
# *************************************************************************** #
function ensure_built_or_ready
{
    BUILD_NAME=$1
    BUILD_VERSION=$2
    INSTALL_DIR=$VISITDIR/$BUILD_NAME/$BUILD_VERSION/$VISITARCH
    BUILD_DIR=$3
    SRC_FILE=$4
    DOWNLOAD_PATH=$5

    info "Checking for ${BUILD_NAME}-${BUILD_VERSION}"

    ALREADY_INSTALLED="NO"
    HAVE_TARBALL="NO"

    check_if_installed $BUILD_NAME $BUILD_VERSION
    if [[ $? == 0 || -d $BUILD_DIR ]] ; then
        ALREADY_INSTALLED="YES"
    fi
    if [[ -e ${SRC_FILE%.gz} || -e ${SRC_FILE} ]] ; then
        HAVE_TARBALL="YES"
    fi

    if [[ "$ALREADY_INSTALLED" == "NO" && "$HAVE_TARBALL" == "NO" ]] ; then
        download_file ${SRC_FILE} ${DOWNLOAD_PATH}
        if [[ $? != 0 ]] ; then
            warn "Error: Cannot obtain source for $BUILD_NAME."
            return 1
        fi
    fi
    return 0
}


# *************************************************************************** #
# Function: prepare_build_dir                                                 #
#                                                                             #
# Purpose: Helper that prepares a build directory from a src file.            #
#                                                                             #
# Returns:                                                                    #
#          -1 on failure                                                      #
#           0 for success without untar                                       #
#           1 for success with untar                                          #
#           2 for failure with checksum                                       #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date: Thu Nov 13 09:28:26 PST 2008                                          #
#                                                                             #
# Modifications:                                                              #
#                                                                             #
#   Paul Selby, Wed  4 Feb 17:25:22 GMT 2015                                  #
#   Fixed typo which prevented verify_checksum being called                   #
# *************************************************************************** #
function prepare_build_dir
{
    echo "prepare_build_dir:" $1 $2
    BUILD_DIR=$1
    SRC_FILE=$2

    #optional
    CHECKSUM_TYPE=$3
    CHECKSUM_VALUE=$4

    untarred_src=0
    if [[ -d ${BUILD_DIR} ]] ; then
        info "Found ${BUILD_DIR} . . ."
        untarred_src=0
    elif [[ -f ${SRC_FILE} ]] ; then
        if [[ $CHECKSUM_VALUE != "" && $CHECKSUM_TYPE != "" ]]; then
            verify_checksum $CHECKSUM_TYPE $CHECKSUM_VALUE ${SRC_FILE}
            if [[ $? != 0 ]]; then
                return 2
            fi
        fi
        info "Unzipping/Untarring ${SRC_FILE} . . ."
        uncompress_untar ${SRC_FILE}
        untarred_src=1
        if [[ $? != 0 ]] ; then
            warn \
                "Unable to untar $SRC_FILE  Corrupted file or out of space on device?"
            return -1
        fi
    elif [[ -f ${SRC_FILE%.*} ]] ; then
        info "Untarring ${SRC_FILE%.*} . . ."
        $TAR xf ${SRC_FILE%.*}
        untarred_src=1
        if [[ $? != 0 ]] ; then
            warn \
                "Unable to untar ${SRC_FILE%.*}.  Corrupted file or out of space on device?"
            return -1
        fi
    fi

    return $untarred_src
}

# *************************************************************************** 
# check_3rdparty
# --------------------------------------------------------------------------- 
# This function will check to make sure that all of the necessary files
# for the third party libraries actually exist.
#
# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Combined 'check_required_3rdparty' and 'check_optional_3rdparty' into one
#   function to reduce code duplication.
#
#   Kathleen Biagas, Friday May 16, 2025
#   Check for enabled status and continue loop without further processing
#   if lib is disabled.
#
# ****************************************************************************

function check_3rdparty
{
    info "Checking for files . . ."

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        groupname=${grouplibs_name[$bv_i]}
        info "Checking ${groupname} libraries"
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            $"bv_${lib}_is_enabled"

            #if not enabled then skip
            if [[ $? == 0 ]]; then
                continue
            fi

            ensure="bv_${lib}_ensure"
            $ensure
            if [[ $? != 0 ]] ; then
                return 1
            fi
        done
    done

    return 0
}


# *************************************************************************** #
#                         Function 1.0, check_files                           #
# --------------------------------------------------------------------------- #
# This function will check to make sure that all of the necessary files       #
# actually exist.                                                             #
# *************************************************************************** #

function check_files
{
    check_3rdparty
    if [[ $? != 0 ]]; then
        return 1
    fi

    if [[ "$DO_VISIT" == "yes" ]] ;  then
        bv_visit_ensure_built_or_ready
        if [[ $? != 0 ]]; then
            return 1
        fi
    fi

    return 0
}


# *************************************************************************** #
#                          process_parallel_ldflags                           #
# --------------------------------------------------------------------------- #
# This routine processes the PAR_LIBS variable into three other variables.    #
#   PAR_LINKER_FLAGS :        Any linker flags that aren't libraries (don't   #
#                             start with "-l".                                #
#   PAR_LIBRARY_NAMES:        The library names with the "-l" stripped out.   #
#   PAR_LIBRARY_LINKER_FLAGS: The library names with the "-l".                #
# *************************************************************************** #
function process_parallel_ldflags
{
    export PAR_LINKER_FLAGS=""
    export PAR_LIBRARY_NAMES=""
    export PAR_LIBRARY_LINKER_FLAGS=""

    for arg in $1; do
        pos=`echo "$arg" | awk '{ printf "%d", index($1,"-l"); }'`
        if [[ "$pos" != "0" ]] ; then
            # We have a library.
            # Add it to the running list of library names with the "-l".
            export PAR_LIBRARY_LINKER_FLAGS="$PAR_LIBRARY_LINKER_FLAGS$arg "
            # Remove the "-l" prefix & add it to the running list of library
            # names without the "-l".
            LIB_NAME=${arg#-l}
            export PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES$LIB_NAME "
        else
            # we have a linker flag, add it to the running list.
            export PAR_LINKER_FLAGS="$PAR_LINKER_FLAGS$arg "
        fi
    done
}

# *************************************************************************** #
#                         Function 2.1, check_parallel                        #
# --------------------------------------------------------------------------- #
# This function will check to make sure that parallel options have been setup #
# if we're going to build a parallel version of VisIt.                        #
# *************************************************************************** #
function check_parallel
{
    rv=0

    if [[ "$DO_MPICH" == "yes" && "$parallel" == "no" ]] ; then
        parallel="yes"
    fi

    # If we are using PAR_LIBS, call helper to split this into:
    # PAR_LINKER_FLAGS, PAR_LIBRARY_NAMES & PAR_LIBRARY_LINKER_FLAGS
    process_parallel_ldflags "$PAR_LIBS"

    # If we are using PAR_INCLUDE, store the directory name without the
    # "-I"
    export PAR_INCLUDE_PATH=`echo "$PAR_INCLUDE" | sed "s/-I//"`

    #
    # Parallelization
    #
    if [[ "$parallel" == "yes" ]] ; then

        #
        # VisIt's cmake build can obtain all necessary MPI flags from
        # a MPI compiler wrapper.
        # Check if PAR_COMPILER is set & if so use that.
        #
        export VISIT_MPI_COMPILER=""
        export VISIT_MPI_COMPILER_CXX=""
        if [[ "$PAR_COMPILER" != "" ]] ; then
            export VISIT_MPI_COMPILER="$PAR_COMPILER"
            info \
                "Configuring with mpi compiler wrapper: $VISIT_MPI_COMPILER"
            if [[ "$PAR_COMPILER_CXX" != "" ]] ; then
                export VISIT_MPI_COMPILER_CXX="$PAR_COMPILER_CXX"
                info \
                    "Configuring with mpi c++ compiler wrapper: $VISIT_MPI_COMPILER_CXX"
            fi
            return 0
        fi

        #
        # VisIt's build_visit can obtain all necessary MPI flags from
        # bv_mpich. If we are building mpich and the user
        # did not set PAR_LIBS or PAR_INCLUDE we are done.
        #
        if [[ "$DO_MPICH" == "yes" && "$PAR_INCLUDE" == "" && "$PAR_LIBS" == "" && "$MPIWRAPPER" == "" ]] ; then

            export MPICH_COMPILER="${VISITDIR}/mpich/$MPICH_VERSION/${VISITARCH}/bin/mpicc"
            export MPICH_COMPILER_CXX="${VISITDIR}/mpich/$MPICH_VERSION/${VISITARCH}/bin/mpic++"
            export VISIT_MPI_COMPILER="$MPICH_COMPILER"
            export VISIT_MPI_COMPILER_CXX="$MPICH_COMPILER_CXX"
            export PAR_COMPILER="$MPICH_COMPILER"
            export PAR_COMPILER_CXX="$MPICH_COMPILER_CXX"
            export PAR_INCLUDE="-I${VISITDIR}/mpich/$MPICH_VERSION/${VISITARCH}/include"
            info  "Configuring parallel with mpich build: "
            info  "  PAR_COMPILER: $PAR_COMPILER"
            info  "  PAR_COMPILER_CXX: $PAR_COMPILER_CXX"
            info  "  PAR_INCLUDE: $PAR_INCLUDE"
            return 0
        fi

        #
        # Check the environment that mpicc would set up as a first stab.
        # Since VisIt currently only ever uses MPI's C interface, we need
        # only the information to link to MPI's implementation of its C
        # interface. So, although VisIt is largely a C++ code, it is fine
        # and correct to utilize an MPI C compiler here.
        #
        MPICC_CPPFLAGS=""
        MPICC_LDFLAGS=""
        MPIWRAPPER=$(which mpicc)
        if [[ "${MPIWRAPPER#no }" != "${MPIWRAPPER}" ]] ; then
            MPIWRAPPER=""
        fi
        if [[ "$MPIWRAPPER" == "" ]] ; then
            if [[ "$CRAY_MPICH_DIR" != "" ]] ; then
                warn "Unable to find mpicc..."
            fi
        fi

        #
        # VisIt's cmake build can obtain all necessary MPI flags from
        # a MPI compiler wrapper. If we have found one & the user
        # did not set PAR_LIBS or PAR_INCLUDE we are done.
        #
        if [[ "$PAR_INCLUDE" == "" && "$PAR_LIBS" == "" && "$MPIWRAPPER" != "" ]] ; then
            export VISIT_MPI_COMPILER=$MPIWRAPPER
            export PAR_COMPILER=$MPIWRAPPER
            info \
                "Configuring with mpi compiler wrapper: $VISIT_MPI_COMPILER"
            return 0
        fi

        #
        # VisIt's build_visit can obtain all necessary MPI flags from
        # bv_mpich. If we are building mpich and the user
        # did not set PAR_LIBS or PAR_INCLUDE we are done.
        #
        if [[ "$DO_MPICH" == "yes" && "$PAR_INCLUDE" == "" && "$PAR_LIBS" == "" && "$MPIWRAPPER" == "" ]] ; then

            export MPICH_COMPILER="${VISITDIR}/mpich/$MPICH_VERSION/${VISITARCH}/bin/mpicc"
            export VISIT_MPI_COMPILER="$MPICH_COMPILER"
            export PAR_COMPILER="$MPICH_COMPILER"
            info \
                "Configuring with build mpich: $MPICH_COMPILER"
            return 0
        fi

        #
        # Try and use the Cray wrapper compiler to get MPI options.
        #
        if [[ "$CRAY_MPICH_DIR" != "" ]] ; then
             # NOTE: Unload darshan and cray-libsci. Otherwise keep the
             #       programming environment that is in effect.
             CCOUT=$(module unload darshan; module unload cray-libsci; CC --cray-print-opts=all)
             ingroup="no"
             arg_rpath=""
             for arg in $CCOUT ;
             do
                 # NOTE: adding the -Wl,-Bstatic/-Wl,-Bdynamic around the group is
                 # a workaround to linking with the "darshan" libraries that come
                 # in via CCOUT on cori.nersc.gov
                 if [[ "$arg" == "-Wl,--start-group" ]] ; then
                     ingroup="yes"
                     if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
                         PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES $arg"
                     else
                         PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES -Wl,-Bstatic $arg"
                     fi
                 elif [[ "$arg" == "-Wl,--end-group" ]] ; then
                     ingroup="no"
                     if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
                         PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES $arg"
                     else
                         PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES -Wl,-Bdynamic $arg"
                     fi
                 elif [[ "$ingroup" == "yes" ]] ; then
                     PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES $arg"
                 else
                     A2=$(echo $arg | cut -c 1-2)
                     A3=$(echo $arg | cut -c 1-3)
                     if [[ "$A2" == "-I" ]] ; then
                         PAR_INCLUDE="$PAR_INCLUDE $arg"
                     elif [[ "$A2" == "-L" ]] ; then
                         arg_rpath="$arg_rpath -Wl,-rpath,$(echo $arg | cut -c 3-)"
                         PAR_LINKER_FLAGS="$PAR_LINKER_FLAGS $arg"
                     elif [[ "$A3" == "-Wl" ]] ; then
                         PAR_LINKER_FLAGS="$PAR_LINKER_FLAGS $arg"
                     elif [[ "$A2" == "-l" ]] ; then
                         PAR_LIBRARY_NAMES="$PAR_LIBRARY_NAMES $(echo $arg | cut -c 3-)"
                     fi
                 fi
             done
             if [[ "$DO_STATIC_BUILD" == "no" ]] ; then
                 PAR_LINKER_FLAGS="$PAR_LINKER_FLAGS$arg_rpath"
             fi
        fi

        # The script pretty much assumes that you *must* have some flags
        # and libs to do a parallel build.  If that is *not* true,
        # i.e. mpi.h is in your include path, then, congratulations,
        # you are working on a better configured system than I have
        # ever encountered.
        if [[ "$PAR_INCLUDE" == "" || "$PAR_LIBRARY_NAMES" == "" || "$PAR_LINKER_FLAGS" == "" ]] ; then
            warn \
                        "To configure parallel VisIt you must satisfy one of the following conditions:
    The PAR_COMPILER env var provides a path to a mpi compiler wrapper (such as mpicc).
    A mpi compiler wrapper (such as mpicc) to exists in your path.
    The PAR_INCLUDE & PAR_LIBS env vars provide necessary CXX & LDFLAGS to use mpi.

 To build ICE-T the PAR_INCLUDE env var must provide the include path to your mpi headers.
    "
            rv=1
        fi

        if [[ $rv != 0 ]] ; then
            return 1
        fi
    fi

    return 0
}

# *************************************************************************** #
#                          Function 9, build_hostconf                         #
#                                                                             #
# Mark C. Miller, Wed Oct 27 19:29:19 PDT 2010                                #
# Adjusted ordering of database lib variables to ensure LIBDEP gets processed #
# correctly. Added comments to host conf file regarding ordering issue.       #
#                                                                             #
# Kathleen Bonnell, Wed Feb 16 08:35:40 PST 2011                              #
# Remove setting of CMAKE_BUILD_TYPE                                          #
#                                                                             #
# Kathleen Biagas, Mon Aug 8 08:12:37 MST 2011                                #
# Use FILEPATH type for compilers, STRING type for libdep.                    #
# *************************************************************************** #
hostconf_library_success=""
function hostconf_library
{
    local build_lib=$1
    local depends_on=""

    # if already in success list then ignore..
    if [[ "$hostconf_library_success" == *$build_lib* ]]; then
        return
    fi

    depends_on=$("bv_${build_lib}_depends_on")

    #replace commas with spaces if there are any..
    depends_on=${depends_on//,/ }

    for depend_lib in `echo $depends_on`;
    do
        hostconf_library $depend_lib
    done

    #build ..
    $"bv_${build_lib}_host_profile"
    hostconf_library_success="${hostconf_library_success} ${build_lib}"
}

# *************************************************************************** #
# Function: build_hostconf                                                    #
#                                                                             #
# Purpose: builds the config-site file for this host                          #
#                                                                             #
# Modifications:                                                              #
#   Kathleen Biagas, Thu Mar 14 11:28:38 PDT 2019                             #
#   Don't put the C or CXX OPT_FLAGS in the host file. These will be handled  #
#   by CMake when CMAKE_BUILD_TYPE is selected.                               #
#                                                                             #
#   Kathleen Biagas, Monday May 12, 2025                                      #
#   Loop over groups when writing individual libs host conf instead of        #
#   duplicating logic for reqlibs and optlibs.                                #
#                                                                             #
# *************************************************************************** #

function build_hostconf
{
    #
    # Set up environment variables for the configure step.
    #
    PARFLAGS=""
    if [[ "$parallel" == "yes" ]] ; then
       PARFLAGS="--enable-parallel"
    fi

    #
    # Set up the config-site file, which gives configure the information it
    # needs about the third party libraries.

    export HOSTCONF="$(hostname).cmake"

    if [[ "${VISIT_HOSTNAME}" != "" ]]; then
        info "VISIT_HOSTNAME env variable found: Using ${VISIT_HOSTNAME}.cmake"
        HOSTCONF="${VISIT_HOSTNAME}.cmake"
    fi

    if [[ "${EXTERNAL_HOSTNAME}" != "" ]]; then
        info "External Hostname variable found: Using ${EXTERNAL_HOSTNAME}"
        HOSTCONF="${EXTERNAL_HOSTNAME}"
    fi

    info "Creating $HOSTCONF"

    # First line of config-site file provides a hint to the location
    # of cmake.

    THIRD_PARTY_ABS_PATH=$(pushd $THIRD_PARTY_PATH >/dev/null 2>&1; pwd; popd >/dev/null 2>&1)
    if [[ "$CMAKE_INSTALL" != "" ]]; then
        echo "#$CMAKE_INSTALL/cmake" > $HOSTCONF
    else
        echo "#$THIRD_PARTY_ABS_PATH/cmake/$CMAKE_VERSION/$VISITARCH/bin/cmake" > $HOSTCONF
    fi
    echo "##" >> $HOSTCONF
    echo "## $0 generated host.cmake" >> $HOSTCONF
    echo "## created: $(date)" >> $HOSTCONF
    echo "## system: $(uname -a)" >> $HOSTCONF
    echo "## by: $(whoami)" >> $HOSTCONF
    echo >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## Setup VISITHOME & VISITARCH variables." >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "SET(VISITHOME $VISITDIR)" >> $HOSTCONF
    echo "SET(VISITARCH $VISITARCH)" >> $HOSTCONF
    echo >> $HOSTCONF

#####
    echo "## Compiler flags." >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "VISIT_OPTION_DEFAULT(VISIT_C_COMPILER $C_COMPILER TYPE FILEPATH)">> $HOSTCONF
    echo "VISIT_OPTION_DEFAULT(VISIT_CXX_COMPILER $CXX_COMPILER TYPE FILEPATH)" >> $HOSTCONF
    if [[ "$FC_COMPILER" != "" ]] ; then
        echo "VISIT_OPTION_DEFAULT(VISIT_FORTRAN_COMPILER $FC_COMPILER TYPE FILEPATH)" >> $HOSTCONF
    fi

    if [[ "$USE_VISIBILITY_HIDDEN" == "yes" ]] ; then
        echo "VISIT_OPTION_DEFAULT(VISIT_C_FLAGS \"$CFLAGS -fvisibility=hidden\" TYPE STRING)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_CXX_FLAGS \"$CXXFLAGS -fvisibility=hidden\" TYPE STRING)" >> $HOSTCONF
    else
        if test -n "$CFLAGS" ; then
            echo "VISIT_OPTION_DEFAULT(VISIT_C_FLAGS \"$CFLAGS\" TYPE STRING)" >> $HOSTCONF
        fi
        if test -n "$CXXFLAGS" ; then
            echo "VISIT_OPTION_DEFAULT(VISIT_CXX_FLAGS \"$CXXFLAGS\" TYPE STRING)" >> $HOSTCONF
        fi
    fi

    if [[ "$VISIT_INSTALL_PREFIX" != "" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## VisIt install location." >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(CMAKE_INSTALL_PREFIX $VISIT_INSTALL_PREFIX TYPE FILEPATH)" >> $HOSTCONF
    fi
    if [[ "$VISIT_INSTALL_NETWORK" != "" ]] ; then
        echo "VISIT_OPTION_DEFAULT(VISIT_INSTALL_PROFILES_TO_HOSTS \"$VISIT_INSTALL_NETWORK\" TYPE STRING)" >> $HOSTCONF
    fi

    if [[ "${DO_JAVA}" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## VisIt Java Option." >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_JAVA ON TYPE BOOL)" >> $HOSTCONF
    fi

    if [[ "$BUILD_VISIT_BGQ" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## BG/Q-specific settings" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "SET(CMAKE_CROSSCOMPILING    ON)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_USE_X            OFF TYPE BOOL)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_USE_GLEW         OFF TYPE BOOL)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_DISABLE_SELECT   ON  TYPE BOOL)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_USE_NOSPIN_BCAST OFF TYPE BOOL)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_OPENGL_DIR       \${VISITHOME}/mesa/$MESAGL_VERSION/\${VISITARCH})" >> $HOSTCONF
        echo "ADD_DEFINITIONS(-DVISIT_BLUE_GENE_Q)" >> $HOSTCONF
        echo >> $HOSTCONF
    fi

    if [[ "$parallel" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Parallel Build Setup." >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_PARALLEL ON TYPE BOOL)" >> $HOSTCONF
        # we either set an mpi wrapper compiler in the host conf
        if [[ "$VISIT_MPI_COMPILER" != "" ]] ; then
            if [[ "$BUILD_VISIT_BGQ" == "yes" ]] ; then
                echo "## (inserted by build_visit for BG/Q. Configuration as of 10/8/2014.)" >> $HOSTCONF
                echo "## (LC rolled back this ppcfloor configuration from V1R2M2 to V1R2M0 10/16/2014.)" >> $HOSTCONF
                echo "#SET(BLUEGENEQ /bgsys/drivers/ppcfloor)" >> $HOSTCONF
                echo "#VISIT_OPTION_DEFAULT(VISIT_PARALLEL ON TYPE BOOL)" >> $HOSTCONF
                echo "#VISIT_OPTION_DEFAULT(VISIT_MPI_CXX_FLAGS \"-I\${BLUEGENEQ} -I\${BLUEGENEQ}/comm/include -I\${BLUEGENEQ}/spi/include -I\${BLUEGENEQ}/spi/include/kernel/cnk\" TYPE STRING)" >> $HOSTCONF
                echo "#VISIT_OPTION_DEFAULT(VISIT_MPI_C_FLAGS   \"-I\${BLUEGENEQ} -I\${BLUEGENEQ}/comm/include -I\${BLUEGENEQ}/spi/include -I\${BLUEGENEQ}/spi/include/kernel/cnk\" TYPE STRING)" >> $HOSTCONF
                echo "#VISIT_OPTION_DEFAULT(VISIT_MPI_LD_FLAGS  \"-L\${BLUEGENEQ}/spi/lib -L\${BLUEGENEQ}/comm/lib -R/opt/ibmcmp/lib64/bg/bglib64\" TYPE STRING)" >> $HOSTCONF
                echo "#VISIT_OPTION_DEFAULT(VISIT_MPI_LIBS     mpich-xl opa-xl mpl-xl pami-gcc SPI SPI_cnk rt pthread stdc++ pthread TYPE STRING)" >> $HOSTCONF
                echo "" >> $HOSTCONF
                echo "## (inserted by build_visit for BG/Q. Configuration as of 10/15/2014.)" >> $HOSTCONF
                echo "SET(BLUEGENEQ /bgsys/drivers/V1R2M0/ppc64)" >> $HOSTCONF
                echo "VISIT_OPTION_DEFAULT(VISIT_MPI_CXX_FLAGS \"-I\${BLUEGENEQ} -I\${BLUEGENEQ}/comm/sys/include -I\${BLUEGENEQ}/spi/include -I\${BLUEGENEQ}/spi/include/kernel/cnk -I\${BLUEGENEQ}/comm/xl/include\" TYPE STRING)" >> $HOSTCONF
                echo "VISIT_OPTION_DEFAULT(VISIT_MPI_C_FLAGS   \"-I\${BLUEGENEQ} -I\${BLUEGENEQ}/comm/sys/include -I\${BLUEGENEQ}/spi/include -I\${BLUEGENEQ}/spi/include/kernel/cnk -I\${BLUEGENEQ}/comm/xl/include\" TYPE STRING)" >> $HOSTCONF
                echo "VISIT_OPTION_DEFAULT(VISIT_MPI_LD_FLAGS  \"-L\${BLUEGENEQ}/spi/lib -L\${BLUEGENEQ}/comm/sys/lib -L\${BLUEGENEQ}/spi/lib -L\${BLUEGENEQ}/comm/xl/lib -R/opt/ibmcmp/lib64/bg/bglib64\" TYPE STRING)" >> $HOSTCONF
                echo "VISIT_OPTION_DEFAULT(VISIT_MPI_LIBS     mpich opa mpl pami SPI SPI_cnk rt pthread stdc++ pthread TYPE STRING)" >> $HOSTCONF
            else
                echo "## (configured w/ mpi compiler wrapper)" >> $HOSTCONF
                echo "VISIT_OPTION_DEFAULT(VISIT_MPI_COMPILER $VISIT_MPI_COMPILER TYPE FILEPATH)"  >> $HOSTCONF
            fi
        else
            # or we just set the flags.
            echo "## (configured w/ user provided CXX (PAR_INCLUDE) & LDFLAGS (PAR_LIBS) flags)" \
             >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_MPI_C_FLAGS   \"$PAR_INCLUDE\" TYPE STRING)"     >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_MPI_CXX_FLAGS \"$PAR_INCLUDE\" TYPE STRING)"     >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_MPI_LD_FLAGS  \"$PAR_LINKER_FLAGS\" TYPE STRING)" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_MPI_LIBS        $PAR_LIBRARY_NAMES TYPE STRING)" >> $HOSTCONF
        fi
    fi

    if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Static build" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
        "VISIT_OPTION_DEFAULT(VISIT_STATIC ON TYPE BOOL)" >> $HOSTCONF
        if [[ "$CRAY_MPICH_DIR" != "" ]] ; then
            echo "# Force static executables on Cray to be 100% statically linked." >> $HOSTCONF
            echo "SET(VISIT_EXE_LINKER_FLAGS \"-static -static-libgcc -static-libstdc++ -pthread -Wl,-Bstatic\")" >> $HOSTCONF
        fi
    fi
    if [[ "$DO_SERVER_COMPONENTS_ONLY" == "yes" ]]; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Server components only" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
        "VISIT_OPTION_DEFAULT(VISIT_SERVER_COMPONENTS_ONLY ON TYPE BOOL)" >> $HOSTCONF
    fi
    if [[ "$DO_ENGINE_ONLY" == "yes" ]]; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Engine components only" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
        "VISIT_OPTION_DEFAULT(VISIT_ENGINE_ONLY ON TYPE BOOL)" >> $HOSTCONF
    fi

    if [[ "$DO_STATIC_BUILD" == "yes"  && $DO_OSMESA == "yes" ]] ; then
        if [[ "$DO_SERVER_COMPONENTS_ONLY" == "yes" || "$DO_ENGINE_ONLY" == "yes" ]] ; then
            # Turn off VisIt's use of X
            echo "VISIT_OPTION_DEFAULT(VISIT_USE_X OFF TYPE BOOL)" >> $HOSTCONF
        fi
    fi
    # Are we on Cray? We might need the socket relay.
    if [[ "$CRAY_MPICH_DIR" != "" ]] ; then
        echo "VISIT_OPTION_DEFAULT(VISIT_CREATE_SOCKET_RELAY_EXECUTABLE ON)" >> $HOSTCONF
    fi

    if [[ "$DO_XDB" == "yes" ]]; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## XDB" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
        "VISIT_OPTION_DEFAULT(VISIT_ENABLE_XDB ON TYPE BOOL)" >> $HOSTCONF
    fi

    echo >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## VisIt Thread Option" >> $HOSTCONF
    echo "##" >> $HOSTCONF
    if [[ "$DO_THREAD_BUILD" == "yes" ]] ; then
        echo "VISIT_OPTION_DEFAULT(VISIT_THREAD ON TYPE BOOL)" >> $HOSTCONF
    else
        echo "VISIT_OPTION_DEFAULT(VISIT_THREAD OFF TYPE BOOL)" >> $HOSTCONF
    fi

    if [[ "${DO_PARADIS}" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## VisIt paraDIS Option." >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_PARADIS ON TYPE BOOL)" >> $HOSTCONF
    fi

    echo >> $HOSTCONF
    echo \
"##############################################################" >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## Database reader plugin support libraries" >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## The HDF5 and NetCDF libraries must be first so that" >> $HOSTCONF
    echo "## their libdeps are defined for any plugins that need them." >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## For libraries with LIBDEP settings, order matters." >> $HOSTCONF
    echo "## Libraries with LIBDEP settings that depend on other" >> $HOSTCONF
    echo "## Library's LIBDEP settings must come after them." >> $HOSTCONF
    echo \
"##############################################################" >> $HOSTCONF

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            hostconf_library ${lib}
        done
    done

    echo >> $HOSTCONF

 #
 # Patch for Ubuntu 11.04
 #
 #if test -d "/usr/lib/x86_64-linux-gnu" ; then
 #    numLibs=$(ls -1 /usr/lib/x86_64-linux-gnu | wc -l)
 #    if (( $numLibs > 10 )) ; then
 #       rm -f $HOSTCONF.tmp
 #       cat $HOSTCONF | sed "s/\/usr\/lib/\/usr\/lib\/x86_64-linux-gnu/" > $HOSTCONF.tmp
 #       rm $HOSTCONF
 #       mv $HOSTCONF.tmp $HOSTCONF
 #    fi
 #fi

 cd "$START_DIR"
 echo "Done creating $HOSTCONF"
 return 0
}

# *************************************************************************** #
#
# Modifications:
#   Eric Brugger, Fri Feb  1 14:56:58 PST 2019
#   I modified it to work post git transition.
#
#   Kathleen Biagas, Monday May 12, 2025
#   Loop over groups when printing individual libs instead of
#   duplicating logic for reqlibs and optlibs.
#
# *************************************************************************** #

function printvariables
{
    printf "The following is a list of user settable environment variables\n"
    printf "\n"
    printf "%s%s\n" "OPSYS=" "${OPSYS}"
    printf "%s%s\n" "PROC=" "${PROC}"
    printf "%s%s\n" "REL=" "${REL}"
    printf "%s%s\n" "ARCH=" "${ARCH}"
    printf "%s%s\n" "VISITARCH=" "${VISITARCHTMP}"

    printf "%s%s\n" "C_COMPILER=" "${C_COMPILER}"
    printf "%s%s\n" "CXX_COMPILER=" "${CXX_COMPILER}"
    printf "%s%s\n" "FC_COMPILER=" "${FC_COMPILER}"
    printf "%s%s\n" "CFLAGS=" "${CFLAGS}"
    printf "%s%s\n" "CXXFLAGS=" "${CXXFLAGS}"
    printf "%s%s\n" "C_OPT_FLAGS=" "${C_OPT_FLAGS}"
    printf "%s%s\n" "CXX_OPT_FLAGS=" "${CXX_OPT_FLAGS}"
    printf "%s%s\n" "PAR_INCLUDE=" "${PAR_INCLUDE}"
    printf "%s%s\n" "PAR_LIBS=" "${PAR_LIBS}"

    printf "%s%s\n" "MAKE=" "${MAKE}"
    printf "%s%s\n" "THIRD_PARTY_PATH=" "${THIRD_PARTY_PATH}"
    printf "%s%s\n" "GROUP=" "${GROUP}"
    printf "%s%s\n" "LOG_FILE=" "${LOG_FILE}"
    printf "%s%s\n" "LOG_FILE=" "${LOG_FILE}"
    printf "%s%s\n" "WGET_OPTS=" "${WGET_OPTS}"

    bv_visit_print

    for (( bv_i=0; bv_i < ${#grouplibs_name[*]}; ++bv_i ))
    do
        for lib in `echo ${grouplibs_deps[$bv_i]}`;
        do
            initialize="bv_${lib}_print"
            $initialize
        done
    done
}

# *************************************************************************** #
# Modifications:
#   Kathleen Biagas, Friday May 16, 2025
#   Remove 'GROUPING' section. Expand comments for each group instead.
#
# *************************************************************************** #
function usage
{
    initialize_build_visit

    printf "Usage: %s [options]\n" $0

    printf "\n"
    printf "BUILD OPTIONS\n"
    printf "\n"

    printf "%-20s %s [%s]\n" "--build-mode" "VisIt build mode (Debug or Release)" "$VISIT_BUILD_MODE"
    printf "%-20s %s [%s]\n" "--create-rpm" "Enable creation of RPM packages" "$CREATE_RPM"
    printf "%-20s %s [%s]\n" "--cflag"   "Append a flag to CFLAGS" "${CFLAGS}"
    printf "%-20s %s [%s]\n" "--cxxflag" "Append a flag to CXXFLAGS" "$CXXFLAGS"
    printf "%-20s %s [%s]\n" "--cflags"  "Explicitly set CFLAGS" "$CFLAGS"
    printf "%-20s %s [%s]\n" "--cxxflags" "Explicitly set CXXFLAGS" "$CXXFLAGS"
    printf "%-20s %s [%s]\n" "--cc"  "Explicitly set C_COMPILER" "$C_COMPILER"
    printf "%-20s %s [%s]\n" "--cxx" "Explicitly set CXX_COMPILER" "$CXX_COMPILER"
    printf "%s <%s>  %s [%s]\n" "--makeflags" "flags" "Flags to 'make'" "$MAKE_OPT_FLAGS"
    printf "%-20s %s [%s]\n" "--fortran" "Enable compilation of Fortran sources" "no"
    printf "%-20s %s\n"      "--fc" "Explicitly set FC_COMPILER"
    printf "%-20s [%s]\n"    ""     "$FC_COMPILER"
    printf "%-20s %s [%s]\n" "--no-qt-silent" "Disable make silent operation for QT." "no"
    printf "%-20s %s [%s]\n" "--parallel" "Enable parallel build, display MPI prompt" "$parallel"
    printf "%-20s %s [%s]\n" "--static" "Build using static linking" "$DO_STATIC_BUILD"
    printf "%-20s <%s> %s\n" "--installation-build-dir" "path"
    printf "%-20s %s [%s]\n" "" "Specify the directory visit will use for building" "$VISIT_INSTALLATION_BUILD_DIR"

    printf "\n"
    printf "INSTALLATION OPTIONS\n"
    printf "\n"

    printf "%s <%s> %s [%s]\n" "--arch" "architecture" "Set architecture" "$VISITARCHTMP"
    printf "\t  %s\n" "   This variable is used in constructing the 3rd party"
    printf "\t  %s\n" "   library path; usually set to something like"
    printf "\t  %s\n" "   'linux_gcc-3.4.6' or 'Darwin_gcc-4.0.1'"
    printf "%-11s  %s [%s]\n" "--group" "Group name of installed libraries" "$GROUP"
    printf "%-11s <%s> \n%s [%s]\n" "--thirdparty-path" "/path/to/directory" \
           "             Specify the root directory name under which the 3rd party
             libraries have been installed.  If defined, it would typically
             mean the 3rd party libraries are pre-built and are installed
             somewhere like /usr/gapps/visit." "${THIRD_PARTY_PATH}"

    printf "\n"

    printf "VISIT-SPECIFIC OPTIONS\n"
    printf "\n"
    printf "%-20s %s [%s]\n" "--install-network" "Install specific network config files." "${VISIT_INSTALL_NETWORK}"
    printf "%s <%s>    %s [%s]\n" "--prefix" "prefix" "The directory to which VisIt should be installed once it is built" "$VISIT_INSTALL_PREFIX"
    printf "%s <%s>     %s [%s]\n" "--tarball" "file" "tarball to extract VisIt from" "$VISIT_FILE"
    printf "%s <%s>  %s [%s]\n" "--version" "version" "The VisIt version to build" "$VISIT_VERSION"
    printf "%-20s %s [%s]\n" "--no-hostconf" "Do not create host.conf file." "$DO_HOSTCONF"
    printf "%-20s %s [%s]\n" "--java" "Build with the Java client library" "${DO_JAVA}"
    printf "%-20s %s [%s]\n" "--paradis" "Build with the paraDIS client library" "$DO_PARADIS"
    printf "%-20s %s [%s]\n" "--xdb" "Enable FieldView XDB plugin." "$DO_XDB"
    bv_visit_initialize
    bv_visit_print_usage

    printf "\n"
    printf "THIRD-PARTY LIBRARIES\n"
    printf "  A download attempt will be made for all files which do not exist.\n"
    printf "  Enable individual libraries by using '--<name>', e.g. '--mpich'.\n"
    printf "  Disable individual libraries by using '--no-<name>', e.g. '--no-python'.\n"
    printf "\n"
    printf "  REQUIRED -- These are built by default unless --no-thirdparty flag is used.\n"
    printf "\n"

    for (( bv_i=0; bv_i<${#reqlibs[*]}; ++bv_i ))
    do
        initializeFunc="bv_${reqlibs[$bv_i]}_initialize"
        $initializeFunc
        printUsageFunc="bv_${reqlibs[$bv_i]}_print_usage"
        $printUsageFunc
    done

    printf "\n"
    printf "  OPTIONAL -- Using '--optional' flag will enable all libraries in this group.\n"
    printf "\n"

    for (( bv_i=0; bv_i<${#optlibs[*]}; ++bv_i ))
    do
        initializeFunc="bv_${optlibs[$bv_i]}_initialize"
        $initializeFunc
        printUsageFunc="bv_${optlibs[$bv_i]}_print_usage"
        $printUsageFunc
    done

    printf "\n"
    printf "  EXPLICIT -- These are only built when explicitly requested.\n"
    printf "\n"

    for (( bv_i=0; bv_i<${#explicitlibs[*]}; ++bv_i ))
    do
        initializeFunc="bv_${explicitlibs[$bv_i]}_initialize"
        $initializeFunc
        printUsageFunc="bv_${explicitlibs[$bv_i]}_print_usage"
        $printUsageFunc
    done

    printf "\n"
    printf "GIT OPTIONS\n"
    printf "\n"

    printf "%-20s %s\n"      "--git" "Obtain the VisIt source code"
    printf "%-20s %s [%s]\n" "" "from the GIT server" "$DO_GIT"

    printf "\n"
    printf "MISC OPTIONS\n"
    printf "\n"

    printf "%-20s %s [%s]\n" "--bv-debug"   "Enable debugging for this script" "no"
    printf "%-20s %s [%s]\n" "--download-only" "Only download the specified packages" "no"
    printf "%-20s %s [%s]\n" "--engine-only" "Only build the compute engine." "$DO_ENGINE_ONLY"
    printf "%-20s %s [%s]\n" "-h, --help" "Display this help message." "no"
    printf "%-20s <%s>\n" "--log-file"  "filename"
    printf "%-20s %s [%s]\n" ""  "Write build log to provided filename" "$LOG_FILE"
    printf "%-20s %s [%s]\n" "--print-vars" "Display user settable environment variables" "no"
    printf "%-20s %s\n" "--server-components-only" ""
    printf "%-20s %s\n" "" "Only build VisIt's server components"
    printf "%-20s %s [%s]\n" "" "(mdserver,vcl,engine)." "$DO_SERVER_COMPONENTS_ONLY"
    printf "%-20s %s\n" "--skip-opengl-context-check" ""
    printf "%-20s %s\n" "" "Skip check for minimum OpenGL context."
    printf "%-20s %s [%s]\n" "--stdout" "Write build log to stdout" "no"
    printf "%-20s <%s>\n" "--write-unified-file"  "filename"
    printf "%-20s %s [%s]\n" ""  "Write single unified build_visit file using the provided filename" "$WRITE_UNIFIED_FILE"
}


#TODO: pass these two variables from command line..
mangle_src="VTK"
mangle_dest="MTK"
uc_mangled_src=`echo $mangle_src | tr '[a-z]' '[A-Z]'`
uc_mangled_dest=`echo $mangle_dest | tr '[a-z]' '[A-Z]'`
lc_mangled_src=`echo $mangle_src | tr '[A-Z]' '[a-z]'`
lc_mangled_dest=`echo $mangle_dest | tr '[A-Z]' '[a-z]'`

function mangle_file
{
    local input_file="$1"
    local output_file="$2"

    cat "$input_file" | sed -e s/${lc_mangled_src}/${lc_mangled_dest}/g -e s/${uc_mangled_src}/${uc_mangled_dest}/g > "$output_file"

    #chmod --reference=$input_file $output_file
    if [[ -r "$input_file" ]]; then
        chmod u+r "$output_file"
    fi
    if [[ -w "$input_file" ]]; then
        chmod u+r "$output_file"
    fi
    if [[ -x "$input_file" ]]; then
        chmod u+x "$output_file"
    fi
}

function mangle_libraries
{
    local input_dir="$1"
    local mangled_dir="$2"

    if [[ ! -d "$input_dir" ]]; then
        info "Input directory $input_dir does not exist"
        return 1
    fi

    if [[ -d "$mangled_dir" ]]; then

        #check if we have completely mangled the library before..
        if [[ -e "$mangled_dir/done_mangling_library" ]]; then
            info "library was mangled earlier, skipping (please exit if this is not true)"
            return 0
        fi
        info "Found pre-existing mangled directory $mangled_dir, removing"
        rm -fR "$mangled_dir"
    fi

    info "mangling $input_dir $mangled_dir"
    #get all files from directory..
    local args=`find "${input_dir}" -name "*"`
    local i=0
    for i in `echo $args`
    do
        #replace all occurrences of $mangled_src with mangled_dest
        newpath=${i/${input_dir}/}
        newpath=${newpath//${uc_mangled_src}/${uc_mangled_dest}}
        newpath=${newpath//${lc_mangled_src}/${lc_mangled_dest}}
        mangled_path="${mangled_dir}/${newpath}"
        newdir=`dirname "${mangled_path}"`

        #create new dir
        mkdir -p "$newdir"
        #cat old file replace ${mangled_src} with ${mangled_dest}
        if [[ ! -d $i ]]; then
            mangle_file "$i" "${mangled_path}"
        else
            #chmod --reference=$i $newdir
            if [[ -r "$i" ]]; then
                chmod u+r "$newdir"
            fi
            if [[ -w "$i" ]]; then
                chmod u+r "$newdir"
            fi
            if [[ -x "$i" ]]; then
                chmod u+x "$newdir"
            fi
        fi
    done
    touch "$mangled_dir"/done_mangling_library
    return 0
}
#!/bin/bash

# Modifications:
#   Kathleen Biagas, Monday May 12, 2025
#   Added 'explicitlibs' group.
#   Removed 'parseXmlModules' as it was used to separately parse the non-group
#   'required' and 'optional' tags that are no longer used.
#    All libraries are listed in only one of the groups: 'required', 'optional'
#    or 'explicit' and are parsed in the 'parseXmlGroupModules' function.

declare -a xmlp_filecontents
declare -a xmlp_licenses
declare -a xmlp_licenses_range
declare -a xmlp_alllibs
declare -a xmlp_tmp_array
declare -a xmlp_reqlibs
declare -a xmlp_optlibs
declare -a xmlp_explicitlibs
declare -a xmlp_grouplibs_name
declare -a xmlp_grouplibs_deps
declare -a xmlp_grouplibs_comment
declare -a xmlp_grouplibs_enabled

function xmlp_removeSingleLineComment
{
    if [[ "$1" == *\<\!--*--\>* ]]; then
        echo "${1//\<\!--*--\>}"
    else
        echo "$1"
    fi
}

function xmlp_isCommentStart
{
    if [[ $1 == *\<\!--* ]]; then
        return 1
    fi
    return 0
}

function xmlp_isCommentEnd
{
    if [[ $1 == *--\>* ]]; then 
        return 1
    fi
    return 0
}

function readXmlModuleFile
{
    local filename=$1
    local i=0
    local isComment=0
    local range_index=0
    local addlibs=""

    if [[ ! -e $filename ]]; then 
        echo "File $filename does not exist"
        return 0
    fi

    while read line
    do
        line=$(xmlp_removeSingleLineComment "$line")
        xmlp_isCommentStart "$line"
        
        if [[ $? == 1 ]]; then
            isComment=1
        fi

        #remove comments and empty lines..
        if [[ $isComment == 0 && ! -z "$line" ]]; then
            #record which license the files go to..
            if [[ $line == *\<license* ]]; then 
                tmp=`echo $line | sed -e s/^.*=\"// -e s/\".*$//`
                range_index=${#xmlp_licenses[*]}
                xmlp_licenses[$range_index]="$tmp" 
                xmlp_licenses_range[$range_index]="$i"
            fi

            if [[ $line == *\</license\>* ]]; then 
                xmlp_licenses_range[$range_index]="${xmlp_licenses_range[$range_index]} $i"
            fi

            if [[ $line == *\<lib* ]]; then
                addlib=`echo ${line/no-} | sed -e s/^.*=\"// -e s/\".*$//`
                addlibs="${addlibs} $addlib"
            fi
            #trim white space
            xmlp_filecontents[$i]=`echo $line`
            let i++
        fi 

        xmlp_isCommentEnd "$line"

        if [[ $? == 1 ]]; then
            isComment=0
        fi
    done < $filename

    if [[ ${#xmlp_licenses[*]} == 0 ]]; then
        echo "No valid licenses found"
        return 0
    fi

    #get list of all libs, sort and get unique set..
    uniq_libs=`echo $addlibs | tr ' ' '\n' | sort | uniq`
    for lib in $uniq_libs;
    do
        xmlp_alllibs[${#xmlp_alllibs[*]}]="$lib"
    done

    return 1
}

function parseXmlGroupModules
{
    local startReading=0
    local startPattern="<group"
    local endPattern="</group>"
    local lstart=$1
    local lend=$2
    local title=""
    local deps=""
    local comment=""
    local enabled=""

    #find required tag and parse all its parameters..
    for (( i=$lstart; i < $lend; ++i ))
    do
        if [[ ${xmlp_filecontents[$i]} == *$endPattern* ]]; then
            startReading=0
            #remove whitespace with echo
            #echo "Title: $title Comment: $comment Enabled: $enabled Deps $deps"
            xmlp_grouplibs_name[${#xmlp_grouplibs_name[*]}]=`echo $title`
            xmlp_grouplibs_deps[${#xmlp_grouplibs_deps[*]}]=`echo $deps`
            xmlp_grouplibs_comment[${#xmlp_grouplibs_comment[*]}]=`echo $comment`
            xmlp_grouplibs_enabled[${#xmlp_grouplibs_enabled[*]}]=`echo $enabled`
            title=""
            deps=""
        fi

        if [[ $startReading == 1 ]]; then
            #remove everything to first string..
            local tmp="${xmlp_filecontents[$i]}"
            tmp=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
            deps="$deps $tmp"
        fi

        if [[ ${xmlp_filecontents[$i]} == *$startPattern* ]]; then
            startReading=1
            local tmp="${xmlp_filecontents[$i]}"
            #has enabled
            if [[ "$tmp" == *enabled* ]]; then
                tmp_enabled=${tmp/*enabled}
                tmp_enabled=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                enabled="$tmp_enabled"

		tmp=${tmp/enabled*}

		#has comment
		if [[ "$tmp" == *comment* ]]; then
                    tmp_comment=${tmp/*comment}
                    tmp_comment=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                    comment="$tmp_comment"

                    tmp=${tmp/comment*}
                    tmp=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                    title="$tmp"
		else
                    tmp=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                    title="$tmp"
                    comment=""
		fi
            #has comment
            elif [[ "$tmp" == *comment* ]]; then
                tmp_comment=${tmp/*comment}
                tmp_comment=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                comment="$tmp_comment"
                enabled=""

                tmp=${tmp/comment*}
                tmp=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                title="$tmp"
            else
                tmp=`echo $tmp | sed -e s/^.*=\"// -e s/\".*$//`
                title="$tmp"
                comment=""
                enabled=""
            fi
        fi
    done
}


#check if input argument is actually a license
function xmlp_licenseMatch
{
    local license=${1/--}
    local bv_i=0

    for (( bv_i=0; bv_i < ${#xmlp_licenses[*]}; ++bv_i ))
    do
        local xmlp_lic=${xmlp_licenses[$bv_i]//\|/ }
        for lic in `echo $xmlp_lic`;
        do
            if [[ "$lic" == "$license" ]]; then
                return 1
            fi
        done
    done 
    return 0
}

#loop through argument list and extract license
function xmlp_get_license
{
    local defaultLicense="" 
    for arg in "$@" ; do
        #potential input license..
        xmlp_licenseMatch "${arg/--}"
        if [[ $? == 1 ]]; then
            defaultLicense="$defaultLicense ${arg/--}"
        fi
    done

    if [[ "$defaultLicense" == "" ]]; then
        defaultLicense="${xmlp_licenses[0]/\|*}"
    fi

    echo "$defaultLicense"
}

function parseXmlModuleContents
{
    local license=$1
    local lstart=-1
    local lend=-1
    local i=0
    local groupname=""

    xmlp_reqlibs=()
    xmlp_optlibs=()
    xmlp_explicitlibs=()
    xmlp_grouplibs_name=()
    xmlp_grouplibs_deps=()
    xmlp_grouplibs_comment=()
    xmlp_grouplibs_enabled=()

    for (( i=0; i < ${#xmlp_licenses[*]}; ++i ))
    do
        local range=${xmlp_licenses_range[$i]}
        local xmlp_lic=${xmlp_licenses[$i]//\|/ }
        for lic in `echo $xmlp_lic`;
        do
            if [[ "$lic" == "$license" ]]; then
                lstart=${range/ *}
                lend=${range/* }
            fi
        done
    done

    if [[ $lstart == -1 || $lend == -1 ]]; then
        echo "License $license not found"
        return 0
    fi

    len=${#xmlp_filecontents[*]}
    if [[ $len -lt 2 ]]; then 
        echo "Incomplete Module file"
        return 0
    fi

    if [[   ${xmlp_filecontents[0]} != *\<modules* || 
                ${xmlp_filecontents[${#xmlp_filecontents[*]}-1]} != *\</modules\>* ]]; then
        echo "Module file not formatted properly must start and end with <module> </module> tag"
        return 0
    fi

    #echo "parsing license $license, start=$lstart, end=$lend"

    #parse all groups
    parseXmlGroupModules $lstart $lend

    for (( i = 0; i < ${#xmlp_grouplibs_name[*]}; ++i ))
    do
        groupname=${xmlp_grouplibs_name[$i]}
        if [[ $groupname == "required" ]] ; then
            xmlp_reqlibs=( ${xmlp_grouplibs_deps[$i]} )
        elif [[ $groupname == "optional" ]] ; then
            xmlp_optlibs=( ${xmlp_grouplibs_deps[$i]} )
        elif [[ $groupname == "explicit" ]] ; then
            xmlp_explicitlibs=( ${xmlp_grouplibs_deps[$i]} )
        fi
        #echo "group name: $groupname"
        #echo "group deps: ${xmlp_grouplibs_deps[$i]}"
    done

    #for (( i = 0; i < ${#xmlp_reqlibs[*]}; ++i ))
    #do
    #    echo "required: ${xmlp_reqlibs[$i]}"
    #done

    #for (( i = 0; i < ${#xmlp_optlibs[*]}; ++i ))
    #do
    #    echo "optional: ${xmlp_optlibs[$i]}"
    #done

    #for (( i = 0; i < ${#xmlp_explicitlibs[*]}; ++i ))
    #do
    #    echo "extra: ${xmlp_explicitlibs[$i]}"

    if [[   ${#xmlp_reqlibs[*]} == 0 || 
                ${#xmlp_optlibs[*]} == 0 ]]; then
        echo "Required and Optional Modules not present in module files"
        return 0
    fi
    return 1
}

#readXmlModuleFile "modules.xml"
##parseXmlModuleContents "lgpl"
function bv_visit_initialize
{
    export DO_VISIT="yes"
}

function bv_visit_enable
{ 
    DO_VISIT="yes"
}

function bv_visit_disable
{
    DO_VISIT="no"
}

function bv_visit_depends_on
{
    echo ""
}

function bv_visit_info
{
    export VISIT_SHA256_CHECKSUM=""
}

function bv_visit_print
{
    printf "%s%s\n" "VISIT_FILE=" "${VISIT_FILE}"
    printf "%s%s\n" "VISIT_VERSION=" "${VISIT_VERSION}"
}

function bv_visit_print_usage
{
    printf "%-20s %s [%s]\n" "--visit"   "Build VisIt" "$DO_VISIT"
}

function bv_visit_host_profile
{
    if [[ "$DO_VISIT" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## VISIT" >> $HOSTCONF
    fi
}

function bv_visit_ensure_built_or_ready
{
    # Check out the latest Git sources, before building VisIt
    if [[ "$DO_GIT" == "yes" && "$USE_VISIT_FILE" == "no" ]] ; then
        if [[ -d visit ]] ; then
            info "Found existing Git VisIt directory ($(cd visit && pwd)), using that . . ."
        else
            # Print a dialog screen
            info "Cloning VisIt with Git ($GIT_ROOT_PATH) . . ."
            if [[ "$DO_REVISION" == "yes" && "$GITREVISION" != "" ]] ; then
                # Get the specified revision.
                if ! git clone --recursive "$GIT_ROOT_PATH"; then
                    warn "Unable to build VisIt. Recursive Git clone of '$GIT_ROOT_PATH' failed."
                    return 1
                fi
                cd visit || return 1
                if ! git checkout "$GITREVISION"; then
                    warn "Unable to build VisIt. Git checkout of revision '$GITREVISION' failed."
                    cd .. || return 1
                    return 1
                fi
                cd .. || return 1
            elif [[ "$TRUNK_BUILD" == "yes" ]] ; then
                # Get the trunk version
                if ! git clone --recursive "$GIT_ROOT_PATH"; then
                    warn "Unable to build VisIt. Recursive Git clone of '$GIT_ROOT_PATH' failed."
                    return 1
                fi
            elif [[ "$RC_BUILD" == "yes" ]] ; then
                # Get the RC version
                if ! git clone --recursive "$GIT_ROOT_PATH"; then
                    warn "Unable to build VisIt. Recursive Git clone of '$GIT_ROOT_PATH' failed."
                    return 1
                fi
                cd visit || return 1
                if ! git checkout "${VISIT_VERSION:0:3}RC"; then
                    warn "Unable to build VisIt. Git checkout of RC '${VISIT_VERSION:0:3}RC' failed."
                    cd .. || return 1
                    return 1
                fi
                cd .. || return 1
            elif [[ "$TAGGED_BUILD" == "yes" ]] ; then
                # Get the tagged version
                if ! git clone --recursive "$GIT_ROOT_PATH"; then
                    warn "Unable to build VisIt. Recursive Git clone of '$GIT_ROOT_PATH' failed."
                    return 1
                fi
                cd visit || return 1
                if ! git checkout "v${VISIT_VERSION}"; then
                    warn "Unable to build VisIt. Git checkout of tag 'v${VISIT_VERSION}' failed."
                    return 1
                fi
                cd .. || return 1
            fi
        fi

    # Build using (the assumed) existing Git "visit" directory
    elif [[ -d visit ]] ; then
        info "Found existing Git VisIt directory ($(cd visit && pwd)), using that . . ."
        #resetting any values that have mixup the build between Trunk and RC
        VISIT_FILE="" #erase any accidental setting of these values
        USE_VISIT_FILE="no"
        DO_GIT="yes" #if visit directory exists it may have come from git.

    # Build using a VisIt source tarball
    else
        if [[ -e ${VISIT_FILE%.gz} || -e ${VISIT_FILE} ]] ; then
            info \
                "Got VisIt source code. Let's look for 3rd party libraries."
        else
            if ! download_file "$VISIT_FILE"; then
                warn \
                    "Unable to build VisIt. Can't find source code: ${VISIT_FILE}."
                return 1
            fi
        fi
    fi
}


function bv_visit_print_build_command
{
    echo "visit has no build commands set"
}

function bv_visit_modify_makefiles
{
    # NOTE: We are inside the VisIt src directory when this function is called.

    if [[ "$OPSYS" == "Darwin" ]]; then
        # Check for version < 8.0.0 (MacOS 10.4, Tiger) for gcc < 4.x
        VER=$(uname -r)
        if (( ${VER%%.*} > 8 )) ; then
            cat databases/Shapefile/Makefile | \
                sed '/LDFLAGS/s/$/ -Wl,-dylib_file,\/System\/Library\/Frameworks\/OpenGL.framework\/Versions\/A\/Libraries\/libGLU.dylib:\/System\/Library\/Frameworks\/OpenGL.framework\/Versions\/A\/Libraries\/libGLU.dylib/' > Make.tmp
            mv -f databases/Shapefile/Makefile databases/Shapefile/Makefile.orig
            mv -f Make.tmp databases/Shapefile/Makefile
        fi 
        if (( ${VER%%.*} < 8 )) ; then
            info "Patching VisIt . . ."
            cat databases/Fluent/Makefile | sed '/CXXFLAGS/s/$/ -O0/g' > Make.tmp
            mv -f databases/Fluent/Makefile databases/Fluent/Makefile.orig
            mv -f Make.tmp databases/Fluent/Makefile
            cat avt/Pipeline/Data/avtCommonDataFunctions.C | \
                sed '/isfinite/s/isfinite/__isfinited/g' > C.tmp
            mv -f avt/Pipeline/Data/avtCommonDataFunctions.C \
               avt/Pipeline/Data/avtCommonDataFunctions.C.orig
            mv -f C.tmp avt/Pipeline/Data/avtCommonDataFunctions.C
            cat avt/Expressions/Abstract/avtExpressionFilter.C | \
                sed '/isfinite/s/isfinite/__isfinited/g' > C.tmp
            mv -f avt/Expressions/Abstract/avtExpressionFilter.C \
               avt/Expressions/Abstract/avtExpressionFilter.C.orig
            mv -f C.tmp avt/Expressions/Abstract/avtExpressionFilter.C
        fi
        if (( ${VER%%.*} < 7 )) ; then
            cat third_party_builtin/mesa_stub/Makefile | \
                sed 's/glx.c glxext.c//' > Make.tmp
            mv -f third_party_builtin/mesa_stub/Makefile \
               third_party_builtin/mesa_stub/Makefile.orig
            mv -f Make.tmp third_party_builtin/mesa_stub/Makefile
        fi
        if (( ${VER%%.*} > 6 )) ; then
            cat avt/Expressions/Makefile | \
                sed '/LDFLAGS/s/$/ -Wl,-undefined,dynamic_lookup/g' > Make.tmp
            mv -f avt/Expressions/Makefile \
               avt/Expressions/Makefile.orig
            mv -f Make.tmp avt/Expressions/Makefile
        else
            cat avt/Expressions/Makefile | \
                sed '/LDFLAGS/s/$/ -Wl,-flat_namespace,-undefined,suppress/g' > \
                    Make.tmp
            mv -f avt/Expressions/Makefile \
               avt/Expressions/Makefile.orig
            mv -f Make.tmp avt/Expressions/Makefile
        fi
    fi

    if [[ "$BUILD_VISIT_BGQ" == "yes" ]] ; then
        # Filter the engine link line so it will not include X11 libraries. CMake is adding
        # them even though we don't want them. Also get rid of extra static/dynamic 
        # link keywords that prevent the linker from making a good static executable.
        for target in engine_ser_exe.dir engine_par_exe.dir
        do
            edir="engine/main/CMakeFiles/$target"
            if test -e "$edir/link.txt" ; then
                sed "s/-lX11//g" $edir/link.txt > $edir/link1.txt
                sed "s/-lXext//g" $edir/link1.txt > $edir/link2.txt
                sed "s/-Wl,-Bstatic//g" $edir/link2.txt > $edir/link3.txt
                sed "s/-Wl,-Bdynamic//g" $edir/link3.txt > $edir/link4.txt
                rm -f $edir/link1.txt $edir/link2.txt $edir/link3.txt
                mv $edir/link4.txt $edir/link.txt
            else
                echo "***** DID NOT SEE: $edir/link.txt   pwd=`pwd`"
            fi
            if test -e "$edir/relink.txt" ; then
                sed "s/-lX11//g" $edir/relink.txt > $edir/relink1.txt
                sed "s/-lXext//g" $edir/relink1.txt > $edir/relink2.txt
                sed "s/-Wl,-Bstatic//g" $edir/relink2.txt > $edir/relink3.txt
                sed "s/-Wl,-Bdynamic//g" $edir/relink3.txt > $edir/relink4.txt
                rm -f $edir/relink1.txt $edir/relink2.txt $edir/relink3.txt
                mv $edir/relink4.txt $edir/relink.txt
            else
                echo "***** DID NOT SEE: $edir/relink.txt   pwd=`pwd`"
            fi
        done
        # Filter the visitconvert link line so it will not include X11 libraries. CMake 
        # is adding them even though we don't want them. Also get rid of extra static/dynamic 
        # link keywords that prevent the linker from making a good static executable.
        for target in visitconvert_ser.dir visitconvert_par.dir
        do
            edir="tools/convert/CMakeFiles/$target"
            if test -e "$edir/link.txt" ; then
                sed "s/-lX11//g" $edir/link.txt > $edir/link1.txt
                sed "s/-lXext//g" $edir/link1.txt > $edir/link2.txt
                sed "s/-Wl,-Bstatic//g" $edir/link2.txt > $edir/link3.txt
                sed "s/-Wl,-Bdynamic//g" $edir/link3.txt > $edir/link4.txt
                rm -f $edir/link1.txt $edir/link2.txt $edir/link3.txt
                mv $edir/link4.txt $edir/link.txt
            else
                echo "***** DID NOT SEE: $edir/link.txt   pwd=`pwd`"
            fi
            if test -e "$edir/relink.txt" ; then
                sed "s/-lX11//g" $edir/relink.txt > $edir/relink1.txt
                sed "s/-lXext//g" $edir/relink1.txt > $edir/relink2.txt
                sed "s/-Wl,-Bstatic//g" $edir/relink2.txt > $edir/relink3.txt
                sed "s/-Wl,-Bdynamic//g" $edir/relink3.txt > $edir/relink4.txt
                rm -f $edir/relink1.txt $edir/relink2.txt $edir/relink3.txt
                mv $edir/relink4.txt $edir/relink.txt
            else
                echo "***** DID NOT SEE: $edir/relink.txt   pwd=`pwd`"
            fi
        done
    fi

    return 0
}

# *************************************************************************** #
#                          Function 9.1, build_visit                          #
# *************************************************************************** #

function build_visit
{
    if [[ "$DO_GIT" != "yes" || "$USE_VISIT_FILE" == "yes" ]] ; then
        #
        # Unzip the file, provided a gzipped file exists.
        #
        if [[ -f ${VISIT_FILE} ]] ; then
            info "Unzipping/untarring ${VISIT_FILE} . . ."
            uncompress_untar ${VISIT_FILE}
            if [[ $? != 0 ]] ; then
                warn \
                    "Unable to untar ${VISIT_FILE}.  Corrupted file or out of space on device?"
                return 1
            fi
        elif [[ -f ${VISIT_FILE%.*} ]] ; then
            info "Unzipping ${VISIT_FILE%.*} . . ."
            $TAR xf ${VISIT_FILE%.*}
            if [[ $? != 0 ]] ; then
                warn  \
                    "Unable to untar ${VISIT_FILE%.*}.  Corrupted file or out of space on device?"
                return 1
            fi
        fi
    fi

    #
    # Set up the VisIt build dir which is a sibling to the VisIt src dir
    #
    if [[ "$DO_GIT" == "yes" && "$USE_VISIT_FILE" == "no" ]] ; then
        VISIT_BUILD_DIR="visit/build"
    else
        VISIT_BUILD_DIR="${VISIT_FILE%.tar*}/build"
    fi

    if [[ ! -e $VISIT_BUILD_DIR ]] ; then
        mkdir $VISIT_BUILD_DIR || error "Can't make VisIt build dir."
    else
        rm -rf $VISIT_BUILD_DIR/* || error "Can't clean VisIt build dir."
    fi

    info "Building VisIt in ${VISIT_BUILD_DIR} . . ."
    
    cd $VISIT_BUILD_DIR

    #
    # Create the GIT_VERSION file.
    #
    if [[ "$DO_GIT" == "yes" && "$USE_VISIT_FILE" == "no" ]] ; then
        git log -1 | grep "^commit" | cut -d' ' -f2 | head -c 7 > ../src/GIT_VERSION
    fi

    #
    # Set up the config-site file, which gives configure the information it
    # needs about the third party libraries.
    #

    # No real need to do this as it is defined on the cmake line BUT
    # Users may rebuild visit with updated git
    cp ${START_DIR}/${HOSTCONF} ../src/config-site

    #
    # Call cmake
    # 
    info "Configuring VisIt . . ."
    FEATURES="-DVISIT_CONFIG_SITE:FILEPATH=${START_DIR}/${HOSTCONF}"
    FEATURES="${FEATURES} -DVISIT_INSTALL_THIRD_PARTY:BOOL=ON"
    if [[ "$parallel" == "yes" ]] ; then
        FEATURES="${FEATURES} -DVISIT_PARALLEL:BOOL=ON"
    fi
    FEATURES="${FEATURES} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"
    FEATURES="${FEATURES} -DVISIT_C_COMPILER:FILEPATH=${C_COMPILER}"
    FEATURES="${FEATURES} -DVISIT_CXX_COMPILER:FILEPATH=${CXX_COMPILER}"

    if test -n "${CFLAGS}" || test -n "${C_OPT_FLAGS}" ; then
        FEATURES="${FEATURES} -DVISIT_C_FLAGS:STRING=\"${CFLAGS} ${C_OPT_FLAGS}\""
    fi
    if [[ "$parallel" == "yes" ]] ; then
        CXXFLAGS="$CXXFLAGS $PAR_INCLUDE"
    fi
    if test -n "${CXXFLAGS}" || test -n "${CXX_OPT_FLAGS}" ; then
        FEATURES="${FEATURES} -DVISIT_CXX_FLAGS:STRING=\"${CXXFLAGS} ${CXX_OPT_FLAGS}\""
    fi
    if [[ "${DO_JAVA}" == "yes" ]] ; then
        FEATURES="${FEATURES} -DVISIT_JAVA:BOOL=ON"
    fi
    if [[ "${VISIT_INSTALL_PREFIX}" != "" ]] ; then
        FEATURES="${FEATURES} -DCMAKE_INSTALL_PREFIX:PATH=${VISIT_INSTALL_PREFIX}"
        FEATURES="${FEATURES} -DCPACK_INSTALL_PREFIX:PATH=${VISIT_INSTALL_PREFIX}"
        FEATURES="${FEATURES} -DCPACK_PACKAGING_INSTALL_PREFIX:PATH=${VISIT_INSTALL_PREFIX}"
    fi
    # Select a specialized build mode.
    if [[ "${DO_DBIO_ONLY}" == "yes" ]] ; then
        FEATURES="${FEATURES} -DVISIT_DBIO_ONLY:BOOL=ON"
    elif [[ "${DO_ENGINE_ONLY}" = "yes" ]] ; then
        FEATURES="${FEATURES} -DVISIT_ENGINE_ONLY:BOOL=ON"
    elif [[ "${DO_SERVER_COMPONENTS_ONLY}" = "yes" ]] ; then
        FEATURES="${FEATURES} -DVISIT_SERVER_COMPONENTS_ONLY:BOOL=ON"
    fi

    # Let the user turn on XDB.
    if [[ "${DO_XDB}" == "yes" ]] ; then
        FEATURES="${FEATURES} -DVISIT_ENABLE_XDB:BOOL=ON"
    fi

    # Let the user pick a subset of plugins.
    if [[ "${VISIT_SELECTED_DATABASE_PLUGINS}" != "" ]] ; then
        FEATURES="${FEATURES} -DVISIT_SELECTED_DATABASE_PLUGINS:STRING=${VISIT_SELECTED_DATABASE_PLUGINS}"
    fi
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}
    CMAKE_BIN="${CMAKE_INSTALL}/cmake"
    rm -f CMakeCache.txt

    if [[ "${CREATE_RPM}" == "yes" ]]; then
        sed -i "s/SET(CPACK_GENERATOR \"TGZ\")/#SET(CPACK_GENERATOR \"TGZ\")/" CMakeLists.txt
        FEATURES="${FEATURES} -DCPACK_BINARY_RPM:BOOL=ON -DCPACK_GENERATOR:STRING=\"RPM;TGZ\""
        FEATURES="${FEATURES} -DCPACK_RPM_SPEC_MORE_DEFINE:STRING=\"%global_python_bytecompile_errors_terminate_build 0\""
    fi

    # Several platforms have had problems with the cmake configure command
    # issued simply via "issue_command".  This was first discovered on
    # BGQ and then showed up in random cases for both OSX and Linux machines.
    # Brad resolved this on BGQ  with a simple work around - we write a simple
    # script that we invoke with bash which calls cmake with all of the
    # arguments. We are now using this strategy for all platforms.
    #

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\"" ${FEATURES} ../src > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "VisIt configuration failed."

    #
    # Some platforms like to modify the generated Makefiles.
    #
    bv_visit_modify_makefiles

    #
    # Build VisIt
    #
    info "Building VisIt . . . (~50 minutes)"
    if [[ "${PY_BUILD_SPHINX}" == "yes" ]] ; then
        ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS --target manuals
        if [[ $? != 0 ]] ; then
            warn "Building the VisIt manuals failed.  Continuing"
        fi
    fi
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "VisIt build failed.  Giving up"
        return 1
    fi
    warn "All indications are that VisIt was successfully built."

    #
    # Package VisIt
    #
    info "Packaging VisIt ... (~10 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS --target package
    if [[ $? != 0 ]] ; then
        warn "VisIt package failed.  Giving up"
        return 1
    fi
    mv visit*.*.tar.gz ../..
    cp ../scripts/visit-install ../..
    warn "All indications are that VisIt was successfully packaged."

    #
    # Install VisIt
    #
    if [[ "${VISIT_INSTALL_PREFIX}" != "" ]] ; then
        ${CMAKE_COMMAND} --install .
        if [[ $? != 0 ]] ; then
            warn "VisIt installation failed.  Giving up"
            return 1
        fi
        warn "All indications are that VisIt was successfully installed."
    fi

    #
    # Major hack here. Mark M. should really pull this total hack out of
    # this script. It is here to make the visitconvert tool be called
    # imeshio to satisfy needs of ITAPS SciDAC project.
    #
    if [[ "${DO_DBIO_ONLY}" == "yes" && "$0" == "build_imeshio" ]] ; then
        if [[ -e exe/visitconvert_ser_lite ]]; then
            cp exe/visitconvert_ser_lite exe/imeshioconvert
            cp bin/visitconvert bin/imeshioconvert
        fi
    fi
}

function bv_visit_is_enabled
{
    if [[ $DO_VISIT == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_visit_is_installed
{
    #always return false?
    return 0
}

function bv_visit_build
{
    #
    # Build the actual VisIt code
    #

    if [[ "$DO_VISIT" == "yes" ]] ; then
        cd "$START_DIR"
        info "Building VisIt (~50 minutes)"
        build_visit
        if [[ $? != 0 ]] ; then
            error "Unable to build or install VisIt.  Bailing out."
        fi

        #
        # Output the message indicating that we are finished.
        #
        info "Finished creating a VisIt distribution."
        info
        info "This created a tar file called visitVERSION.ARCH.tar.gz,"
        info "where VERSION is the version number, and ARCH is the"
        info "operating system and architecure."
        info
        info "To install the above tar file in a directory called \"INSTALL_DIR_PATH\""
        info "enter: ./visit-install VERSION ARCH INSTALL_DIR_PATH"
        info
        info "If you run into problems, contact us via https://visit-help.llnl.gov."
    else
        if [[ $ANY_ERRORS == "no" ]] ; then
            info "Finished!"
        else
            info "Finished with Errors"
        fi
    fi

    if [[ $VISIT_BUILD_MODE == "Debug" ]]; then
        info "Debug build mode was specified. The default build mode for VisIt is Release."
        info "To build VisIt in Debug mode, pass -DCMAKE_BUILD_TYPE:STRING=Debug to VisIt's cmake configure command."
    fi
}
function bv_adios_initialize
{
    export DO_ADIOS="no"
    export USE_SYSTEM_ADIOS="no"
    add_extra_commandline_args "adios" "alt-adios-dir" 1 "Use alternative directory for adios"

}

function bv_adios_enable
{
    DO_ADIOS="yes"
}

function bv_adios_disable
{
    DO_ADIOS="no"
}

function bv_adios_alt_adios_dir
{
    echo "Using alternate Adios directory"

    # Check to make sure the directory or a particular include file exists.
    #    [ ! -e "$1" ] && error "Adios not found in $1"

    bv_adios_enable
    USE_SYSTEM_ADIOS="yes"
    ADIOS_INSTALL_DIR="$1"
}

function bv_adios_depends_on
{
    if [[ "$USE_SYSTEM_ADIOS" == "yes" ]]; then
        echo ""
    else
        depends_on=""

        if [[ "$DO_MPICH" == "yes" ]] ; then
            depends_on="$depends_on mpich"
        fi

        if [[ "$DO_HDF5" == "yes" ]] ; then
            depends_on="$depends_on hdf5"
        fi

        if [[ "$DO_BLOSC" == "yes" ]] ; then
            depends_on="$depends_on blosc"
        fi

        echo $depends_on
    fi
}

function bv_adios_initialize_vars
{
    if [[ "$parallel" == "no" ]]; then
        bv_adios_disable
        warn "Adios requested by default but the parallel flag has not been set. Adios will not be built."
        return
    fi

    if [[ "$USE_SYSTEM_ADIOS" == "no" ]]; then
        ADIOS_INSTALL_DIR="${VISITDIR}/adios/$ADIOS_VERSION/$VISITARCH"
    fi
}

function bv_adios_info
{
    export ADIOS_VERSION=${ADIOS_VERSION:-"1.13.1"}
    export ADIOS_FILE=${ADIOS_FILE:-"adios-${ADIOS_VERSION}.tar.gz"}
    export ADIOS_COMPATIBILITY_VERSION=${ADIOS_COMPATIBILITY_VERSION:-"${ADIOS_VERSION}"}
    export ADIOS_BUILD_DIR=${ADIOS_BUILD_DIR:-"adios-${ADIOS_VERSION}"}
    export ADIOS_SHA256_CHECKSUM="684096cd7e5a7f6b8859601d4daeb1dfaa416dfc2d9d529158a62df6c5bcd7a0"
}

function bv_adios_print
{
    printf "%s%s\n" "ADIOS_FILE=" "${ADIOS_FILE}"
    printf "%s%s\n" "ADIOS_VERSION=" "${ADIOS_VERSION}"
    printf "%s%s\n" "ADIOS_COMPATIBILITY_VERSION=" "${ADIOS_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "ADIOS_BUILD_DIR=" "${ADIOS_BUILD_DIR}"
}

function bv_adios_print_usage
{
    printf "%-20s %s [%s]\n" "--adios" "Build ADIOS" "$DO_ADIOS"
    printf "%-20s %s [%s]\n" "--alt-adios-dir" "Use ADIOS from an alternative directory"
}

function bv_adios_host_profile
{
    if [[ "$DO_ADIOS" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## ADIOS" >> $HOSTCONF
        if [[ "$VISIT_MPI_COMPILER" != "" ]] ; then
            echo "## (configured w/ mpi compiler wrapper)" >> $HOSTCONF
        fi
        echo "##" >> $HOSTCONF

        if [[ "$USE_SYSTEM_ADIOS" == "yes" ]]; then
            warn "Assuming version 1.11.0 for Adios"
            echo "SETUP_APP_VERSION(ADIOS 1.11.0)" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_ADIOS_DIR $ADIOS_INSTALL_DIR)" >> $HOSTCONF
        else
            echo "SETUP_APP_VERSION(ADIOS $ADIOS_VERSION)" >> $HOSTCONF
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_ADIOS_DIR \${VISITHOME}/adios/\${ADIOS_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF
        fi
    fi
}

function bv_adios_ensure
{
    if [[ "$DO_ADIOS" == "yes" && "$USE_SYSTEM_ADIOS" == "no" ]] ; then
        ensure_built_or_ready "adios" $ADIOS_VERSION $ADIOS_BUILD_DIR $ADIOS_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_ADIOS="no"
            error "Unable to build ADIOS.  ${ADIOS_FILE} not found."
        fi
    fi
}

# ***************************************************************************
#                         Function 8.22, build_ADIOS
#
# Modifications:
#
# ***************************************************************************

function apply_adios_1_6_0_patch
{
    # fix for osx -- malloc.h doesn't exist (examples/C/schema includes this file)
    info "Patching ADIOS"
    patch -p0 << \EOF
diff -rcN adios-1.6.0-orig/examples/C/schema/rectilinear2d.c adios-1.6.0/examples/C/schema/rectilinear2d.c
*** adios-1.6.0-orig/examples/C/schema/rectilinear2d.c  2013-12-05 08:15:37.000000000 -0800
--- adios-1.6.0/examples/C/schema/rectilinear2d.c       2014-06-02 15:27:23.000000000 -0700
***************
*** 10,16 ****
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #include <malloc.h>
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
--- 10,18 ----
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #if !defined(__APPLE__)
!  #include <malloc.h>
! #endif
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
diff -rcN adios-1.6.0-orig/examples/C/schema/structured2d.c adios-1.6.0/examples/C/schema/structured2d.c
*** adios-1.6.0-orig/examples/C/schema/structured2d.c   2013-12-05 08:15:37.000000000 -0800
--- adios-1.6.0/examples/C/schema/structured2d.c        2014-06-02 15:27:23.000000000 -0700
***************
*** 10,16 ****
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #include <malloc.h>
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
--- 10,18 ----
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #if !defined(__APPLE__)
!  #include <malloc.h>
! #endif
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
diff -rcN adios-1.6.0-orig/examples/C/schema/tri2d.c adios-1.6.0/examples/C/schema/tri2d.c
*** adios-1.6.0-orig/examples/C/schema/tri2d.c  2013-12-05 08:15:37.000000000 -0800
--- adios-1.6.0/examples/C/schema/tri2d.c       2014-06-02 15:27:23.000000000 -0700
***************
*** 10,16 ****
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #include <malloc.h>
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
--- 10,18 ----
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #if !defined(__APPLE__)
!  #include <malloc.h>
! #endif
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
diff -rcN adios-1.6.0-orig/examples/C/schema/uniform2d.c adios-1.6.0/examples/C/schema/uniform2d.c
*** adios-1.6.0-orig/examples/C/schema/uniform2d.c      2013-12-05 08:15:37.000000000 -0800
--- adios-1.6.0/examples/C/schema/uniform2d.c   2014-06-02 15:27:23.000000000 -0700
***************
*** 10,16 ****
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #include <malloc.h>
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>
--- 10,18 ----
  #include <stdio.h>
  #include <stdlib.h>
  #include <string.h>
! #if !defined(__APPLE__)
!  #include <malloc.h>
! #endif
  #include <unistd.h>
  #include <fcntl.h>
  #include <errno.h>

EOF
    if [[ $? != 0 ]] ; then
        warn "ADIOS patch failed."
        return 1
    fi

    return 0;
}

function apply_adios_patch
{
    if [[ ${ADIOS_VERSION} == 1.6.0 ]] ; then
        apply_adios_1_6_0_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0
}

function build_adios
{
    #
    # Prepare build dir
    #
    prepare_build_dir $ADIOS_BUILD_DIR $ADIOS_FILE
    untarred_ADIOS=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_ADIOS == -1 ]] ; then
        warn "Unable to prepare ADIOS Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    apply_adios_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_ADIOS == 1 ]] ; then
            warn "Giving up on ADIOS build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Apply configure
    #
    info "Configuring ADIOS . . ."
    cd $ADIOS_BUILD_DIR || error "Can't cd to ADIOS build dir."

    info "Invoking command to configure ADIOS"

    # MPI support
    if [[ "$VISIT_MPI_COMPILER" != "" ]] ; then
        WITH_MPI_ARGS="MPICC=\"$VISIT_MPI_COMPILER\" MPICXX=\"$VISIT_MPI_COMPILER_CXX\" LDFLAGS=\"-lpthread $PAR_LINKER_FLAGS\""
        WITH_MPI_INC="$PAR_INCLUDE"

    else
        WITH_MPI_ARGS="--without-mpi"
    fi

    # HDF5 support
    if [[ "$DO_HDF5" == "yes" ]] ; then
        export HDF5ROOT="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH"
        export SZIPROOT="$VISITDIR/szip/$SZIP_VERSION/$VISITARCH"
        WITH_HDF5_ARGS="--with-hdf5=$HDF5ROOT"
        #HDF5_DYLIB="-L$HDF5ROOT/lib -L$SZIPROOT/lib -lhdf5 -lsz -lz"
    else
        WITH_HDF5_ARGS="--without-hdf5"
        #HDF5_DYLIB=""
    fi

    # blosc support
    if [[ "$DO_BLOSC" == "yes" ]]; then
        WITH_BLOSC_ARGS="--with-blosc=$BLOSCDIR"
    else
        WITH_BLOSC_ARGS="--without-blosc"
    fi

    # Fix compilation error on newer Darwin
    if [[ "$OPSYS" == "Darwin" && $(uname -r | cut -d'.' -f1) -ge 23 ]]; then
        sed -i '' 's/^libparse_test_query_xml_a_LIBADD/#libparse_test_query_xml_a_LIBADD/' tests/C/query/common/Makefile.in
    fi

    set -x
    sh -c "./configure ${OPTIONAL} CXX=\"$CXX_COMPILER\" CC=\"$C_COMPILER\" \
           CFLAGS=\"$CFLAGS $C_OPT_FLAGS $WITH_MPI_INC\" \
           CXXFLAGS=\"$CXXFLAGS $CXX_OPT_FLAGS $WITH_MPI_INC\" \
           $WITH_MPI_ARGS $WITH_HDF5_ARGS $WITH_BLOSC_ARGS \
           --disable-fortran \
           --without-netcdf --without-nc4par --without-phdf5 --without-mxml \
           --prefix=\"$VISITDIR/adios/$ADIOS_VERSION/$VISITARCH\""

    set +x
    if [[ $? != 0 ]] ; then
        warn "ADIOS configure failed.  Giving up"
        return 1
    fi

    #
    # Apply patches
    #
    apply_adios_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_adios == 1 ]] ; then
            warn "Giving up on Adios build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Build ADIOS
    #
    info "Building ADIOS . . . (~2 minutes)"
    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "ADIOS build failed.  Giving up"
        return 1
    fi

    info "Installing ADIOS . . ."
    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "ADIOS build (make install) failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/ADIOS"
        chgrp -R ${GROUP} "$VISITDIR/ADIOS"
    fi

    cd "$START_DIR"
    info "Done with ADIOS"
    return 0
}

function bv_adios_is_enabled
{
    if [[ $DO_ADIOS == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_adios_is_installed
{
    if [[ "$USE_SYSTEM_ADIOS" == "yes" ]]; then
        return 1
    fi

    check_if_installed "adios" $ADIOS_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_adios_build
{
    cd "$START_DIR"

    if [[ "$DO_ADIOS" == "yes" && "$USE_SYSTEM_ADIOS" == "no" ]] ; then
        check_if_installed "adios" $ADIOS_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping ADIOS build.  ADIOS is already installed."
        else
            info "Building ADIOS (~1 minutes)"
            build_adios
            if [[ $? != 0 ]] ; then
                error "Unable to build or install ADIOS.  Bailing out."
            fi
            info "Done building ADIOS"
        fi
    fi
}
function bv_adios2_initialize
{
    export DO_ADIOS2="no"
    export USE_SYSTEM_ADIOS2="no"
    add_extra_commandline_args "adios2" "alt-adios2-dir" 1 "Use alternative directory for adios"

}

function bv_adios2_enable
{
    DO_ADIOS2="yes"
}

function bv_adios2_disable
{
    DO_ADIOS2="no"
}

function bv_adios2_alt_adios2_dir
{
    echo "Using alternate Adios2 directory"

    # Check to make sure the directory or a particular include file exists.
    #    [ ! -e "$1" ] && error "Adios not found in $1"

    bv_adios2_enable
    USE_SYSTEM_ADIOS2="yes"
    ADIOS2_INSTALL_DIR="$1"
}

function bv_adios2_depends_on
{
    if [[ "$USE_SYSTEM_ADIOS2" == "yes" ]]; then
        echo ""
    else
        depends_on="cmake"

        if [[ "$DO_MPICH" == "yes" ]] ; then
            depends_on="$depends_on mpich"
        fi

        if [[ "$DO_HDF5" == "yes" ]] ; then
            depends_on="$depends_on hdf5"
        fi

        depends_on="$depends_on blosc2"

        echo $depends_on
    fi
}

function bv_adios2_initialize_vars
{
    if [[ "$USE_SYSTEM_ADIOS2" == "no" ]]; then
        ADIOS2_INSTALL_DIR="${VISITDIR}/adios2/$ADIOS2_VERSION/$VISITARCH"
    fi
}

function bv_adios2_info
{
    export ADIOS2_VERSION=${ADIOS2_VERSION:-"2.10.0-rc1"}
    export ADIOS2_FILE=${ADIOS2_FILE:-"adios2-${ADIOS2_VERSION}.tar.gz"}
    export ADIOS2_COMPATIBILITY_VERSION=${ADIOS2_COMPATIBILITY_VERSION:-"${ADIOS2_VERSION}"}
    export ADIOS2_BUILD_DIR=${ADIOS2_BUILD_DIR:-"ADIOS2-"${ADIOS2_VERSION}}
    export ADIOS2_SHA256_CHECKSUM="8b72142bd5aabfb80c7963f524df11b8721c09ef20caea6df5fb00c31a7747c0"
}

function bv_adios2_print
{
    printf "%s%s\n" "ADIOS2_FILE=" "${ADIOS2_FILE}"
    printf "%s%s\n" "ADIOS2_VERSION=" "${ADIOS2_VERSION}"
    printf "%s%s\n" "ADIOS2_COMPATIBILITY_VERSION=" "${ADIOS2_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "ADIOS2_BUILD_DIR=" "${ADIOS2_BUILD_DIR}"
}

function bv_adios2_print_usage
{
    printf "%-20s %s [%s]\n" "--adios2" "Build ADIOS2" "$DO_ADIOS2"
    printf "%-20s %s [%s]\n" "--alt-adios2-dir" "Use ADIOS2 from an alternative directory"
}

function bv_adios2_host_profile
{
    if [[ "$DO_ADIOS2" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## ADIOS2" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        if [[ "$USE_SYSTEM_ADIOS2" == "yes" ]]; then
            echo "SETUP_APP_VERSION(ADIOS2 $ADIOS2_VERSION)" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_ADIOS2_DIR $ADIOS2_INSTALL_DIR)" >> $HOSTCONF
        else
            echo "SETUP_APP_VERSION(ADIOS2 $ADIOS2_VERSION)" >> $HOSTCONF
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_ADIOS2_DIR \${VISITHOME}/adios2-ser/\${ADIOS2_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF

            if [[ "$parallel" == "yes" ]] ; then
                echo "## (configured w/ mpi compiler wrapper)" >> $HOSTCONF
                echo "VISIT_OPTION_DEFAULT(VISIT_ADIOS2_PAR_DIR \${VISITHOME}/adios2-par/\${ADIOS2_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF
            fi
        fi
    fi
}

function bv_adios2_ensure
{
    if [[ "$DO_ADIOS2" == "yes" && "$USE_SYSTEM_ADIOS2" == "no" ]] ; then
        ensure_built_or_ready "adios2-ser" $ADIOS2_VERSION $ADIOS2_BUILD_DIR $ADIOS2_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_ADIOS2="no"
            error "Unable to build ADIOS2.  ${ADIOS2_FILE} not found."
        fi
        ensure_built_or_ready "adios2-par" $ADIOS2_VERSION $ADIOS2_BUILD_DIR $ADIOS2_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_ADIOS2="no"
            error "Unable to build ADIOS2.  ${ADIOS2_FILE} not found."
        fi
    fi
}

function build_adios2
{
    #
    # ADIOS2 uses CMake  -- make sure we have it.
    #
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}
    if [[ -e ${CMAKE_INSTALL}/cmake ]] ; then
        info "ADIOS2: CMake found"
    else
        warn "Unable to find cmake, cannot build ADIOS2. Giving up."
        return 1
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $ADIOS2_BUILD_DIR $ADIOS2_FILE
    untarred_ADIOS2=$?
    if [[ $untarred_ADIOS2 == -1 ]] ; then
        warn "Unable to prepare ADIOS2 Build Directory. Giving Up"
        return 1
    fi

    #### begin parallel

    par_build_types="ser"
    if [[ "$parallel" == "yes" ]]; then
        par_build_types="$par_build_types par"
    fi

    ADIOS2_SRC_DIR=$ADIOS2_BUILD_DIR

    for bt in $par_build_types; do

        # Configure.
        cd $ADIOS2_SRC_DIR || error "Can't cd to $ADIOS2_SRC_DIR"
        info "Configuring ADIOS2-$bt (~1 minute)"

        # Make a build directory for an out-of-source build.. Change the
        # VISIT_BUILD_DIR variable to represent the out-of-source build directory.
        ADIOS2_BUILD_DIR="${ADIOS2_SRC_DIR}-$bt-build"

        if [[ ! -d $ADIOS2_BUILD_DIR ]] ; then
            echo "Making build directory $ADIOS2_BUILD_DIR"
            mkdir $ADIOS2_BUILD_DIR
        fi

        cd $ADIOS2_BUILD_DIR || error "Can't cd to $ADIOS2_BUILD_DIR"

        #
        # Remove the CMakeCache.txt files ... existing files sometimes prevent
        # fields from getting overwritten properly.
        #
        rm -Rf $ADIOS2_BUILD_DIR/CMakeCache.txt $ADIOS2_BUILD_DIR/*/CMakeCache.txt

        adios2_build_mode="${VISIT_BUILD_MODE}"
        adios2_install_path="${VISITDIR}/adios2-$bt/${ADIOS2_VERSION}/${VISITARCH}"

        cfg_opts=""
        cfg_opts="${cfg_opts} -DADIOS2_BUILD_EXAMPLES:STRING=OFF"
        cfg_opts="${cfg_opts} -DADIOS2_USE_ZeroMQ:STRING=OFF"
        cfg_opts="${cfg_opts} -DADIOS2_USE_Fortran:STRING=OFF"

        # Disable PNG and FFI dependence on macOS
        if [[ "$OPSYS" == "Darwin" ]]; then
            cfg_opts="${cfg_opts} -DADIOS2_USE_PNG:STRING=OFF"
            cfg_opts="${cfg_opts} -DCMAKE_DISABLE_FIND_PACKAGE_LibFFI=TRUE"
        fi

        if test "x${DO_STATIC_BUILD}" = "xyes" ; then
            cfg_opts="${cfg_opts} -DBUILD_SHARED_LIBS:BOOL=OFF"
        else
            cfg_opts="${cfg_opts} -DBUILD_SHARED_LIBS:BOOL=ON"
        fi
        cfg_opts="${cfg_opts} -DCMAKE_BUILD_TYPE:STRING=${adios2_build_mode}"
        cfg_opts="${cfg_opts} -DCMAKE_INSTALL_PREFIX:PATH=${adios2_install_path}"
        cfg_opts="${cfg_opts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS}\""
        cfg_opts="${cfg_opts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS}\""
        cfg_opts="${cfg_opts} -DADIOS2_USE_SST:STRING=ON"
        cfg_opts="${cfg_opts} -DADIOS2_USE_Sodium:STRING=OFF"

        # Use Blosc2
        if [[ "$DO_BLOSC2" == "yes" ]] ; then
            BLOSC2_INSTALL_DIR="${VISITDIR}/blosc2/${BLOSC2_VERSION}/${VISITARCH}"
            BLOSC2_INCLUDE_DIR="${BLOSC2_INSTALL_DIR}/include"
            # note: lib dir can be `lib``, or `lib64` depending on the platform
            if [[ -d "${BLOSC2_INSTALL_DIR}/lib64/" ]] ; then
                BLOSC2_LIBRARY="${BLOSC2_INSTALL_DIR}/lib64/libblosc2.${SO_EXT}"
            elif [[ -d "${BLOSC2_INSTALL_DIR}/lib/" ]] ; then
                BLOSC2_LIBRARY="${BLOSC2_INSTALL_DIR}/lib/libblosc2.${SO_EXT}"
            fi

            cfg_opts="${cfg_opts} -DADIOS2_USE_Blosc2:STRING=ON"
            cfg_opts="${cfg_opts} -DBlosc2_DIR=${BLOSC2_INSTALL_DIR}"
            cfg_opts="${cfg_opts} -DBLOSC2_INCLUDE_DIR=${BLOSC2_INCLUDE_DIR}"
            cfg_opts="${cfg_opts} -DBLOSC2_LIBRARY=${BLOSC2_LIBRARY}"
        fi

        if [[ "$bt" == "ser" ]]; then
            cfg_opts="${cfg_opts} -DADIOS2_USE_MPI:STRING=OFF"
            cfg_opts="${cfg_opts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
            cfg_opts="${cfg_opts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
        elif [[ "$bt" == "par" ]]; then
            cfg_opts="${cfg_opts} -DADIOS2_USE_MPI:STRING=ON"
            cfg_opts="${cfg_opts} -DCMAKE_C_COMPILER:STRING=${PAR_COMPILER}"
            cfg_opts="${cfg_opts} -DCMAKE_CXX_COMPILER:STRING=${PAR_COMPILER_CXX}"
        fi

        # Use HDF5?
        if [[ "$DO_HDF5" == "yes" ]] ; then
            hdf5_install_path="${VISITDIR}/hdf5/${HDF5_VERSION}/${VISITARCH}"
            cfg_opts="${cfg_opts} -DCMAKE_PREFIX_PATH:PATH=${hdf5_install_path}"
        fi

        # call configure.
        CMAKE_BIN="${CMAKE_INSTALL}/cmake"
        if test -e bv_run_cmake.sh ; then
            rm -f bv_run_cmake.sh
        fi

        echo "\"${CMAKE_BIN}\"" ${cfg_opts} ../ > bv_run_cmake.sh
        cat bv_run_cmake.sh
        issue_command bash bv_run_cmake.sh

        if [[ $? != 0 ]] ; then
            warn "ADIOS2 configure failed.  Giving up"
            return 1
        fi

        #
        # Build ADIOS2
        #
        info "Building ADIOS2-$bt . . . (~5 minutes)"
        ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
        if [[ $? != 0 ]] ; then
            warn "ADIOS2 build failed.  Giving up"
            return 1
        fi

        #
        # Install into the VisIt third party location.
        #
        info "Installing ADIOS2-$bt"
        ${CMAKE_COMMAND} --install .
        if [[ $? != 0 ]] ; then
            warn "ADIOS2 install failed.  Giving up"
            return 1
        fi

        if [[ "$DO_GROUP" == "yes" ]] ; then
            chmod -R ug+w,a+rX "$VISITDIR/adios2"
            chgrp -R ${GROUP} "$VISITDIR/adios2"
        fi

        cd "$START_DIR"
    done

    cd "$START_DIR"
    info "Done with ADIOS2"
    return 0
}

function bv_adios2_is_enabled
{
    if [[ $DO_ADIOS2 == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_adios2_is_installed
{
    if [[ "$USE_SYSTEM_ADIOS2" == "yes" ]]; then
        return 1
    fi

    check_if_installed "adios2" $ADIOS2_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_adios2_build
{
    cd "$START_DIR"

    if [[ "$DO_ADIOS2" == "yes" && "$USE_SYSTEM_ADIOS2" == "no" ]] ; then
        ser_installed="no"
        par_installed="no"
        check_if_installed "adios2-ser" $ADIOS2_VERSION
        if [[ $? == 0 ]] ; then ser_installed="yes"; fi
        if [[ "$parallel" == "yes" ]]; then
            check_if_installed "adios2-par" $ADIOS2_VERSION
            if [[ $? == 0 ]] ; then par_installed="yes"; fi
        fi

        if [ "$ser_installed" == "yes" ] && ([ "$parallel" == "no" ] || [ "$par_installed" == "yes" ]) ; then
            info "ADIOS2 already installed, skipping"
        else
            build_adios2
            if [[ $? != 0 ]] ; then
                error "Unable to build or install ADIOS2.  Bailing out."
            fi
            info "Done building ADIOS2"
        fi
    fi
}
function bv_advio_initialize
{
    export DO_ADVIO="no"
}

function bv_advio_enable
{
    DO_ADVIO="yes"
}

function bv_advio_disable
{
    DO_ADVIO="no"
}

function bv_advio_depends_on
{
    echo ""
}

function bv_advio_info
{
    export ADVIO_FILE=${ADVIO_FILE:-"AdvIO-1.2.tar.gz"}
    export ADVIO_VERSION=${ADVIO_VERSION:-"1.2"}
    export ADVIO_COMPATIBILITY_VERSION=${ADVIO_COMPATIBILITY_VERSION:-"1.2"}
    export ADVIO_BUILD_DIR=${ADVIO_BUILD_DIR:-AdvIO-1.2}
    export ADVIO_SHA256_CHECKSUM="cd89d8a7f1fe94c1bd2d04888028d8b2b98a37853c4a8d5b2b7417b83ea1e803"
}

function bv_advio_print
{
    printf "%s%s\n" "ADVIO_FILE=" "${ADVIO_FILE}"
    printf "%s%s\n" "ADVIO_VERSION=" "${ADVIO_VERSION}"
    printf "%s%s\n" "ADVIO_COMPATIBILITY_VERSION=" "${ADVIO_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "ADVIO_BUILD_DIR=" "${ADVIO_BUILD_DIR}"
}

function bv_advio_print_usage
{
    printf "%-20s %s [%s]\n" "--advio"   "Build AdvIO" "$DO_ADVIO"
}

function bv_advio_host_profile
{
    if [[ "$DO_ADVIO" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## AdvIO" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_ADVIO_DIR \${VISITHOME}/AdvIO/$ADVIO_VERSION/\${VISITARCH})"\
            >> $HOSTCONF
    fi

}

function bv_advio_ensure
{
    if [[ "$DO_ADVIO" == "yes" ]] ; then
        ensure_built_or_ready "AdvIO" $ADVIO_VERSION $ADVIO_BUILD_DIR $ADVIO_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_ADVIO="no"
            error "Unable to build AdvIO. ${ADVIO_FILE} not found. You can register and download it from: http://adventure.sys.t.u-tokyo.ac.jp/download/IO.html"
        fi
    fi
}

function apply_advio_12_configure_patch
{
    patch -p0 << \EOF
--- AdvIO-1.2/configure	2006-02-14 05:19:56.000000000 -0800
+++ AdvIO-1.2/configure.new	2024-02-09 16:28:49.000000000 -0800
@@ -1003,7 +1003,7 @@
 #line 1004 "configure"
 #include "confdefs.h"
 
-main(){return(0);}
+int main(){return(0);}
 EOF
 if { (eval echo configure:1009: \"$ac_link\") 1>&5; (eval $ac_link) 2>&5; } && test -s conftest${ac_exeext}; then
   ac_cv_prog_cc_works=yes
@@ -1897,11 +1897,12 @@
 #line 1898 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(short));
+  fprintf(f, "%d\n", (int)sizeof(short));
   exit(0);
 }
 EOF
@@ -1936,11 +1937,12 @@
 #line 1937 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(int));
+  fprintf(f, "%d\n", (int)sizeof(int));
   exit(0);
 }
 EOF
@@ -1975,11 +1977,12 @@
 #line 1976 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(long));
+  fprintf(f, "%d\n", (int)sizeof(long));
   exit(0);
 }
 EOF
@@ -2014,11 +2017,12 @@
 #line 2015 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(long long));
+  fprintf(f, "%d\n", (int)sizeof(long long));
   exit(0);
 }
 EOF
@@ -2053,11 +2057,12 @@
 #line 2054 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(float));
+  fprintf(f, "%d\n", (int)sizeof(float));
   exit(0);
 }
 EOF
@@ -2092,11 +2097,12 @@
 #line 2093 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(double));
+  fprintf(f, "%d\n", (int)sizeof(double));
   exit(0);
 }
 EOF
@@ -2131,11 +2137,12 @@
 #line 2132 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(long double));
+  fprintf(f, "%d\n", (int)sizeof(long double));
   exit(0);
 }
 EOF
@@ -2170,11 +2177,12 @@
 #line 2171 "configure"
 #include "confdefs.h"
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(size_t));
+  fprintf(f, "%d\n", (int)sizeof(size_t));
   exit(0);
 }
 EOF
@@ -2309,15 +2317,13 @@
   cat > conftest.$ac_ext <<EOF
 #line 2311 "configure"
 #include "confdefs.h"
-#ifdef __cplusplus
-extern "C" void exit(int);
-#endif
 #include <stdio.h>
+#include <stdlib.h>
-main()
+int main()
 {
   FILE *f=fopen("conftestval", "w");
   if (!f) exit(1);
-  fprintf(f, "%d\n", sizeof(bool));
+  fprintf(f, "%d\n", (int)sizeof(bool));
   exit(0);
 }
 EOF
@@ -3969,7 +3975,7 @@
 #============================================================
 
 
-subdirs="${subdirs} Base FileIO IDL DocIO doc"
+subdirs="${subdirs} Base FileIO DocIO doc"
 #if test "${adv_cv_lib_micogtk}" = "yes"; then
 #  subdirs="${subdirs} Frame"
 #  subdirs="${subdirs} Compo"
EOF
    if [[ $? != 0 ]] ; then
        echo "Failed applying AdvIO configure patch"
        return 1
    fi

    return 0 
}

function apply_advio_12_patch
{
    apply_advio_12_configure_patch

    return $?
}

function apply_advio_patch
{
    if [[ ${ADVIO_VERSION} == 1.2 ]] ; then
        apply_advio_12_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0
}

# *************************************************************************** #
#                         Function 8.18, build_advio                          #
#                                                                             #
# Kevin Griffin, Tue Nov 18 18:25:38 PST 2014                                 #
# Added patch for OS X 10.9 Mavericks.                                        #
#                                                                             #
# Kevin Griffin, Mon Aug 8 17:34:52 PDT 2016                                  #
# Updated patch for OS X 10.1*.                                               #
# *************************************************************************** #

function build_advio
{
    #
    # Prepare build dir
    #
    prepare_build_dir $ADVIO_BUILD_DIR $ADVIO_FILE
    untarred_ADVIO=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_ADVIO == -1 ]] ; then
        warn "Unable to prepare AdvIO Build Directory. Giving up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching AdvIO . . ."
    apply_advio_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_ADVIO == 1 ]] ; then
            warn "Giving up on AdvIO build because the patch failed."
            return 1
        else 
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Configure AdvIO
    #
    info "Configuring AdvIO . . ."
    cd $ADVIO_BUILD_DIR || error "Can't cd to AdvIO build dir."
    # Remove IDL dependencies from the build process
    sed "s%@idldir@%%g" Makefile.in > m2
    mv m2 Makefile.in
    sed "s%FileIO IDL DocIO%FileIO DocIO%g" configure > c2
    mv c2 configure
    chmod 750 ./configure
    info "Invoking command to configure AdvIO"
    ADVIO_HOST=""
    if [[ "$OPSYS" == "Darwin" ]]; then
        ADVIO_HOST="--host=darwin"
    elif [[ "$OPSYS" == "Linux" ]]; then
        ADVIO_HOST="--host=Linux"
    fi
    ADVIO_DEBUG=""
    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        ADVIO_DEBUG="--enable-debug"
    fi
    C_OPT_FLAGS="-Wno-error=implicit-function-declaration"
    set -x
    env CXX="$CXX_COMPILER" CC="$C_COMPILER" \
        CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
        ./configure --prefix="$VISITDIR/AdvIO/$ADVIO_VERSION/$VISITARCH" --disable-gtktest $ADVIO_HOST $ADVIO_DEBUG
    set +x
    if [[ $? != 0 ]] ; then
        warn "AdvIO configure failed.  Giving up"
        return 1
    fi

    #
    # Build AdvIO
    #
    info "Building AdvIO . . . (~1 minute)"

    $MAKE
    if [[ $? != 0 ]] ; then
        warn "AdvIO build failed.  Giving up"
        return 1
    fi

    # Install AdvIO
    info "Installing AdvIO"
    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "AdvIO install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/AdvIO"
        chgrp -R ${GROUP} "$VISITDIR/AdvIO"
    fi

    cd "$START_DIR"
    info "Done with AdvIO"
    return 0
}

function bv_advio_is_enabled
{
    if [[ $DO_ADVIO == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_advio_is_installed
{
    check_if_installed "AdvIO" $ADVIO_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_advio_build
{
    cd "$START_DIR"
    if [[ "$DO_ADVIO" == "yes" ]] ; then
        check_if_installed "AdvIO" $ADVIO_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping AdvIO build.  AdvIO is already installed."
        else
            info "Building AdvIO (~1 minutes)"
            build_advio
            if [[ $? != 0 ]] ; then
                error "Unable to build or install AdvIO.  Bailing out."
            fi
            info "Done building AdvIO"
        fi
    fi
}
# Module automatically read in from construct_build_visit

#initialize all the variables
function bv_anari_initialize
{
    export DO_ANARI="no"
    export DO_ANARI_NVTX="no"
    export USE_ALT_ANARI="no"
    add_extra_commandline_args "anari" "enable-vtk-nvtx" 0 "Enable NVTX instrumentation for VTK"
    add_extra_commandline_args "anari" "alt-anari-dir" 1 "Use alternate directory for ANARI"
}

#enable the module for install
function bv_anari_enable
{
    DO_ANARI="yes"
}

#disable the module for install
function bv_anari_disable
{
    DO_ANARI="no"
}

#enable NVTX instrumentation for VTK
function bv_anari_enable_vtk_nvtx
{
    bv_anari_enable
    DO_ANARI_NVTX="yes"
    info "Enabling NVTX instrumentation for VTK"
}

#use alternate ANARI dir
function bv_anari_alt_anari_dir
{
    bv_anari_enable
    USE_ALT_ANARI="yes"
    ALT_ANARI_DIR="$1"
    info "Using Alternate ANARI Directory: $ALT_ANARI_DIR"
}

#add any dependency with comma separation, both dependers and dependees
function bv_anari_depends_on
{
    depends_on="cmake"
    echo "${depends_on}"
}

#add information about how to get library..
function bv_anari_info
{
    export ANARI_VERSION=${ANARI_VERSION:-"0.14.1"}
    export ANARI_SHORT_VERSION=${ANARI_SHORT_VERSION:-"0.14"}
    export ANARI_FILE=${ANARI_FILE:-"ANARI-SDK-${ANARI_VERSION}.tar.gz"}
    export ANARI_COMPATIBILITY_VERSION=${ANARI_SHORT_VERSION}
    export ANARI_URL=${ANARI_URL:-"https://github.com/KhronosGroup/ANARI-SDK/archive/refs/tags/v0.14.1.tar.gz"}
    export ANARI_SRC_DIR=${ANARI_SRC_DIR:-"ANARI-SDK-${ANARI_VERSION}"}
    export ANARI_INSTALL_DIR=${ANARI_INSTALL_DIR:-"anari"}
    export ANARI_SHA256_CHECKSUM="a1df9e917bdb0b6edb0ad4b8e59e1171468a446f850559c74ad5731317201e16"
}

#print variables used by this module
function bv_anari_print
{
    printf "%s%s\n" "ANARI_FILE=" "${ANARI_FILE}"
    printf "%s%s\n" "ANARI_VERSION=" "${ANARI_VERSION}"
    printf "%s%s\n" "ANARI_SRC_DIR=" "${ANARI_SRC_DIR}"
}

#print how to install and uninstall module..
function bv_anari_print_usage
{
    printf "%-20s %s [%s]\n" "--anari"   "Build ANARI" "$DO_ANARI"
    printf "%-20s %s [%s]\n" "--alt-anari-dir"   "Use ANARI from an alternative directory" "$USE_ALT_ANARI"
}

#values to add to host profile, write to $HOSTCONF
function bv_anari_host_profile
{
    #Add code to write values to variable $HOSTCONF
    if [[ "$DO_ANARI" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## ANARI" >> $HOSTCONF
        echo "##" >> $HOSTCONF

	echo "SETUP_APP_VERSION(ANARI $ANARI_VERSION)" >> $HOSTCONF

        if [[ "$USE_ALT_ANARI" == "yes" ]] ; then
	    echo "VISIT_OPTION_DEFAULT(VISIT_ANARI_DIR $ALT_ANARI_DIR)" >> $HOSTCONF
	else
	    echo "VISIT_OPTION_DEFAULT(VISIT_ANARI_DIR \${VISITHOME}/anari/\${ANARI_VERSION}/\${VISITARCH})" >> $HOSTCONF
        fi
    fi
}

#prepare the module and check whether it is built or is ready to be built.
function bv_anari_ensure
{
    if [[ "$DO_ANARI" == "yes" && "$USE_ALT_ANARI" == "no" ]] ; then
        ensure_built_or_ready $ANARI_INSTALL_DIR $ANARI_VERSION $ANARI_SRC_DIR $ANARI_FILE $ANARI_URL

        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            bv_anari_disable
            error "Unable to build ANARI. ${ANARI_FILE} not found."
        fi
    fi
}

function build_anari
{
    if [[ -d $ANARI_SRC_DIR ]] ; then
        if [[ ! -f $ANARI_FILE ]] ; then
            warn "The directory ${ANARI_SRC_DIR} exists, deleting before downloading and uncompressing"
            rm -Rf $ANARI_SRC_DIR
            bv_anari_ensure

            if [[ "$DO_ANARI" == "no" ]] ; then
                return 1
            fi
        fi
    fi

    # Extract sources
    prepare_build_dir $ANARI_SRC_DIR $ANARI_FILE
    untarred_anari=$?
    # -1 on failure, 0 for success without untar
    #  1 for success with untar, 2 for failure with checksum

    if [[ $untarred_anari == -1 ]] ; then
        warn "Unable to prepare ANARI source directory. Giving Up!"
        return 1
    fi

    # Make build directory for an out-of-source build.
    ANARI_BUILD_DIR="${ANARI_SRC_DIR}-build"

    if [[ ! -d $ANARI_BUILD_DIR ]] ; then
        echo "Making build directory $ANARI_BUILD_DIR"
        mkdir $ANARI_BUILD_DIR
    fi

    # CMake config options
    anari_build_mode="${VISIT_BUILD_MODE}"
    anari_inst_path="${VISITDIR}/${ANARI_INSTALL_DIR}/${ANARI_VERSION}/${VISITARCH}"

    vopts="-DCMAKE_BUILD_TYPE:STRING=${anari_build_mode}"
    vopts="${vopts} -DCMAKE_INSTALL_PREFIX:PATH=${anari_inst_path}"
    vopts="${vopts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    vopts="${vopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    vopts="${vopts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS}\""
    vopts="${vopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS}\""
    vopts="${vopts} -DCMAKE_EXE_LINKER_FLAGS:STRING=${lf}"
    vopts="${vopts} -DCMAKE_MODULE_LINKER_FLAGS:STRING=${lf}"
    vopts="${vopts} -DCMAKE_SHARED_LINKER_FLAGS:STRING=${lf}"

    if test "${OPSYS}" = "Darwin" ; then
	    vopts="${vopts} -DCMAKE_INSTALL_NAME_DIR:PATH=${anari_inst_path}/lib"
    fi

    # ANARI config options
    if test "x${DO_STATIC_BUILD}" = "xyes" ; then
	    vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
	    vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi

    vopts="${vopts} -DBUILD_HELIDE_DEVICE:BOOL=ON"
    vopts="${vopts} -DBUILD_REMOTE_DEVICE:BOOL=OFF"
    vopts="${vopts} -DINSTALL_CODE_GEN_SCRIPTS:BOOL=ON"
    vopts="${vopts} -DBUILD_CTS:BOOL=OFF"
    vopts="${vopts} -DBUILD_EXAMPLES:BOOL=ON"
    vopts="${vopts} -DBUILD_TESTING:BOOL=OFF"
    vopts="${vopts} -DBUILD_VIEWER:BOOL=OFF"

    #
    # Configure and Build the ANARI SDK
    #
    cd ${ANARI_BUILD_DIR}
    rm -rf *

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"

    #
    # Several platforms have had problems with the VTK cmake configure command
    # issued simply via "issue_command".  This was first discovered on
    # BGQ and then showed up in random cases for both OSX and Linux machines.
    # Brad resolved this on BGQ  with a simple work around - we write a simple
    # script that we invoke with bash which calls cmake with all of the properly
    # arguments. We are now using this strategy for all platforms.
    #
    echo "\"${CMAKE_BIN}\"" ${vopts} ../${ANARI_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "ANARI configuration failed."

    #
    # Now build ANARI
    #
    info "Building ANARI . . ."
    env DYLD_LIBRARY_PATH=`pwd`/bin ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS || \
        error "ANARI did not build correctly.  Giving up."

    info "Installing ANARI . . . "
    ${CMAKE_COMMAND} --install . || error "ANARI did not install correctly."

    chmod -R ug+w,a+rX ${VISITDIR}/${ANARI_INSTALL_DIR}

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chgrp -R ${GROUP} "$VISITDIR/${ANARI_INSTALL_DIR}"
    fi

    cd "$START_DIR"
    return 0
}

function bv_anari_is_enabled
{
    if [[ $DO_ANARI == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_anari_is_installed
{
    if [[ "USE_ALT_ANARI" == "yes" ]]; then
	    return 1
    fi

    check_if_installed "anari" $ANARI_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

#the build command..
function bv_anari_build
{
    cd "$START_DIR"

    if [[ "$DO_ANARI" == "yes" && "$USE_ALT_ANARI" == "no" ]] ; then
        check_if_installed $ANARI_INSTALL_DIR $ANARI_VERSION

        if [[ $? == 0 ]] ; then
            info "Skipping ANARI build.  ANARI is already installed."
        else
            #Build the Module
            build_anari

            if [[ $? != 0 ]] ; then
                error "Unable to build or install ANARI.  Bailing out."
            fi

            info "Done building ANARI"
       	fi
    fi
}
# by default, turn blosc2 off
function bv_blosc2_initialize
{
    export DO_BLOSC2="no"
}

# Enables the module
function bv_blosc2_enable
{
    DO_BLOSC2="yes"
}

# Disables the module
function bv_blosc2_disable
{
    DO_BLOSC2="no"
}

# Where to get the module, the version, etc...
function bv_blosc2_info
{
    BLOSC2_DIR="${VISITDIR}/blosc2/${BLOSC2_VERSION}/${VISITARCH}"
    # note this is c-blosc2, NOT c-blosc
    export BLOSC2_VERSION=${BLOSC2_VERSION:-"2.11.3"}
    export BLOSC2_FILE=${BLOSC2_FILE:-"c-blosc2-${BLOSC2_VERSION}.tar.gz"}
    export BLOSC2_BUILD_DIR=${BLOSC2_BUILD_DIR:-"c-blosc2-${BLOSC2_VERSION}"}
    export BLOSC2_SHA256_CHECKSUM="7273ec3ab42adc247425ab34b0601db86a6e2a6aa1a97a11e29df02e078f5037"
}

# Ensure the module has been downloaded and extracted properly.
function bv_blosc2_ensure
{
    if [[ "$DO_BLOSC2" == "yes" ]] ; then
        ensure_built_or_ready "blosc2" $BLOSC2_VERSION $BLOSC2_BUILD_DIR $BLOSC2_FILE $BLOSC2_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_BLOSC2="no"
            error "Unable to build c-blosc2.  ${BLOSC2_FILE} not found."
        fi
    fi
}

# What other modules does c-blosc2 depend on.
function bv_blosc2_depends_on
{
    echo "cmake"
}

function build_blosc2
{
    #
    # Blosc2 uses CMake  -- make sure we have it.
    #
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}
    if [[ -e ${CMAKE_INSTALL}/cmake ]] ; then
        info "Blosc2: CMake found"
    else
        warn "Unable to find cmake, cannot build Blosc2. Giving up."
        return 1
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $BLOSC2_BUILD_DIR $BLOSC2_FILE
    untarred_blosc2=$?
    if [[ $untarred_blosc2 == -1 ]] ; then
        warn "Unable to prepare Blosc2 build directory. Giving Up!"
        return 1
    fi

    cd $BLOSC2_BUILD_DIR || error "Can't cd to BLOSC2 source dir."

    cfg_opts="-DCMAKE_INSTALL_PREFIX:PATH=${VISITDIR}/blosc2/${BLOSC2_VERSION}/${VISITARCH}"
    # Enable ssse3 target feature on intel and amd processors.
    if [[ "$(uname -m)" == "x86_64" ]] ; then
        cfg_opts="$cfg_opts -DCMAKE_C_FLAGS=-mssse3"
        cfg_opts="$cfg_opts -DCMAKE_CXX_FLAGS=-mssse3"
    fi

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"
    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi

    echo "\"${CMAKE_BIN}\"" ${cfg_opts} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh

    if [[ $? != 0 ]] ; then
        warn "Blosc2 configure failed.  Giving up"
        return 1
    fi

    #
    # Build Blosc2
    #
    info "Building Blosc2 . . . (~5 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Blosc2 build failed.  Giving up"
        return 1
    fi
    
    #
    # Install into the VisIt third party location.
    #
    info "Installing Blosc2"
    ${CMAKE_COMMAND} --install .
    if [[ $? != 0 ]] ; then
        warn "Blosc2 install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/blosc2"
        chgrp -R ${GROUP} "$VISITDIR/blosc2"
    fi

    cd "$START_DIR"
    info "Done with Blosc2"
    return 0
}

# build the module
function bv_blosc2_build
{
    cd "$START_DIR"
    if [[ "$DO_BLOSC2" == "yes" ]] ; then
        check_if_installed "blosc2" $BLOSC2_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Blosc2 build.  Blosc2 is already installed."
        else
            info "Building Blosc2 (~5 minutes)"

            build_blosc2
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Blosc2.  Bailing out."
            fi
            info "Done building Blosc2"
        fi
    fi
}

function bv_blosc2_print
{
    printf "%s%s\n" "BLOSC2_FILE=" "${BLOSC2_FILE}"
    printf "%s%s\n" "BLOSC2_VERSION=" "${BLOSC2_VERSION}"
    printf "%s%s\n" "BLOSC2_BUILD_DIR=" "${BLOSC2_BUILD_DIR}"
}

function bv_blosc2_print_usage
{
    printf "%-20s %s [%s]\n" "--blosc2" "Build Blosc2" "DO_BLOSC2"
}

function bv_blosc2_host_profile
{
    if [[ "$DO_BLOSC2" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## BLOSC2" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_BLOSC2_DIR \${VISITHOME}/blosc2/$BLOSC2_VERSION/\${VISITARCH})" \
             >> $HOSTCONF
    fi
}

function bv_blosc2_dry_run
{
    if [[ "$DO_BLOSC2" == "yes" ]] ; then
        echo "Dry run option not set for blosc2."
    fi
}

function bv_blosc2_is_installed
{
    check_if_installed "blosc2" $BLOSC2_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_blosc2_is_enabled
{
    if [[ $DO_BLOSC2 == "yes" ]]; then
        return 1
    fi
    return 0
}
function bv_boost_initialize
{
    export DO_BOOST="no"
    export USE_SYSTEM_BOOST="no"
    add_extra_commandline_args "boost" "alt-boost-dir" 1 "Use alternative directory for boost"
}

function bv_boost_enable
{
    DO_BOOST="yes"
}

function bv_boost_disable
{
    DO_BOOST="no"
}

function bv_boost_alt_boost_dir
{
    bv_boost_enable
    USE_SYSTEM_BOOST="yes"
    BOOST_INSTALL_DIR="$1"
}

function bv_boost_depends_on
{
    if [[ "$USE_SYSTEM_BOOST" == "yes" ]]; then
        echo ""
    else
        echo ""
    fi
}

function bv_boost_initialize_vars
{
    if [[ "$USE_SYSTEM_BOOST" == "no" ]]; then
        BOOST_INSTALL_DIR="${VISITDIR}/boost/${BOOST_VERSION}/${VISITARCH}"
    fi
}

function bv_boost_info
{
    export BOOST_VERSION=${BOOST_VERSION:-"1_67_0"}
    export BOOST_FILE=${BOOST_FILE:-"boost_${BOOST_VERSION}.tar.gz"}
    export BOOST_COMPATIBILITY_VERSION=${BOOST_COMPATIBILITY_VERSION:-"1_67"}
    export BOOST_BUILD_DIR=${BOOST_BUILD_DIR:-"boost_${BOOST_VERSION}"}
    export BOOST_SHA256_CHECKSUM="8aa4e330c870ef50a896634c931adf468b21f8a69b77007e45c444151229f665"
}

function bv_boost_print
{
    printf "%s%s\n" "BOOST_FILE=" "${BOOST_FILE}"
    printf "%s%s\n" "BOOST_VERSION=" "${BOOST_VERSION}"
    printf "%s%s\n" "BOOST_COMPATIBILITY_VERSION=" "${BOOST_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "BOOST_BUILD_DIR=" "${BOOST_BUILD_DIR}"
}

function bv_boost_print_usage
{
    printf "%-20s %s [%s]\n" "--boost" "Build BOOST" "${DO_BOOST}"
    printf "%-20s %s [%s]\n" "--alt-boost-dir" "Use Boost from an alternative directory"
}

function bv_boost_host_profile
{
    if [[ "$DO_BOOST" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## BOOST" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        echo "SETUP_APP_VERSION(BOOST $BOOST_VERSION)" >> $HOSTCONF
        if [[ "$USE_SYSTEM_BOOST" == "yes" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_BOOST_DIR $BOOST_INSTALL_DIR)" \
                >> $HOSTCONF 
        else
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_BOOST_DIR \${VISITHOME}/boost/\${BOOST_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF 
        fi
    fi
}

function bv_boost_ensure
{
    if [[ "$DO_BOOST" == "yes" && "$USE_SYSTEM_BOOST" == "no" ]] ; then
        ensure_built_or_ready "boost" $BOOST_VERSION $BOOST_BUILD_DIR $BOOST_FILE $BOOST_URL 
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_BOOST="no"
            error "Unable to build BOOST.  ${BOOST_FILE} not found."
        fi
    fi
}

function apply_boost_ppc_rounding_control_patch
{
   # resolves a C++11 narrowing error

   patch -p0 << \EOF
*** boost/numeric/interval/detail/ppc_rounding_control.hpp.orig       Mon Aug 17 15:26:50 2020
--- boost/numeric/interval/detail/ppc_rounding_control.hpp    Mon Aug 17 15:27:12 2020
***************
*** 28,37 ****
    double dmode;
  } rounding_mode_struct;
  
! static const rounding_mode_struct mode_upward      = { 0xFFF8000000000002LL };
! static const rounding_mode_struct mode_downward    = { 0xFFF8000000000003LL };
! static const rounding_mode_struct mode_to_nearest  = { 0xFFF8000000000000LL };
! static const rounding_mode_struct mode_toward_zero = { 0xFFF8000000000001LL };
  
  struct ppc_rounding_control
  {
--- 28,37 ----
    double dmode;
  } rounding_mode_struct;
  
! static const rounding_mode_struct mode_upward      = { (long long int)0xFFF8000000000002LL };
! static const rounding_mode_struct mode_downward    = { (long long int)0xFFF8000000000003LL };
! static const rounding_mode_struct mode_to_nearest  = { (long long int)0xFFF8000000000000LL };
! static const rounding_mode_struct mode_toward_zero = { (long long int)0xFFF8000000000001LL };
  
  struct ppc_rounding_control
  {
EOF

   if [[ $? != 0 ]] ; then
      warn "boost patch for ppc_rounding_control failed."
      return 1
    fi
    return 0;
}

function apply_boost_patch
{
    apply_boost_ppc_rounding_control_patch
    if [[ $? != 0 ]] ; then
       return 1
    fi
    return 0;
}

# *************************************************************************** #
#                          Function 8.1, build_boost                           #
# *************************************************************************** #

function build_boost
{
    #
    # Prepare build dir
    #
    prepare_build_dir $BOOST_BUILD_DIR $BOOST_FILE
    untarred_boost=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_boost == -1 ]] ; then
        warn "Unable to prepare BOOST Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    cd $BOOST_BUILD_DIR || error "Can't cd to BOOST build dir."
    apply_boost_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_boost == 1 ]] ; then
            warn "Giving up on Boost build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    # Get a list of libraries to build. This list of libraries is used
    # for the OS X name fix up.

    # This list must include dependent libraries also. For instance,
    # the serialization library requires the wserialization
    # library. So it too must be listed. However, it can not be in the
    # build_libs list otherwise boost barfs.
    libs=""

    if [[ "$DO_DAMARIS" == "yes" ]] ; then
        libs="$libs \
              date_time system filesystem"
    fi

    if [[ "$DO_NEKTAR_PLUS_PLUS" == "yes" ]] ; then
        libs="$libs \
              chrono iostreams thread date_time filesystem \
              system program_options regex timer"
    fi
    
#    if [[ "$DO_UINTAH" == "yes" ]] ; then
#        libs="$libs \
#              chrono filesystem wserialization serialization system thread signals date_time program_options"
#    fi

    # Remove all of the duplicate libs.
    libs=`echo $libs | tr ' ' '\n' | sort -u | tr '\n' ' ' | sed s'/.$//'`

    # Note: the library name 'wserialization' can not be in the list
    # of build libraries but must be part of the name fixup for OS X.
    build_libs=`echo $libs | sed s'/ wserialization//' | tr ' ' ','`

    if [[ "$build_libs" != ""  ]] ; then

        build_libs=" --with-libraries=\"$build_libs\" "

        info "Configuring BOOST . . . $build_libs"

        #        if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        #            cf_build_type="--disable-shared --enable-static"
        #        else
        #            cf_build_type="--enable-shared --disable-static"
        #        fi

        #        if [[ "$DO_THREAD_BUILD" == "yes" ]]; then
        #            cf_build_thread="--enable-threadsafe --with-pthread"
        #        else
        #            cf_build_thread=""
        #        fi

        # In order to ensure $FORTRANARGS is expanded to build the arguments to
        # configure, we wrap the invokation in 'sh -c "..."' syntax
        info "Invoking command to configure BOOST"

        set -x
        sh -c "./bootstrap.sh $build_libs \
            --prefix=\"$VISITDIR/boost/$BOOST_VERSION/$VISITARCH\" "

        set +x
        if [[ $? != 0 ]] ; then
            warn "BOOST configure failed.  Giving up"
            return 1
        fi

        #
        # Build BOOST
        #
        info "Making BOOST . . ."

        sh -c "./b2"
        if [[ $? != 0 ]] ; then
            warn "BOOST build failed.  Giving up"
            return 1
        fi

        #
        # Install into the VisIt third party location.
        #
        info "Installing BOOST . . ."
        sh -c "./b2 install \
              --prefix=\"$VISITDIR/boost/$BOOST_VERSION/$VISITARCH\" "

        if [[ $? != 0 ]] ; then
            warn "BOOST install failed.  Giving up"
            return 1
        fi

        if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
            #
            # Make dynamic executable, need to patch up the install path and
            # version information.
            #
            info "Creating dynamic libraries for BOOST . . ."
            INSTALLNAMEPATH="${BOOST_INSTALL_DIR}/lib"

            for lib in $libs;
            do
                fulllibname=$INSTALLNAMEPATH/libboost_${lib}.${SO_EXT}

                install_name_tool -id $fulllibname $fulllibname

                # Find all the dependent libraries (more or less)
                deplibs=`otool -L $fulllibname | sed "s/(.*)//g"`

                for deplib in $deplibs;
                do
                    # Only get the libraries related to boost and not itself.
                    if [[ `echo $deplib | grep -c libboost_` == 1 && \
                                `echo $deplib | grep -c libboost_${lib}` == 0 ]] ; then

                        # Get the library name sans the directory path
                        deplibname=`echo $deplib | sed "s/.*\///"`
                        
                        # Set the library path
                        install_name_tool -change $deplib \
                                          ${INSTALLNAMEPATH}/$deplibname \
                                          $fulllibname

                    fi
                done            
            done
        fi

    else
        info "Installing BOOST . . . headers only"

        mkdir "$VISITDIR/boost"
        mkdir "$VISITDIR/boost/$BOOST_VERSION"
        mkdir "$VISITDIR/boost/$BOOST_VERSION/$VISITARCH"
        mkdir "$VISITDIR/boost/$BOOST_VERSION/$VISITARCH/include"

        cp -r boost $VISITDIR/boost/$BOOST_VERSION/$VISITARCH/include

        if [[ $? != 0 ]] ; then
            warn "BOOST install failed.  Giving up"
            return 1
        fi
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/boost"
        chgrp -R ${GROUP} "$VISITDIR/boost"
    fi
    cd "$START_DIR"
    info "Done with BOOST"
    return 0
}

function bv_boost_is_enabled
{
    if [[ $DO_BOOST == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_boost_is_installed
{
    if [[ "$USE_SYSTEM_BOOST" == "yes" ]]; then
        return 1
    fi

    check_if_installed "boost" $BOOST_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_boost_build
{
    cd "$START_DIR"

    if [[ "$DO_BOOST" == "yes" && "$USE_SYSTEM_BOOST" == "no" ]] ; then
        check_if_installed "boost" $BOOST_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping BOOST build.  BOOST is already installed."
        else
            info "Building BOOST (~15 minutes)"
            build_boost
            if [[ $? != 0 ]] ; then
                error "Unable to build or install BOOST.  Bailing out."
            fi
            info "Done building BOOST"
        fi
    fi
}



# Notes to Windows developers on building boost:
# grab the .zip or .7z tarball and extract
# Open command prompt in the extracted boost_<version> directory
# To build everything and install to default C:\Boost location:
#   .\bootstrap
#   .\b2
#   .\b2 install
#
# To change install location, add --prefix="\path\to\boost" to
# all commands. (All might be overkill, but I experienced problems
# when specified for only bootrap or b2, so I added it to all).
#
# If you want shared libs only, linked with shared CRT, release only, 64-bit:
#
#   .\boostrap --prefix="C:\path\to\where\you\want\boost"
#   .\b2 --prefix="C:\path\to\where\you\want\boost" link=shared runtime-link=shared variant=release threading=multi address-model=64
#   .\b2 --prefix="C:\path\to\where\you\want\boost" link=shared runtime-link=shared variant=release threading=multi address-model=64 install
#
# If you only want a subset of the libraries add a '--with-<lib>' for each 
# library you want:
#   .\boostrap --prefix="C:\path\to\where\you\want\boost"
#   .\b2 --with-system --prefix="C:\path\to\where\you\want\boost" link=shared runtime-link=shared variant=release threading=multi address-model=64
#   .\b2 --with-system --prefix="C:\path\to\where\you\want\boost" link=shared runtime-link=shared variant=release threading=multi address-model=64 install
#
# Still not certain that all the arguments are needed for the 'install' step
# of running b2, but I ran into problems without using them, so ...
#
# I found the following links helpful, as well as running '.\b2 --help'
# once I had bootstrapped.
#
# http://www.boost.org/doc/libs/1_57_0/more/getting_started/windows.html#simplified-build-from-source
# 
# http://www.boost.org/build/doc/html/bbv2/overview/invocation.html
function bv_boxlib_initialize
{
    export DO_BOXLIB="no"
}

function bv_boxlib_enable
{
    DO_BOXLIB="yes"
}

function bv_boxlib_disable
{
    DO_BOXLIB="no"
}

function bv_boxlib_depends_on
{
    echo ""
}

function bv_boxlib_info
{
    export BOXLIB_VERSION=${BOXLIB_VERSION:-"1.3.5"}
    export BOXLIB_FILE=${BOXLIB_FILE:-"ccse-${BOXLIB_VERSION}.tar.gz"}
    export BOXLIB_COMPATIBILITY_VERSION=${BOXLIB_COMPATIBILITY_VERSION:-"1.3.5"}
    export BOXLIB_BUILD_DIR=${BOXLIB_BUILD_DIR:-"ccse-${BOXLIB_VERSION}/Src/C_BaseLib"}
    export BOXLIB_SHA256_CHECKSUM="2dd2496d27dc84d9171be06b44e3968fa481867d936174e7d49a547da5f6f755"
}

function bv_boxlib_print
{
    printf "%s%s\n" "BOXLIB_FILE=" "${BOXLIB_FILE}"
    printf "%s%s\n" "BOXLIB_VERSION=" "${BOXLIB_VERSION}"
    printf "%s%s\n" "BOXLIB_COMPATIBILITY_VERSION=" "${BOXLIB_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "BOXLIB_BUILD_DIR=" "${BOXLIB_BUILD_DIR}"
}

function bv_boxlib_print_usage
{
    printf "%-20s %s [%s]\n" "--boxlib"  "Build Boxlib" "$DO_BOXLIB" 
}

function bv_boxlib_host_profile
{
    if [[ "$DO_BOXLIB" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Boxlib" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_BOXLIB_DIR \${VISITHOME}/boxlib/$BOXLIB_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi

}

function bv_boxlib_ensure
{
    if [[ "$DO_BOXLIB" == "yes" ]] ; then
        ensure_built_or_ready "boxlib" $BOXLIB_VERSION $BOXLIB_BUILD_DIR $BOXLIB_FILE $BOXLIB_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_BOXLIB="no"
            error "Unable to build Boxlib.  ${BOXLIB_FILE} not found."
        fi
    fi
}
# *************************************************************************** #
#                         Function 8.8, build_boxlib                          #
# *************************************************************************** #

function apply_nan_inf_patch
{
    patch -p0 << \EOF
diff -c a/Src/C_BaseLib/FArrayBox.cpp ccse-1.3.5/Src/C_BaseLib/FArrayBox.cpp
*** a/Src/C_BaseLib/FArrayBox.cpp
--- ccse-1.3.5/Src/C_BaseLib/FArrayBox.cpp
***************
*** 21,30 ****
  #include <BL_CXX11.H>
  #include <MemPool.H>
  
- #ifdef BL_Darwin
  using std::isinf;
  using std::isnan;
- #endif
  
  #if defined(DEBUG) || defined(BL_TESTING)
  bool FArrayBox::do_initval = true;
--- 21,28 ----
EOF
    if [[ $? != 0 ]] ; then
        warn "boxlib patch failed."
        return 1
    fi

    return 0;

}

function apply_endian_patch
{
    patch -p0 << \EOF
--- ccse-1.3.5/Src/C_BaseLib/FPC.cpp	2016-02-18 18:15:45.000000000 -0800
+++ ccse-1.3.5-patched/Src/C_BaseLib/FPC.cpp	2024-02-16 09:03:09.837102000 -0800
@@ -23,7 +23,8 @@
 IntDescriptor&
 FPC::NativeLongDescriptor ()
 {
-#if defined(__i486__) || \
+#if (defined(__BYTE_ORDER__)&&(__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)) || \
+    defined(__i486__) || \
     defined(WIN32) || \
     defined(i386) || \
     defined(__i386__) || \
@@ -33,7 +34,8 @@
     static const IntDescriptor nld(sizeof(long), IntDescriptor::ReverseOrder);
 #endif
 
-#if defined(__sgi) || \
+#if (defined(__BYTE_ORDER__)&&(__BYTE_ORDER__ == __ORDER_BIG_ENDIAN__)) || \
+    defined(__sgi) || \
     defined(__sun) || \
     defined(_AIX)  || \
     defined(__ppc__) || \
@@ -50,7 +52,8 @@
 RealDescriptor&
 FPC::NativeRealDescriptor ()
 {
-#if defined(__i486__) || \
+#if (defined(__BYTE_ORDER__)&&(__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)) || \
+    defined(__i486__) || \
     defined(WIN32) || \
     defined(i386) || \
     defined(__i386__) || \
@@ -63,7 +66,8 @@
 #endif
 #endif
 
-#if defined(__sgi) || \
+#if (defined(__BYTE_ORDER__)&&(__BYTE_ORDER__ == __ORDER_BIG_ENDIAN__)) || \
+    defined(__sgi) || \
     defined(__sun) || \
     defined(_AIX)  || \
     defined(__ppc__) || \
@@ -85,7 +89,8 @@
 RealDescriptor&
 FPC::Native32RealDescriptor ()
 {
-#if defined(__i486__) || \
+#if (defined(__BYTE_ORDER__)&&(__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)) || \
+    defined(__i486__) || \
     defined(WIN32) || \
     defined(i386) || \
     defined(__i386__) || \
@@ -94,7 +99,8 @@
     static const RealDescriptor n32rd(ieee_float, reverse_float_order, 4);
 #endif
 
-#if defined(__sgi) || \
+#if (defined(__BYTE_ORDER__)&&(__BYTE_ORDER__ == __ORDER_BIG_ENDIAN__)) || \
+    defined(__sgi) || \
     defined(__sun) || \
     defined(_AIX)  || \
     defined(__ppc__) || \
@@ -138,6 +144,7 @@
       defined(__hpux)   || \
       defined(powerpc)  || \
       defined(_MSC_VER) || \
+      defined(__BYTE_ORDER__) || \
       defined(_AIX))
 #error We do not yet support FAB I/O on this machine
 #endif
EOF
    if [[ $? != 0 ]] ; then
        warn "endianness patch failed."
        return 1
    fi

    return 0;
}


function apply_darwin_patch_1
{
    patch -p0 << \EOF
--- ccse-1.3.5/Src/C_BaseLib/VisMF.cpp	2021-03-30 08:21:05.000000000 -0700
+++ VisMF.cpp.new	2021-03-30 08:21:16.000000000 -0700
@@ -200,16 +200,20 @@
     {
         ar[i].resize(M);
 
+        std::string line;
+        std::string delimiter = ",";
+        is >> line;
+
         for (long j = 0; j < M; j++)
         {
+            std::string nextValue = line.substr(0, line.find(delimiter));
+            line = line.substr(line.find(delimiter) + 1);
 #ifdef BL_USE_FLOAT
-            is >> dtemp >> ch;
+            dtemp = std::atof(nextValue.c_str()); 
             ar[i][j] = static_cast<Real>(dtemp);
 #else
-            is >> ar[i][j] >> ch;
+            ar[i][j] = std::atof(nextValue.c_str());
 #endif
-	    if ( ch != ',' ) 
-	      BoxLib::Error("Expected a ',' got something else");
         }
     }
 
EOF
    if [[ $? != 0 ]] ; then
        warn "darwin patch failed."
        return 1
    fi

    return 0;
}

function apply_boxlib_patch
{
    apply_nan_inf_patch
    if [[ $? != 0 ]]; then
        return 1
    fi

    apply_endian_patch
    if [[ $? != 0 ]]; then
        return 1
    fi

    if [[ "$OPSYS" == "Darwin" ]]; then
        apply_darwin_patch_1
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0;
}

function build_boxlib
{
    #
    # Prepare build dir
    #
    prepare_build_dir $BOXLIB_BUILD_DIR $BOXLIB_FILE
    untarred_boxlib=$?
    if [[ $untarred_boxlib == -1 ]] ; then
        warn "Unable to prepare Boxlib Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching Boxlib . . ."
    apply_boxlib_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_boxlib == 1 ]] ; then
            warn "Giving up on Boxlib build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    cd $BOXLIB_BUILD_DIR || error "Can't cd to BoxLib build dir."

    #
    # Build BoxLib
    #
    info "Building Boxlib. . . (~4 minutes)"

    set -x
    if [[ "$OPSYS" == "Darwin" ]]; then
        $MAKE -f GNUmakefile CXX="$CXX_COMPILER" CC="$C_COMPILER" \
              CCFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
              DEBUG="FALSE" DIM=3 USE_MPI="FALSE" BL_MANGLE_SYMBOLS_WITH_DIM="TRUE" \
              BL_NO_FORT="TRUE" || error "Boxlib build failed. Giving up"

        $MAKE -f GNUmakefile CXX="$CXX_COMPILER" CC="$C_COMPILER" \
              CCFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
              DEBUG="FALSE" DIM=2 USE_MPI="FALSE" BL_MANGLE_SYMBOLS_WITH_DIM="TRUE" \
              BL_NO_FORT="TRUE" || error "Boxlib build failed. Giving up"
    else
        $MAKE -f GNUmakefile CXX="$CXX_COMPILER" CC="$C_COMPILER" \
              CCFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
              DEBUG="FALSE" DIM=3 USE_MPI="FALSE" \
              BL_NO_FORT="TRUE" || error "Boxlib build failed. Giving up"

        $MAKE -f GNUmakefile CXX="$CXX_COMPILER" CC="$C_COMPILER" \
              CCFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
              DEBUG="FALSE" DIM=2 USE_MPI="FALSE" \
              BL_NO_FORT="TRUE" || error "Boxlib build failed. Giving up"
    fi
    set +x
    #
    # Create dynamic library for Darwin
    #
    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        INSTALLNAMEPATH="$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH/lib"

        $CXX_COMPILER -dynamiclib -o libbox3D.$SO_EXT o/3d.Darwin.*/*.o \
                      -lSystem -Wl,-headerpad_max_install_names \
                      -Wl,-install_name,$INSTALLNAMEPATH/libbox3D.$SO_EXT \
                      -Wl,-compatibility_version,$BOXLIB_COMPATIBILITY_VERSION \
                      -Wl,-current_version,$BOXLIB_VERSION || \
            error "Creation of dynamic 3D Boxlib library failed. Giving up!"
        $CXX_COMPILER -dynamiclib -o libbox2D.$SO_EXT o/2d.Darwin.*/*.o \
                      -lSystem -Wl,-headerpad_max_install_names \
                      -Wl,-install_name,$INSTALLNAMEPATH/libbox2D.$SO_EXT \
                      -Wl,-compatibility_version,$BOXLIB_COMPATIBILITY_VERSION \
                      -Wl,-current_version,$BOXLIB_VERSION || \
            error "Creation of dynamic 2D Boxlib library failed. Giving up!"
        boxlib_ext=$SO_EXT
    else
        mv libbox3d.*.a libbox3D.a
        mv libbox2d.*.a libbox2D.a
        boxlib_ext=a
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing Boxlib . . ."

    mkdir "$VISITDIR/boxlib"
    mkdir "$VISITDIR/boxlib/$BOXLIB_VERSION"
    mkdir "$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH"
    mkdir "$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH/include"
    mkdir "$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH/lib"

    cp libbox3D.$boxlib_ext \
       "$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH/lib/" || \
        error "Boxlib install failed. Giving up!"

    cp libbox2D.$boxlib_ext \
       "$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH/lib/" || \
        error "Boxlib install failed. Giving up!"

    cp *.H "$VISITDIR/boxlib/$BOXLIB_VERSION/$VISITARCH/include" || \
        error "Boxlib install failed. Giving up!"

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/boxlib"
        chgrp -R ${GROUP} "$VISITDIR/boxlib"
    fi

    cd "$START_DIR"
    info "Done with BoxLib"
    return 0
}

function bv_boxlib_is_enabled
{
    if [[ $DO_BOXLIB == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_boxlib_is_installed
{
    check_if_installed "boxlib" $BOXLIB_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_boxlib_build
{
    cd "$START_DIR"
    if [[ "$DO_BOXLIB" == "yes" ]] ; then
        check_if_installed "boxlib" $BOXLIB_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Boxlib build.  Boxlib is already installed."
        else
            info "Building Boxlib (~2 minutes)"
            build_boxlib
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Boxlib.  Bailing out."
            fi
            info "Done building Boxlib"
        fi
    fi
}
function bv_cfitsio_initialize
{
    export DO_CFITSIO="no"
}

function bv_cfitsio_enable
{
    DO_CFITSIO="yes"
}

function bv_cfitsio_disable
{
    DO_CFITSIO="no"
}

function bv_cfitsio_depends_on
{
    echo ""
}

function bv_cfitsio_info
{
    export CFITSIO_FILE=${CFITSIO_FILE:-"cfitsio3006.tar.gz"}
    export CFITSIO_VERSION=${CFITSIO_VERSION:-"3006"}
    export CFITSIO_COMPATIBILITY_VERSION=${CFITSIO_COMPATIBILITY_VERSION:-"3.0"}
    export CFITSIO_BUILD_DIR=${CFITSIO_BUILD_DIR:-"cfitsio"}
    export CFITSIO_SHA256_CHECKSUM="c156ee0becee8987a14229e705f0f9f39dd2b73bbc9e73bc5d69f43896cb9a63"
}

function bv_cfitsio_print
{
    printf "%s%s\n" "CFITSIO_FILE=" "${CFITSIO_FILE}"
    printf "%s%s\n" "CFITSIO_VERSION=" "${CFITSIO_VERSION}"
    printf "%s%s\n" "CFITSIO_COMPATIBILITY_VERSION=" "${CFITSIO_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "CFITSIO_BUILD_DIR=" "${CFITSIO_BUILD_DIR}"
}

function bv_cfitsio_print_usage
{
    printf "%-20s %s [%s]\n" "--cfitsio" "Build CFITSIO" "$DO_CFITSIO"
}

function bv_cfitsio_host_profile
{
    if [[ "$DO_CFITSIO" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## CFITSIO" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_CFITSIO_DIR \${VISITHOME}/cfitsio/$CFITSIO_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi

}
function bv_cfitsio_ensure
{
    if [[ "$DO_CFITSIO" == "yes" ]] ; then
        ensure_built_or_ready "cfitsio" $CFITSIO_VERSION $CFITSIO_BUILD_DIR $CFITSIO_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_CFITSIO="no"
            error "Unable to build CFITSIO.  ${CFITSIO_FILE} not found."
        fi
    fi
}
# *************************************************************************** #
#                         Function 8.9, build_cfitsio                         #
# *************************************************************************** #

function apply_mv_vs_cp_patch
{
    patch -p0 << \EOF
--- cfitsio/Makefile.in	2024-02-20 16:26:11.776100000 -0800
+++ cfitsio_patched/Makefile.in	2024-02-20 16:34:10.879376000 -0800
@@ -88,10 +88,10 @@
 
 install:	libcfitsio.a ${CFITSIO_PREFIX} ${CFITSIO_LIB} ${CFITSIO_INCLUDE}
 		@if [ -f libcfitsio.a ]; then \
-			/bin/mv libcfitsio.a ${CFITSIO_LIB}; \
+			/bin/cp libcfitsio.a ${CFITSIO_LIB}; \
 		fi; \
 		if [ -f libcfitsio${SHLIB_SUFFIX} ]; then \
-			/bin/mv libcfitsio${SHLIB_SUFFIX} ${CFITSIO_LIB}; \
+			/bin/cp libcfitsio${SHLIB_SUFFIX} ${CFITSIO_LIB}; \
 		fi; \
 		/bin/cp fitsio.h fitsio2.h longnam.h drvrsmem.h ${CFITSIO_INCLUDE}/

EOF
    if [[ $? != 0 ]] ; then
        warn "CFITSIO Makefile patch failed."
        return 1
    fi

    return 0;

}

function apply_cfitsio_configure_patch
{
    # fixes configure error on Fedora40 with gcc 14.
    patch -p0 << \EOF
diff -u cfitsio/configure.orig cfitsio/configure
--- cfitsio/configure.orig	2025-07-07 15:51:29.700266000 -0700
+++ cfitsio/configure	2025-07-07 15:51:39.430265000 -0700
@@ -764,7 +764,7 @@
 #line 765 "configure"
 #include "confdefs.h"
 
-main(){return(0);}
+int main(){return(0);}
 EOF
 if { (eval echo configure:770: \"$ac_link\") 1>&5; (eval $ac_link) 2>&5; } && test -s conftest${ac_exeext}; then
   ac_cv_prog_cc_works=yes
EOF
    if [[ $? != 0 ]] ; then
        warn "CFITSIO configure patch failed."
        return 1
    fi

    return 0;
}

function apply_cfitsio_patch
{
    apply_mv_vs_cp_patch
    if [[ $? != 0 ]]; then
        return 1
    fi

    apply_cfitsio_configure_patch
    if [[ $? != 0 ]]; then
        return 1
    fi

    return 0;
}

function build_cfitsio
{
    #
    # Prepare build dir
    #
    prepare_build_dir $CFITSIO_BUILD_DIR $CFITSIO_FILE
    untarred_cfitsio=$?
    if [[ $untarred_cfitsio == -1 ]] ; then
        warn "Unable to prepare CFITSIO Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching cfitsio . . ."
    apply_cfitsio_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_cfitsio == 1 ]] ; then
            warn "Giving up on CFITSIO build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    info "Configuring CFITSIO . . ."
    cd $CFITSIO_BUILD_DIR || error "Can't cd to cfits IO build dir."

    #
    # Fix an issue with configure
    #
    if [[ "$OPSYS" == "Darwin" && $(uname -r | cut -d'.' -f1) -ge 23 ]]; then
        sed -i '' 's/^main(){return(0);}/int main(){return(0);}/' configure
    fi

    C_OPT_FLAGS="-Wno-error=implicit-function-declaration"
    set -x
    env CXX="$CXX_COMPILER" CC="$C_COMPILER" \
        CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
        ./configure \
        --prefix="$VISITDIR/cfitsio/$CFITSIO_VERSION/$VISITARCH"
    set +x
    if [[ $? != 0 ]] ; then
        warn "CFITSIO configure failed.  Giving up"
        return 1
    fi

    #
    # Build CFITSIO
    #
    info "Building CFITSIO . . . (~2 minutes)"

    $MAKE
    if [[ $? != 0 ]] ; then
        warn "CFITSIO build failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        #
        # Make dynamic executable
        #
        info "Creating dynamic libraries for CFITSIO . . ."

        INSTALLNAMEPATH="$VISITDIR/cfitsio/${CFITSIO_VERSION}/$VISITARCH/lib"
        ## switch back to gcc "external relocation entries" restFP saveFP
        ##      /usr/bin/libtool -o libcfitsio.$SO_EXT -dynamic libcfitsio.a -lSystem \
        ##      -headerpad_max_install_names \
        ##      -install_name $INSTALLNAMEPATH/libcfitsio.$SO_EXT \
        ##      -compatibility_version $CFITSIO_COMPATIBILITY_VERSION \
        ##      -current_version $CFITSIO_VERSION
        gcc -o libcfitsio.$SO_EXT -dynamiclib *.o -lSystem \
            -Wl,-headerpad_max_install_names \
            -Wl,-install_name,$INSTALLNAMEPATH/libcfitsio.$SO_EXT \
            -Wl,-compatibility_version,$CFITSIO_COMPATIBILITY_VERSION \
            -Wl,-current_version,$CFITSIO_VERSION
        if [[ $? != 0 ]] ; then
            warn "Creating dynamic CFITSIO library failed.  Giving up"
            return 1
        fi
        #       cp libcfitsio.$SO_EXT "$VISITDIR/cfitsio/$CFITSIO_VERSION/$VISITARCH/lib"
    fi
    #
    # Install into the VisIt third party location.
    #
    info "Installing CFITSIO . . ."

    mkdir "$VISITDIR/cfitsio"
    mkdir "$VISITDIR/cfitsio/$CFITSIO_VERSION"
    mkdir "$VISITDIR/cfitsio/$CFITSIO_VERSION/$VISITARCH"

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "CFITSIO install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/cfitsio"
        chgrp -R ${GROUP} "$VISITDIR/cfitsio"
    fi
    cd "$START_DIR"
    info "Done with CFITSIO"
    return 0
}

function bv_cfitsio_is_enabled
{
    if [[ $DO_CFITSIO == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_cfitsio_is_installed
{
    check_if_installed "cfitsio" $CFITSIO_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_cfitsio_build
{
    cd "$START_DIR"
    if [[ "$DO_CFITSIO" == "yes" ]] ; then
        check_if_installed "cfitsio" $CFITSIO_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping CFITSIO build.  CFITSIO is already installed."
        else
            info "Building CFITSIO (~2 minutes)"
            build_cfitsio
            if [[ $? != 0 ]] ; then
                error "Unable to build or install CFITSIO.  Bailing out."
            fi
            info "Done building CFITSIO"
        fi
    fi
}
function bv_cgns_initialize
{
    export DO_CGNS="no"
}

function bv_cgns_enable
{
    DO_CGNS="yes"
}

function bv_cgns_disable
{
    DO_CGNS="no"
}

function bv_cgns_depends_on
{
    local depends=""
    if [[ "$DO_HDF5" == "yes" ]] ; then
        depends="hdf5"
        if [[ "$DO_SZIP" == "yes" ]] ; then
            depends="szip hdf5"
        fi
    fi
    
    echo $depends
}

function bv_cgns_info
{
    export CGNS_FILE=${CGNS_FILE:-"CGNS-4.1.0.tar.gz"}
    export CGNS_VERSION=${CGNS_VERSION:-"4.1.0"}
    export CGNS_COMPATIBILITY_VERSION=${CGNS_COMPATIBILITY_VERSION:-"4.1"}
    export CGNS_BUILD_DIR=${CGNS_BUILD_DIR:-"CGNS-4.1.0/src"}
    export CGNS_SHA256_CHECKSUM="b4584e4d0fa52c737a0fb4738157a88581df251c8c5886175ee287e1777e99fd"
}

function bv_cgns_print
{
    printf "%s%s\n" "CGNS_FILE=" "${CGNS_FILE}"
    printf "%s%s\n" "CGNS_VERSION=" "${CGNS_VERSION}"
    printf "%s%s\n" "CGNS_COMPATIBILITY_VERSION=" "${CGNS_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "CGNS_BUILD_DIR=" "${CGNS_BUILD_DIR}"
}

function bv_cgns_print_usage
{
    printf "%-20s %s [%s]\n" "--cgns"    "Build CGNS" "$DO_CGNS" 
}

function bv_cgns_host_profile
{
    if [[ "$DO_CGNS" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## CGNS" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_CGNS_DIR \${VISITHOME}/cgns/$CGNS_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
        if [[ "$DO_HDF5" == "yes" ]] ; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_CGNS_LIBDEP HDF5_LIBRARY_DIR hdf5 \${VISIT_HDF5_LIBDEP} TYPE STRING)" \
                >> $HOSTCONF
        fi
    fi

}

function bv_cgns_ensure
{
    if [[ "$DO_CGNS" == "yes" ]] ; then
        ensure_built_or_ready "cgns" $CGNS_VERSION $CGNS_BUILD_DIR $CGNS_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_CGNS="no"
            error "Unable to build CGNS.  ${CGNS_FILE} not found."
        fi
    fi
}

function apply_cgns_410_patch
{
    info "Patching CGNS 4.1.0"
    patch -p0 << \EOF
diff -c CGNS-4.1.0/src/configure.orig CGNS-4.1.0/src/configure
*** CGNS-4.1.0/src/configure.orig	Thu Feb 11 17:51:22 2021
--- CGNS-4.1.0/src/configure	Fri Feb 12 07:55:02 2021
***************
*** 5939,5945 ****
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="-lz  $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
--- 5939,5945 ----
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="$ZLIBLIB -lz  $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
***************
*** 5974,5980 ****
  #define HAVE_LIBZ 1
  _ACEOF
  
!   LIBS="-lz $LIBS"
  
  else
    unset HAVE_ZLIB
--- 5974,5980 ----
  #define HAVE_LIBZ 1
  _ACEOF
  
!   LIBS="$ZLIBLIB -lz $LIBS"
  
  else
    unset HAVE_ZLIB
***************
*** 6031,6037 ****
  
  
      if test $shared = yes; then
!       ZLIBLIB="-L$zlib_lib"
      else
        if test -n "$zlib_lib"; then
          for a in $exts ; do
--- 6031,6037 ----
  
  
      if test $shared = yes; then
!       ZLIBLIB="-L$zlib_lib -lz"
      else
        if test -n "$zlib_lib"; then
          for a in $exts ; do
***************
*** 6050,6056 ****
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="-lz  $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
--- 6050,6056 ----
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="$ZLIBLIB $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
***************
*** 6085,6091 ****
  #define HAVE_LIBZ 1
  _ACEOF
  
!   LIBS="-lz $LIBS"
  
  else
    unset HAVE_ZLIB
--- 6085,6091 ----
  #define HAVE_LIBZ 1
  _ACEOF
  
!   LIBS="$ZLIBLIB $LIBS"
  
  else
    unset HAVE_ZLIB
***************
*** 6147,6153 ****
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="-lsz  $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
--- 6147,6153 ----
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="$SZIPLIB -lsz  $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
***************
*** 6182,6188 ****
  #define HAVE_LIBSZ 1
  _ACEOF
  
!   LIBS="-lsz $LIBS"
  
  else
    unset HAVE_SZIP
--- 6182,6188 ----
  #define HAVE_LIBSZ 1
  _ACEOF
  
!   LIBS="$SZIPLIB -lsz $LIBS"
  
  else
    unset HAVE_SZIP
***************
*** 6239,6245 ****
  
  
      if test $shared = yes; then
!       SZIPLIB="-L$szip_lib"
      else
        if test -n "$szip_lib"; then
          for a in $exts ; do
--- 6239,6245 ----
  
  
      if test $shared = yes; then
!       SZIPLIB="-L$szip_lib -lsz"
      else
        if test -n "$szip_lib"; then
          for a in $exts ; do
***************
*** 6258,6264 ****
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="-lsz  $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
--- 6258,6264 ----
    $as_echo_n "(cached) " >&6
  else
    ac_check_lib_save_LIBS=$LIBS
! LIBS="$SZIPLIB $LIBS"
  cat confdefs.h - <<_ACEOF >conftest.$ac_ext
  /* end confdefs.h.  */
  
***************
*** 6293,6299 ****
  #define HAVE_LIBSZ 1
  _ACEOF
  
!   LIBS="-lsz $LIBS"
  
  else
    unset HAVE_SZIP
--- 6293,6299 ----
  #define HAVE_LIBSZ 1
  _ACEOF
  
!   LIBS="$SZIPLIB $LIBS"
  
  else
    unset HAVE_SZIP
EOF
    if [[ $? != 0 ]] ; then
        return 1
    fi

    patch -p0 << \EOF
diff -u CGNS-4.1.0/src/Makefile.in.orig CGNS-4.1.0/src/Makefile.in
--- CGNS-4.1.0/src/Makefile.in.orig	2021-01-29 09:15:50.000000000 -0800
+++ CGNS-4.1.0/src/Makefile.in	2021-05-05 08:52:32.000000000 -0700
@@ -53,7 +53,7 @@
 
 $(CGNSLIB) : $(OBJDIR) $(CGNSOBJS) $(FGNSOBJS) $(ADFOBJS) $(F2COBJS)
 	-@$(RM) $@
-	@AR_LIB@ $@ $(CGNSOBJS) $(FGNSOBJS) $(ADFOBJS) $(F2COBJS)
+	@AR_LIB@ $@ $(LDFLAGS) $(CGNSOBJS) $(FGNSOBJS) $(ADFOBJS) $(F2COBJS) $(CLIBS)
 	@RAN_LIB@ $@
 
 $(OBJDIR) :
EOF
    if [[ $? != 0 ]] ; then
        return 1
    fi

    return 0
}

function apply_cgns_patch
{
    if [[ ${CGNS_VERSION} == "4.1.0" ]] ; then
        apply_cgns_410_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0
}

# *************************************************************************** #
#                         Function 8.5, build_cgns                            #
#                                                                             #
# Kevin Griffin, Tue Dec 30 11:39:02 PST 2014                                 #
# Added a patch for the configure script to correctly locate and use the      #
# the dylib for hdf5 and szip. Added the correct linker options to the        #
# dynamic library creation.                                                   #
#                                                                             #
# Kevin Griffin, Fri Jan 16 10:28:21 PST 2015                                 #
# Fixed the --with-szip and --with-zlib to specify the full path to the       #
# library for both OSX and linux                                              #
#                                                                             #
# Kevin Griffin, Mon Apr 27 15:20:43 PDT 2015                                 #
# Patched the configure file to use the zlib library specified in the         #
# --with-zlib option.                                                         #
#                                                                             #
# *************************************************************************** #

function build_cgns
{
    #
    # Prepare build dir
    #
    prepare_build_dir $CGNS_BUILD_DIR $CGNS_FILE
    untarred_cgns=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_cgns == -1 ]] ; then
        warn "Unable to prepare CGNS Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    apply_cgns_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_cgns == 1 ]] ; then
            warn "Giving up on CGNS build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Configure CGNS
    #
    info "Configuring CGNS . . ."
    cd $CGNS_BUILD_DIR || error "Can't cd to CGNS build dir."
    info "Invoking command to configure CGNS"
    LIBEXT=""
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        cf_build_type=""
        LIBEXT="a"
    else
        cf_build_type="--enable-shared=all"
        if [[ "$OPSYS" == "Darwin" ]] ; then
            LIBEXT="dylib"
        else
            LIBEXT="so"
        fi
    fi

    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        cf_build_type="$cf_build_type --enable-debug"
    fi

    # optionally add HDF5 and szip to the configure.
    LIBS_ENV=""
    LDFLAGS_ENV=""
    H5ARGS=""
    if [[ "$DO_HDF5" == "yes" ]] ; then
        LIBS_ENV="-lhdf5"
        LDFLAGS_ENV="-L$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/lib"
        H5ARGS="--with-hdf5=$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH"
        if [[ "$DO_SZIP" == "yes" ]] ; then
            LIBS_ENV="$LIBS_ENV -lsz"
            LDFLAGS_ENV="$LDFLAGS_ENV -L$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib"
            H5ARGS="$H5ARGS --with-szip=$VISITDIR/szip/$SZIP_VERSION/$VISITARCH"
        fi
        LIBS_ENV="$LIBS_ENV -lz"
        LDFLAGS_ENV="$LDFLAGS_ENV -L$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/lib"
        H5ARGS="$H5ARGS --with-zlib=$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH"
    fi

    # Disable fortran
    FORTRANARGS="--with-fortran=no"

    set -x
    if [[ "$OPSYS" == "Darwin" ]] ; then
        env CXX="$CXX_COMPILER" CC="$C_COMPILER" \
            CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
            LDFLAGS="$LDFLAGS_ENV" LIBS="$LIBS_ENV" \
            ./configure --enable-64bit --enable-cgnstools=no ${cf_build_type} $H5ARGS $FORTRANARGS --prefix="$VISITDIR/cgns/$CGNS_VERSION/$VISITARCH"
    else
        env CXX="$CXX_COMPILER" CC="$C_COMPILER" \
            CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
            ./configure --enable-64bit --enable-cgnstools=no ${cf_build_type} $H5ARGS $FORTRANARGS --prefix="$VISITDIR/cgns/$CGNS_VERSION/$VISITARCH"
    fi
    set +x

    if [[ $? != 0 ]] ; then
        warn "CGNS configure failed.  Giving up"
        return 1
    fi

    #
    # Build CGNS
    #
    info "Building CGNS . . . (~2 minutes)"

    $MAKE cgns
    if [[ $? != 0 ]] ; then
        warn "CGNS build failed.  Giving up"
        return 1
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing CGNS . . ."

    $MAKE install-cgns
    if [[ $? != 0 ]] ; then
        warn "CGNS install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        #
        # Make dynamic executable
        #
        info "Creating dynamic libraries for CGNS . . ."

        INSTALLNAMEPATH="$VISITDIR/cgns/${CGNS_VERSION}/$VISITARCH/lib"

        $C_COMPILER -dynamiclib -o libcgns.${SO_EXT} lib/*.o \
                    -Wl,-headerpad_max_install_names \
                    -Wl,-twolevel_namespace,-undefined,dynamic_lookup \
                    -Wl,-install_name,$INSTALLNAMEPATH/libcgns.${SO_EXT} \
                    -Wl,-compatibility_version,$CGNS_COMPATIBILITY_VERSION \
                    -Wl,-current_version,$CGNS_VERSION -lSystem 
        if [[ $? != 0 ]] ; then
            warn "CGNS dynamic library creation failed.  Giving up"
            return 1
        fi
        rm -f "$VISITDIR/cgns/$CGNS_VERSION/$VISITARCH/lib/libcgns.${SO_EXT}"
        cp libcgns.${SO_EXT} "$VISITDIR/cgns/$CGNS_VERSION/$VISITARCH/lib"
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/cgns"
        chgrp -R ${GROUP} "$VISITDIR/cgns"
    fi
    cd "$START_DIR"
    info "Done with CGNS"
    return 0
}

function bv_cgns_is_enabled
{
    if [[ $DO_CGNS == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_cgns_is_installed
{
    check_if_installed "cgns" $CGNS_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_cgns_build
{
    cd "$START_DIR"
    if [[ "$DO_CGNS" == "yes" ]] ; then
        check_if_installed "cgns" $CGNS_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping CGNS build.  CGNS is already installed."
        else
            info "Building CGNS (~2 minutes)"
            build_cgns
            if [[ $? != 0 ]] ; then
                error "Unable to build or install CGNS.  Bailing out."
            fi
            info "Done building CGNS"
        fi
    fi
}
function bv_cmake_initialize
{
    export DO_CMAKE="yes"
    export USE_SYSTEM_CMAKE="no"
    add_extra_commandline_args "cmake" "system-cmake" 0 "Use cmake found on system"
    add_extra_commandline_args "cmake" "alt-cmake-dir" 1 "Use cmake found in alternative directory"
    add_extra_commandline_args "cmake" "bin-cmake-dir" 1 "Use cmake found in alternative binary directory"
}

function bv_cmake_enable
{
    DO_CMAKE="yes"
}

function bv_cmake_disable
{
    DO_CMAKE="no"
}

function bv_cmake_depends_on
{
    echo ""
}

function cmake_set_vars_helper
{
    CMAKE_VERSION=`"${CMAKE_COMMAND}" --version`
    CMAKE_VERSION=${CMAKE_VERSION/cmake version }
    CMAKE_BUILD_DIR=`"${CMAKE_COMMAND}" --system-information 2>& 1 | grep _CMAKE_INSTALL_DIR | grep -v _CMAKE_INSTALL_DIR:INTERNAL | sed -e s/\"//g -e s/_CMAKE_INSTALL_DIR//g`
    CMAKE_BUILD_DIR=`echo $CMAKE_BUILD_DIR`
    CMAKE_INSTALL="$CMAKE_BUILD_DIR/bin"
    CMAKE_ROOT=`"$CMAKE_COMMAND" --system-information 2>&1 | grep CMAKE_ROOT | grep -v CMAKE_ROOT:INTERNAL | sed -e s/\"//g -e s/CMAKE_ROOT//g`
    CMAKE_ROOT=`echo "$CMAKE_ROOT"`
    CMAKE_ROOT=`echo $CMAKE_ROOT`

    echo "version: $CMAKE_VERSION build: $CMAKE_BUILD_DIR bin: $CMAKE_INSTALL root: $CMAKE_ROOT"
}

function bv_cmake_system_cmake
{
    echo "using system cmake"

    TEST=`which cmake`
    [ $? != 0 ] && error "System CMake not found"

    bv_cmake_enable

    USE_SYSTEM_CMAKE="yes"

    CMAKE_COMMAND="cmake"
    CMAKE_FILE=""
    cmake_set_vars_helper #set vars..
}

function bv_cmake_alt_cmake_dir
{
    CMAKE_ALT_DIR="$1"
    echo "Using cmake from alternative directory $1"

    [ ! -e "$CMAKE_ALT_DIR/bin/cmake" ] && error "cmake was not found in directory: $1/bin"

    bv_cmake_enable
    USE_SYSTEM_CMAKE="yes"

    CMAKE_COMMAND="$CMAKE_ALT_DIR/bin/cmake"
    CMAKE_FILE=""
    cmake_set_vars_helper #set vars..
}

function bv_cmake_bin_cmake_dir
{
    CMAKE_BIN_DIR="$1"
    echo "Using cmake from bin directory $1"

    [ ! -e "$CMAKE_BIN_DIR/cmake" ] && error "cmake was not found in directory: $1/"

    bv_cmake_enable
    USE_SYSTEM_CMAKE="yes"

    CMAKE_COMMAND="$CMAKE_BIN_DIR/cmake"
    CMAKE_FILE=""
    cmake_set_vars_helper #set vars..
}


function bv_cmake_info
{
    export CMAKE_VERSION=${CMAKE_VERSION:-"3.31.8"}
    export CMAKE_FILE=${CMAKE_FILE:-"cmake-${CMAKE_VERSION}.tar.gz"}
    export CMAKE_BUILD_DIR=${CMAKE_BUILD_DIR:-"cmake-${CMAKE_VERSION}"}
    export CMAKE_SHA256_CHECKSUM="e3cde3ca83dc2d3212105326b8f1b565116be808394384007e7ef1c253af6caa"
}

function bv_cmake_print
{
    printf "%s%s\n" "CMAKE_FILE=" "${CMAKE_FILE}"
    printf "%s%s\n" "CMAKE_VERSION=" "${CMAKE_VERSION}"
    printf "%s%s\n" "CMAKE_BUILD_DIR=" "${CMAKE_BUILD_DIR}"
}

function bv_cmake_print_usage
{
    printf "%-20s %s\n" "--cmake" "Build CMake"
    printf "%-20s %s [%s]\n" "--system-cmake"  "Use the system installed CMake"
    printf "%-20s %s [%s]\n" "--alt-cmake-dir" "Use CMake from an alternative directory"
    printf "%-20s %s [%s]\n" "--bin-cmake-dir" "Use CMake from an alternative binary directory"
}

function bv_cmake_host_profile
{
    #nothing to be done for cmake in cmake host profile..
    echo "##" >> $HOSTCONF
}

function bv_cmake_initialize_vars
{
    if [[ "$USE_SYSTEM_CMAKE" != "yes" ]]; then
        if [[ "$DO_CMAKE" == "yes" || "$DO_VTK" == "yes" ]] ; then
            #initialize variables where cmake should exist..
            CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/${VISITARCH}/bin"}
            CMAKE_ROOT=${CMAKE_ROOT:-"$VISITDIR/cmake/${CMAKE_VERSION}/${VISITARCH}/share/cmake-${CMAKE_VERSION%.*}"}
            CMAKE_COMMAND="${CMAKE_INSTALL}/cmake"
        fi
    fi

}

function bv_cmake_ensure
{
    if [[ "$USE_SYSTEM_CMAKE" != "yes" ]]; then
        if [[ "$DO_CMAKE" == "yes" || "$DO_VTK" == "yes" ]] ; then
            ensure_built_or_ready "cmake"  $CMAKE_VERSION  $CMAKE_BUILD_DIR  $CMAKE_FILE $CMAKE_URL
            if [[ $? != 0 ]] ; then
                return 1
            fi
        fi
    fi
}

# *************************************************************************** #
#                          Function 5, build_cmake                            #
# *************************************************************************** #

function build_cmake
{
    #
    # Prepare cmake build directory
    #
    prepare_build_dir $CMAKE_BUILD_DIR $CMAKE_FILE
    untarred_cmake=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_cmake == -1 ]] ; then
        warn "Unable to prepare CMake build directory. Giving Up!"
        return 1
    fi

    #
    # CMake's logic to test for C++11 constructs like unique_ptr is broken. It fails anytime 'warning'
    # appears on stderr. But, 'warning' can appear on stderr for all sorts of reasons some of which
    # are totally unrelated to the test. One example is file system clock skew...which was happening
    # on LANL's Crossroads. I don't see any benefit in confirming these C++11 constructs now that it
    # is 2024. We just entirely disable these tests by setting these bootstrap flags.
    #
    CMAKE_BOOTSTRAP_FLAGS="-- -DCMake_HAVE_CXX_MAKE_UNIQUE=1 -DCMake_HAVE_CXX_UNIQUE_PTR=1 CMake_HAVE_CXX_UNIQUE_PTR=1"

    #
    # Issue "bootstrap", which takes the place of configure for CMake.
    #
    # It would be better to use --parallel=n here and doing so on slow machines/filesystems certainly
    # does help quite a bit. But, CMake says the n in --parallel=n is a "node count". We're not really
    # sure what they mean by that and so deciding not to include it here yet.
    #
    info "Bootstrapping CMake . . ."
    cd $CMAKE_BUILD_DIR || error "Can't cd to CMake build dir."
    if [[ "$OPSYS" == "Linux" && "$C_COMPILER" == "xlc" ]]; then
        env CXX=xlC CC=xlc CXXFLAGS="" CFLAGS="" ./bootstrap --prefix="$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH"
    else
        env CC=${C_COMPILER} CXX=${CXX_COMPILER} CXXFLAGS="" CFLAGS="" ./bootstrap --prefix="$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH" ${CMAKE_BOOTSTRAP_FLAGS}
    fi
    if [[ $? != 0 ]] ; then
        warn "Bootstrap for cmake failed, giving up."
        return 1
    fi

    #
    # Build the CMake program.
    #
    info "Building CMake . . ."
    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Cannot build cmake, giving up."
        return 1
    fi

    info "Installing CMake . . ."
    $MAKE install
    info "Successfully built CMake"
    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/cmake"
        chgrp -R ${GROUP} "$VISITDIR/cmake"
    fi
    cd "$START_DIR"
    info "Done with CMake"
}

function bv_cmake_is_enabled
{
    if [[ $DO_CMAKE == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_cmake_is_installed
{
    if [[ "$USE_SYSTEM_CMAKE" == "yes" ]]; then
        return 1
    fi

    check_if_installed "cmake" $CMAKE_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_cmake_build
{
    #
    # Build CMake
    #
    cd "$START_DIR"
    if [[ "$DO_CMAKE" == "yes" && "$USE_SYSTEM_CMAKE" == "no" ]]; then
        check_if_installed "cmake" $CMAKE_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping CMake build.  CMake is already installed."
        else
            info "Building CMake (~5 minutes)"
            build_cmake
            if [[ $? != 0 ]] ; then
                error "Unable to build or install CMake.  Bailing out."
            fi
            info "Done building CMake"
        fi
    fi
}
function bv_conduit_initialize
{
    export DO_CONDUIT="no"
}

function bv_conduit_enable
{
    DO_CONDUIT="yes"
}

function bv_conduit_disable
{
    DO_CONDUIT="no"
}

function bv_conduit_depends_on
{
    local depends_on="cmake"

    if [[ "$DO_HDF5" == "yes" ]] ; then
        depends_on="hdf5"
    fi

    if [[ "$DO_SILO" == "yes" ]] ; then
        depends_on="silo"
    fi

    if [[ "$DO_ZLIB" == "yes" ]] ; then
        depends_on="$depends_on zlib"
    fi

    if [[ "$DO_PYTHON" == "yes" ]] ; then
        depends_on="$depends_on python"
    fi

    if [[ "$DO_MPICH" == "yes" ]] ; then
        depends_on="$depends_on mpich"
    fi
    
    echo $depends_on
}

function bv_conduit_info
{
    export CONDUIT_VERSION=${CONDUIT_VERSION:-"v0.9.4"}
    export CONDUIT_FILE=${CONDUIT_FILE:-"conduit-${CONDUIT_VERSION}-src-with-blt.tar.gz"}
    export CONDUIT_COMPATIBILITY_VERSION=${CONDUIT_COMPATIBILITY_VERSION:-"v0.9.4"}
    export CONDUIT_BUILD_DIR=${CONDUIT_BUILD_DIR:-"conduit-${CONDUIT_VERSION}"}
    export CONDUIT_SHA256_CHECKSUM="c9edfb2ff09890084313ad9c2d83bfb7c10e70b696980762d1ae1488f9f08e6c"
}

function bv_conduit_print
{
    printf "%s%s\n" "CONDUIT_FILE=" "${CONDUIT_FILE}"
    printf "%s%s\n" "CONDUIT_VERSION=" "${CONDUIT_VERSION}"
    printf "%s%s\n" "CONDUIT_COMPATIBILITY_VERSION=" "${CONDUIT_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "CONDUIT_BUILD_DIR=" "${CONDUIT_BUILD_DIR}"
}

function bv_conduit_print_usage
{
    printf "%-20s %s [%s]\n" "--conduit"   "Build Conduit" "$DO_CONDUIT"
}

function bv_conduit_host_profile
{
    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Conduit" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        # Need to remove the 'v' from the version string for cmake
        echo "SETUP_APP_VERSION(CONDUIT ${CONDUIT_VERSION:1})" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_CONDUIT_DIR \${VISITHOME}/conduit/$CONDUIT_VERSION/\${VISITARCH})" \
            >> $HOSTCONF

        CONDUIT_HC_LIBDEPS=""
        if [[ "$DO_HDF5" == "yes" ]] ; then
            CONDUIT_HC_LIBDEPS="HDF5_LIBRARY_DIR hdf5 \${VISIT_HDF5_LIBDEP}"
        fi

        if [[ "$DO_SILO" == "yes" ]] ; then
            CONDUIT_HC_LIBDEPS="${CONDUIT_HC_LIBDEPS} \${VISIT_SILO_LIBDEP}"
        fi

        if [[ "$CONDUIT_HC_LIBDEPS" != "" ]] ; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_CONDUIT_LIBDEP ${CONDUIT_HC_LIBDEPS} TYPE STRING)" \
                >> $HOSTCONF
        fi
    fi
}

function bv_conduit_ensure
{
    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        ensure_built_or_ready "conduit" $CONDUIT_VERSION $CONDUIT_BUILD_DIR $CONDUIT_FILE $CONDUIT_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_CONDUIT="no"
            error "Unable to build Conduit.  ${CONDUIT_FILE} not found."
        fi
    fi
}

function apply_conduit_patch
{
    return 0
}

# *************************************************************************** #
# build_conduit
# *************************************************************************** #

function build_conduit
{
    #
    # Conduit uses CMake  -- make sure we have it.
    #
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}
    if [[ -e ${CMAKE_INSTALL}/cmake ]] ; then
        info "Conduit: CMake found"
    else
        warn "Unable to find cmake, cannot build Conduit. Giving up."
        return 1
    fi


    #
    # Prepare build dir
    #
    prepare_build_dir $CONDUIT_BUILD_DIR $CONDUIT_FILE
    untarred_conduit=$?
    if [[ $untarred_conduit == -1 ]] ; then
        warn "Unable to prepare Conduit build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching Conduit . . ."
    cd $CONDUIT_BUILD_DIR || error "Can't cd to Conduit build dir."
    apply_conduit_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_conduit == 1 ]] ; then
            warn "Giving up on Conduit build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    # move back up to the start dir
    cd "$START_DIR"

    #
    # Call configure
    #
    info "Configuring Conduit . . ."

    # Make a build directory for an out-of-source build.. Change the
    # VISIT_BUILD_DIR variable to represent the out-of-source build directory. 
    CONDUIT_SRC_DIR=$CONDUIT_BUILD_DIR
    CONDUIT_BUILD_DIR="${CONDUIT_SRC_DIR}-build"
    if [[ ! -d $CONDUIT_BUILD_DIR ]] ; then
        echo "Making build directory $CONDUIT_BUILD_DIR"
        mkdir $CONDUIT_BUILD_DIR
    fi

    #
    # Remove the CMakeCache.txt files ... existing files sometimes prevent
    # fields from getting overwritten properly.
    #
    rm -Rf $CONDUIT_BUILD_DIR/CMakeCache.txt $CONDUIT_BUILD_DIR/*/CMakeCache.txt


    conduit_build_mode="${VISIT_BUILD_MODE}"
    conduit_install_path="${VISITDIR}/conduit/${CONDUIT_VERSION}/${VISITARCH}"


    cfg_opts=""
    # normal stuff
    cfg_opts="${cfg_opts} -DCMAKE_BUILD_TYPE:STRING=${conduit_build_mode}"
    cfg_opts="${cfg_opts} -DCMAKE_INSTALL_PREFIX:PATH=${conduit_install_path}"
    if test "x${DO_STATIC_BUILD}" = "xyes" ; then
        cfg_opts="${cfg_opts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
        cfg_opts="${cfg_opts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi
    
    cfg_opts="${cfg_opts} -DENABLE_TESTS:BOOL=false"
    cfg_opts="${cfg_opts} -DENABLE_DOCS:BOOL=false"
    cfg_opts="${cfg_opts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    cfg_opts="${cfg_opts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    cfg_opts="${cfg_opts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS} ${PAR_LINKER_FLAGS}\""
    cfg_opts="${cfg_opts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS} ${PAR_LINKER_FLAGS}\""
    if test "${OPSYS}" = "Darwin" ; then
        cfg_opts="${cfg_opts} -DCMAKE_INSTALL_NAME_DIR:PATH=${conduit_install_path}/lib"
        if test "${MACOSX_DEPLOYMENT_TARGET}" = "10.10"; then
            # If building on 10.10 (Yosemite) check if we are building with Xcode 7 ...
            XCODE_VER=$(xcodebuild -version | head -n 1 | awk '{print $2}')
            if test ${XCODE_VER%.*} == 7; then
                # Workaround for Xcode 7 not having a 10.10 SDK: Prevent CMake from linking to 10.11 SDK
                # by using Frameworks installed in root directory.
                echo "Xcode 7 on MacOS 10.10 detected: Enabling CMake workaround"
                cfg_opts="${cfg_opts} -DCMAKE_OSX_DEPLOYMENT_TARGET:STRING=\"\" -DCMAKE_OSX_SYSROOT:STRING=/"
            fi
        fi
    fi

    if [[ "$DO_SILO" == "yes" ]] ; then
        cfg_opts="${cfg_opts} -DSILO_DIR:STRING=$VISITDIR/silo/$SILO_VERSION/$VISITARCH/"
    fi

    if [[ "$DO_HDF5" == "yes" ]] ; then
        cfg_opts="${cfg_opts} -DHDF5_DIR:STRING=$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/"
    fi

    if [[ "$DO_ZLIB" == "yes" ]] ; then
        cfg_opts="${cfg_opts} -DZLIB_DIR:STRING=$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/"
    fi

    if [[ "$DO_PYTHON" == "yes" ]] ; then
        cfg_opts="${cfg_opts} -DPYTHON_EXECUTABLE:STRING=$PYTHON_COMMAND"
        cfg_opts="${cfg_opts} -DENABLE_PYTHON:STRING=TRUE"
    fi

    if [[ "$FC_COMPILER" != "no" ]] ; then
        cfg_opts="${cfg_opts} -DENABLE_FORTRAN:BOOL=ON"
        cfg_opts="${cfg_opts} -DCMAKE_Fortran_COMPILER:STRING=${FC_COMPILER}"
    fi

    #
    # Conduit Relay MPI Support
    #

    if [[ "$PAR_COMPILER" != "" ]] ; then
        cfg_opts="${cfg_opts} -DENABLE_MPI:BOOL=ON"
        cfg_opts="${cfg_opts} -DMPI_C_COMPILER:STRING=${PAR_COMPILER}"
        cfg_opts="${cfg_opts} -DMPI_CXX_COMPILER:STRING=${PAR_COMPILER_CXX}"
    fi
    
    if [[ "$PAR_INCLUDE" != "" ]] ; then
        cfg_opts="${cfg_opts} -DMPI_C_INCLUDE_PATH:STRING=${PAR_INCLUDE_PATH}"
        cfg_opts="${cfg_opts} -DMPI_CXX_INCLUDE_PATH:STRING=${PAR_INCLUDE_PATH}"
    fi
    
    if [[ "$PAR_LIBS" != "" ]] ; then
        cfg_opts="${cfg_opts} -DMPI_C_LINK_FLAGS:STRING=${PAR_LINKER_FLAGS}"
        cfg_opts="${cfg_opts} -DMPI_C_LIBRARIES:STRING=${PAR_LIBRARY_LINKER_FLAGS}"
        cfg_opts="${cfg_opts} -DMPI_CXX_LINK_FLAGS:STRING=${PAR_LINKER_FLAGS}"
        cfg_opts="${cfg_opts} -DMPI_CXX_LIBRARIES:STRING=${PAR_LIBRARY_LINKER_FLAGS}"
    fi
    
    CMAKE_BIN="${CMAKE_INSTALL}/cmake"
    cd ${CONDUIT_BUILD_DIR}

    #
    # Several platforms have had problems with the VTK cmake configure command
    # issued simply via "issue_command".  This was first discovered on 
    # BGQ and then showed up in random cases for both OSX and Linux machines. 
    # Brad resolved this on BGQ  with a simple work around - we write a simple 
    # script that we invoke with bash which calls cmake with all of the properly
    # arguments. We are now using this strategy for all platforms.
    #

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\"" ${cfg_opts} ../${CONDUIT_SRC_DIR}/src > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh

    if [[ $? != 0 ]] ; then
        warn "Conduit configure failed.  Giving up"
        return 1
    fi

    #
    # Build Conduit
    #
    info "Building Conduit . . . (~5 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Conduit build failed.  Giving up"
        return 1
    fi
    
    #
    # Install into the VisIt third party location.
    #
    info "Installing Conduit"
    ${CMAKE_COMMAND} --install .
    if [[ $? != 0 ]] ; then
        warn "Conduit install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/conduit"
        chgrp -R ${GROUP} "$VISITDIR/conduit"
    fi
    cd "$START_DIR"
    info "Done with Conduit"
    return 0
}

function bv_conduit_is_enabled
{
    if [[ $DO_CONDUIT == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_conduit_is_installed
{
    check_if_installed "conduit" $CONDUIT_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_conduit_build
{
    cd "$START_DIR"
    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        check_if_installed "conduit" $CONDUIT_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Conduit build.  Conduit is already installed."
        else
            info "Building Conduit (~5 minutes)"
            build_conduit
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Conduit.  Bailing out."
            fi
            info "Done building Conduit"
        fi
    fi
}
function bv_fms_initialize
{
    export DO_FMS="no"
}

function bv_fms_enable
{
    DO_FMS="yes"
}

function bv_fms_disable
{
    DO_FMS="no"
}

function bv_fms_depends_on
{
    local depends_on=""

    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        depends_on="$depends_on conduit"
    fi

    echo $depends_on
}

function bv_fms_info
{
    export FMS_VERSION=${FMS_VERSION:-"0.2"}
    export FMS_FILE=${FMS_FILE:-"FMS-${FMS_VERSION}.tar.gz"}
    export FMS_BUILD_DIR=${FMS_BUILD_DIR:-"FMS-${FMS_VERSION}"}
    export FMS_SHA256_CHECKSUM="872489a1325b247968dbb7265b8736660af94121a86c93f7938441ce7478183e"
}

function bv_fms_print
{
    printf "%s%s\n" "FMS_FILE=" "${FMS_FILE}"
    printf "%s%s\n" "FMS_VERSION=" "${FMS_VERSION}"
    printf "%s%s\n" "FMS_BUILD_DIR=" "${FMS_BUILD_DIR}"
}

function bv_fms_print_usage
{
    printf "%-20s %s [%s]\n" "--fms" "Build FMS support" "$DO_FMS"
}

function bv_fms_host_profile
{
    if [[ "$DO_FMS" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## FMS" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_FMS_DIR \${VISITHOME}/fms/$FMS_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
        if [[ "$DO_CONDUIT" == "yes" ]] ; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_FMS_LIBDEP CONDUIT_LIBRARY_DIR conduit CONDUIT_LIBRARY_DIR conduit_blueprint CONDUIT_LIBRARY_DIR conduit_relay \${VISIT_CONDUIT_LIBDEP} TYPE STRING)" \
                >> $HOSTCONF
        fi
    fi
}

function bv_fms_ensure
{
    if [[ "$DO_FMS" == "yes" ]] ; then
        ensure_built_or_ready "fms" $FMS_VERSION $FMS_BUILD_DIR $FMS_FILE $FMS_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_FMS="no"
            error "Unable to build FMS.  ${FMS_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_fms
# *************************************************************************** #
function build_fms
{
    #
    # Prepare build dir
    #
    prepare_build_dir $FMS_BUILD_DIR $FMS_FILE
    untarred_fms=$?
    if [[ $untarred_fms == -1 ]] ; then
        warn "Unable to prepare FMS build directory. Giving Up!"
        return 1
    fi

    cd $FMS_BUILD_DIR || error "Can't cd to FMS source dir."
    mkdir build
    cd build || error "Can't cd to FMS build dir."

    vopts="-DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    vopts="${vopts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS}\""
    vopts="${vopts} -DCMAKE_INSTALL_PREFIX:PATH=${VISITDIR}/fms/${FMS_VERSION}/${VISITARCH}"
    if test "x${DO_STATIC_BUILD}" = "xyes" ; then
        vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
        vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi
    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        vopts="${vopts} -DCONDUIT_DIR=${VISITDIR}/conduit/${CONDUIT_VERSION}/${VISITARCH}"
    fi

    #
    # Call configure
    #
    info "Configuring FMS . . ."
    CMAKE_BIN="${CMAKE_INSTALL}/cmake"
    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\" ${vopts} .." > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "FMS configuration failed."

    #
    # Build FMS
    #
    info "Building FMS . . . (~2 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "FMS build failed.  Giving up"
        return 1
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing FMS"
    ${CMAKE_COMMAND} --install .

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/fms"
        chgrp -R ${GROUP} "$VISITDIR/fms"
    fi
    cd "$START_DIR"    
    info "Done with FMS"
    return 0
}


function bv_fms_is_enabled
{
    if [[ $DO_FMS == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_fms_is_installed
{
    check_if_installed "fms" $FMS_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_fms_build
{
    cd "$START_DIR"
    if [[ "$DO_FMS" == "yes" ]] ; then
        check_if_installed "fms" $FMS_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping FMS build.  FMS is already installed."
        else
            info "Building FMS (~2 minutes)"
            build_fms
            if [[ $? != 0 ]] ; then
                error "Unable to build or install FMS.  Bailing out."
            fi
            info "Done building FMS"
        fi
    fi
}
function bv_gdal_initialize
{
    export DO_GDAL="no"
}

function bv_gdal_enable
{
    DO_GDAL="yes"
}

function bv_gdal_disable
{
    DO_GDAL="no"
}

function bv_gdal_depends_on
{
    echo ""
}

function bv_gdal_info
{
    export GDAL_FILE=${GDAL_FILE:-"gdal-2.2.4.tar.gz"}
    export GDAL_VERSION=${GDAL_VERSION:-"2.2.4"}
    export GDAL_COMPATIBILITY_VERSION=${GDAL_COMPATIBILITY_VERSION:-"2.2"}
    export GDAL_BUILD_DIR=${GDAL_BUILD_DIR:-"gdal-2.2.4"}
    export GDAL_SHA256_CHECKSUM="b9d5a723787f3006a82cb276db171c721187b048b866c0e20e6df464d671a1a4"
}

function bv_gdal_print
{
    printf "%s%s\n" "GDAL_FILE=" "${GDAL_FILE}"
    printf "%s%s\n" "GDAL_VERSION=" "${GDAL_VERSION}"
    printf "%s%s\n" "GDAL_COMPATIBILITY_VERSION=" "${GDAL_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "GDAL_BUILD_DIR=" "${GDAL_BUILD_DIR}"
}

function bv_gdal_print_usage
{
    printf "%-20s %s [%s]\n" "--gdal" "Build GDAL" "$DO_GDAL"
}

function bv_gdal_host_profile
{
    if [[ "$DO_GDAL" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## GDAL" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_GDAL_DIR \${VISITHOME}/gdal/$GDAL_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi

}

function bv_gdal_ensure
{
    if [[ "$DO_GDAL" == "yes" ]] ; then
        ensure_built_or_ready "gdal" $GDAL_VERSION $GDAL_BUILD_DIR $GDAL_FILE $GDAL_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_GDAL="no"
            error "Unable to build GDAL.  ${GDAL_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                         Function 8.6, build_gdal                            #
# *************************************************************************** #

function apply_gdal_linux_x86_64_patch
{
    mv configure configure.old
    sed "s/expat_prefix\/lib -lexpat/expat_prefix\/lib64 -lexpat/g" configure.old > configure
    chmod 700 configure
}

function apply_gdal_mac6_patch
{
    cat frmts/gtiff/libtiff/GNUmakefile | \
        sed 's/tif_zip.o/tif_zip.o lfind.o/' > tmp.make
    mv frmts/gtiff/libtiff/GNUmakefile \
       frmts/gtiff/libtiff/GNUmakefile.orig
    mv tmp.make frmts/gtiff/libtiff/GNUmakefile

    echo > frmts/gtiff/libtiff/lfind.c
    cat >> frmts/gtiff/libtiff/lfind.c << EOF
#include <sys/types.h>
#include <string.h>
#include <unistd.h>

static char *linear_base();

char *
lfind(key, base, nelp, width, compar)
      char *key, *base;
      u_int *nelp, width;
      int (*compar)();
{
      return(linear_base(key, base, nelp, width, compar, 0));
}

static char *
linear_base(key, base, nelp, width, compar, add_flag)
      char *key, *base;
      u_int *nelp, width;
      int (*compar)(), add_flag;
{
      register char *element, *end;

      end = base + *nelp * width;
      for (element = base; element < end; element += width)
              if (!compar(element, key))              /* key found */
                      return(element);

      if (!add_flag)                                  /* key not found */
              return(NULL);

      ++*nelp;
      bcopy(key, end, (int)width);
      return(end);
}
EOF
}

function build_gdal
{
    #
    # Prepare build dir
    #
    prepare_build_dir $GDAL_BUILD_DIR $GDAL_FILE
    untarred_gdal=$?
    if [[ $untarred_gdal == -1 ]] ; then
        warn "Unable to prepare GDAL Build Directory. Giving Up"
        return 1
    fi

    #
    info "Configuring GDAL . . ."
    cd $GDAL_BUILD_DIR || error "Can't cd to GDAL build dir."
    info "Invoking command to configure GDAL"
    if [[ "$OPSYS" == "Darwin" ]]; then
        if [[ "$DO_STATIC_BUILD" == "no" ]]; then
            EXTRA_FLAGS="F77=\"\" --enable-shared --disable-static --without-libtool --without-expat"
        else
            EXTRA_FLAGS="F77=\"\" --enable-static --without-ld-shared  --without-libtool --without-expat"
        fi
    else
        if [[ "$DO_STATIC_BUILD" == "no" ]]; then
            EXTRA_FLAGS="--enable-shared --disable-static --with-hide-internal-symbols"
        else
            EXTRA_FLAGS="--enable-static --disable-shared --with-hide-internal-symbols"
        fi
    fi

    if [[ "$OPSYS" == "Darwin" ]]; then
        # Check for version 6.x.x (MacOS 10.2, Jaguar)
        VER=$(uname -r)
        if (( ${VER%%.*} < 7 )) ; then
            apply_gdal_mac6_patch
        fi
    fi
    if [[ "$OPSYS" == "Linux" ]] ; then
        if [[ "$(uname -m)" == "x86_64" ]] ; then
            apply_gdal_linux_x86_64_patch
        fi
    fi
    
    C_OPT_FLAGS="-Wno-error=implicit-function-declaration"
    set -x
    ./configure CXX="$CXX_COMPILER" CC="$C_COMPILER" $EXTRA_FLAGS \
                CFLAGS="$CFLAGS $C_OPT_FLAGS -DH5_USE_16_API" \
                CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS -DH5_USE_16_API" \
                --prefix="$VISITDIR/gdal/$GDAL_VERSION/$VISITARCH" \
                --with-libtiff=internal --with-gif=internal \
                --with-png=internal --with-jpeg=internal \
                --with-libz=internal --with-netcdf=no \
                --with-hdf5=no --with-pg=no --with-curl=no \
                --without-jasper --without-python \
                --without-sqlite3 --without-xml2 --with-geos=no
    set +x
    if [[ $? != 0 ]] ; then
        warn "GDAL configure failed.  Giving up"
        return 1
    fi

    #
    # Build GDAL
    #
    info "Building GDAL . . . (~7 minutes)"

    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "GDAL build failed.  Giving up"
        return 1
    fi
    #
    # Install into the VisIt third party location.
    #
    info "Installing GDAL . . ."

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "GDAL install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        #
        # Make dynamic executable
        #
        info "Fixing install_name of dynamic libraries for GDAL . . ."

        cp .libs/libgdal.2.2.4.${SO_EXT} libgdal.${SO_EXT}
        INSTALLNAMEPATH="$VISITDIR/gdal/${GDAL_VERSION}/$VISITARCH/lib"

        install_name_tool -id \
                          $INSTALLNAMEPATH/libgdal.${SO_EXT} \
                          libgdal.${SO_EXT}
        rm "$VISITDIR/gdal/$GDAL_VERSION/$VISITARCH/lib/libgdal.${SO_EXT}"
        cp libgdal.${SO_EXT} \
           "$VISITDIR/gdal/$GDAL_VERSION/$VISITARCH/lib/libgdal.${SO_EXT}"
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/gdal"
        chgrp -R ${GROUP} "$VISITDIR/gdal"
    fi
    cd "$START_DIR"
    info "Done with GDAL"
    return 0
}

function bv_gdal_is_enabled
{
    if [[ $DO_GDAL == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_gdal_is_installed
{
    check_if_installed "gdal" $GDAL_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_gdal_build
{
    cd "$START_DIR"
    if [[ "$DO_GDAL" == "yes" ]] ; then
        check_if_installed "gdal" $GDAL_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping GDAL build.  GDAL is already installed."
        else
            info "Building GDAL (~2 minutes)"
            build_gdal
            if [[ $? != 0 ]] ; then
                error "Unable to build or install GDAL.  Bailing out."
            fi
            info "Done building GDAL"
        fi
    fi
}
function bv_glu_initialize
{
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        export DO_GLU="yes"
    else 
        export DO_GLU="no"
    fi
}

function bv_glu_enable
{
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        DO_GLU="yes"
    fi
}

function bv_glu_disable
{
    DO_GLU="no"
}

function bv_glu_depends_on
{
    # We install into the mesagl directory so it needs to be on.

    if [[ "$DO_MESAGL" == "yes" ]] ; then
        echo "mesagl"
    fi
}

function bv_glu_info
{
    export GLU_FILE=${GLU_FILE:-"glu-9.0.0.tar.gz"}
    export GLU_VERSION=${GLU_VERSION:-"9.0.0"}
    export GLU_BUILD_DIR=${GLU_BUILD_DIR:-"glu-9.0.0"}
    export GLU_SHA256_CHECKSUM="4387476a1933f36fec1531178ea204057bbeb04cc2d8396c9ea32720a1f7e264"
}

function bv_glu_print
{
    printf "%s%s\n" "GLU_FILE=" "${GLU_FILE}"
    printf "%s%s\n" "GLU_VERSION=" "${GLU_VERSION}"
    printf "%s%s\n" "GLU_TARGET=" "${GLU_TARGET}"
    printf "%s%s\n" "GLU_BUILD_DIR=" "${GLU_BUILD_DIR}"
}

function bv_glu_print_usage
{
    printf "%-20s %s [%s]\n" "--glu" "Build GLU" "$DO_GLU"
}

function bv_glu_host_profile
{
#    if [[ "$DO_GLU" == "yes" ]] ; then
#        echo >> $HOSTCONF
#        echo "##" >> $HOSTCONF
#        echo "## GLU" >> $HOSTCONF
#        echo "##" >> $HOSTCONF
#        echo "VISIT_OPTION_DEFAULT(VISIT_GLU_DIR \${VISITHOME}/glu/$GLU_VERSION/\${VISITARCH})" >> $HOSTCONF
#    fi
     return 0
}

function bv_glu_selected
{
    args=$@
    if [[ $args == "--glu" ]]; then
        DO_GLU="yes"
        return 1
    fi

    return 0
}

function bv_glu_initialize_vars
{
    info "initalizing glu vars"
    if [[ "$DO_GLU" == "yes" ]]; then
        if [[ "$DO_MESAGL" == "yes" ]] ; then
            GLU_INSTALL_DIR="${MESAGL_INSTALL_DIR}"
        else
            GLU_INSTALL_DIR="${VISITDIR}/glu/${GLU_VERSION}/${VISITARCH}"
        fi
        GLU_INCLUDE_DIR="${GLU_INSTALL_DIR}/include"
        GLU_LIB_DIR="${GLU_INSTALL_DIR}/lib"
        if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
            GLU_LIB="${GLU_LIB_DIR}/libGLU.a"
        else
            GLU_LIB="${GLU_LIB_DIR}/libGLU.${SO_EXT}"
        fi
    fi
}

function bv_glu_ensure
{
    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        if [[ "$DO_GLU" == "yes" ]] ; then
            ensure_built_or_ready "glu"   $GLU_VERSION   $GLU_BUILD_DIR   $GLU_FILE
            if [[ $? != 0 ]] ; then
                return 1
            fi
        fi
    fi
}

function apply_glu_ppc64le_config_patch
{
  # patch glu's config.guess to allow it to recognize ppc64le
  patch -p0 << \EOF
*** ./glu-9.0.0/config.guess.orig 2018-03-22 11:22:30.000000000 
--- ./glu-9.0.0/config.guess 2018-03-22 11:23:23.000000000 
***************
*** 984,995 ****
--- 984,998 ----
  	  *)    echo hppa-unknown-linux-${LIBC} ;;
  	esac
  	exit ;;
      ppc64:Linux:*:*)
  	echo powerpc64-unknown-linux-${LIBC}
  	exit ;;
+     ppc64le:Linux:*:*)
+ 	echo powerpc64-unknown-linux-${LIBC}
+ 	exit ;;
      ppc:Linux:*:*)
  	echo powerpc-unknown-linux-${LIBC}
  	exit ;;
      s390:Linux:*:* | s390x:Linux:*:*)
  	echo ${UNAME_MACHINE}-ibm-linux
  	exit ;;

EOF

    if [[ $? != 0 ]] ; then
      warn "glu patch for config.guess failed."
      return 1
    fi
    return 0;
}

function apply_glu_patch
{
    apply_glu_ppc64le_config_patch
    if [[ $? != 0 ]] ; then
        return 1
    fi

    return 0
}


function build_glu
{
    #
    # prepare build dir
    #
    prepare_build_dir $GLU_BUILD_DIR $GLU_FILE
    untarred_glu=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_glu == -1 ]] ; then
        warn "Unable to prepare GLU build directory. Giving Up!"
        return 1
    fi

    #
    # Patch glu
    #
    apply_glu_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_glu == 1 ]] ; then
            warn "Giving up on GLU build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Build GLU.
    #
    info "Building GLU . . . (~2 minutes)"
    cd $GLU_BUILD_DIR || error "Couldn't cd to glu build dir."

    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        GLU_STATIC_DYNAMIC="--disable-shared --enable-static"
    fi

    # NOTE: we install the library into the MesaGL directories.
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        set -x
        issue_command env GL_LIBS="-L${MESAGL_INSTALL_DIR}/lib" GL_CFLAGS="-I${MESAGL_INSTALL_DIR}/include" \
            CC=${C_COMPILER} CFLAGS="${C_OPT_FLAGS}" \
            CXX=${CXX_COMPILER} CXXFLAGS="${CXX_OPT_FLAGS}" \
           ./configure --prefix=${MESAGL_INSTALL_DIR} ${GLU_STATIC_DYNAMIC}
        set +x
        if [[ $? != 0 ]] ; then
            warn "GLU: 'configure' failed.  Giving up"
            return 1
        fi
    else
        warn "GLU: 'configure' failed.  Giving up"
        return 1
    fi

    ${MAKE} ${MAKE_OPT_FLAGS}
    if [[ $? != 0 ]] ; then
        warn "GLU: 'make' failed.  Giving up"
        return 1
    fi
    info "Installing GLU ..."
    ${MAKE} install
    if [[ $? != 0 ]] ; then
        warn "GLU: 'make install' failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/glu"
        chgrp -R ${GROUP} "$VISITDIR/glu"
    fi
    cd "$START_DIR"
    info "Done with GLU"
    return 0
}

function bv_glu_is_enabled
{
    if [[ $DO_GLU == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_glu_is_installed
{
    EXT=${SO_EXT}
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        EXT="a"
    fi
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        if [[ -e $VISITDIR/mesagl/$MESAGL_VERSION/$VISITARCH/lib/libGLU.${EXT} ]] ; then
            return 1
        fi
    fi
    return 0
}

function bv_glu_build
{
    #
    # Build GLU
    #
    cd "$START_DIR"
    if [[ "$DO_GLU" == "yes" ]] ; then
        bv_glu_is_installed
        if [[ $? == 1 ]] ; then
            info "Skipping GLU build.  GLU is already installed."
        else
            info "Building GLU (~2 minutes)"
            build_glu
            if [[ $? != 0 ]] ; then
                error "Unable to build or install GLU.  Bailing out."
            fi
            info "Done building GLU"
        fi
    fi
}
function bv_h5part_initialize
{
    export DO_H5PART="no"
}

function bv_h5part_enable
{
    DO_H5PART="yes"
    DO_HDF5="yes"
    DO_SZIP="yes"
}

function bv_h5part_disable
{
    DO_H5PART="no"
}

function bv_h5part_depends_on
{
    echo "szip hdf5"
}

function bv_h5part_info
{
    export H5PART_VERSION=${H5PART_VERSION:-"1.6.6"}
    export H5PART_FILE=${H5PART_FILE:-"H5Part-${H5PART_VERSION}.tar.gz"}
    export H5PART_COMPATIBILITY_VERSION=${H5PART_COMPATIBILITY_VERSION:-"1.6"}
    export H5PART_BUILD_DIR=${H5PART_BUILD_DIR:-"H5Part-${H5PART_VERSION}"}
    export H5PART_SHA256_CHECKSUM="10347e7535d1afbb08d51be5feb0ae008f73caf889df08e3f7dde717a99c7571"
}

function bv_h5part_print
{
    printf "%s%s\n" "H5PART_FILE=" "${H5PART_FILE}"
    printf "%s%s\n" "H5PART_VERSION=" "${H5PART_VERSION}"
    printf "%s%s\n" "H5PART_COMPATIBILITY_VERSION=" "${H5PART_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "H5PART_BUILD_DIR=" "${H5PART_BUILD_DIR}"
}

function bv_h5part_print_usage
{
    printf "%-20s %s [%s]\n" "--h5part" "Build H5Part" "$DO_H5PART"
}

function bv_h5part_host_profile
{
    if [[ "$DO_H5PART" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## H5Part" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "SETUP_APP_VERSION(H5PART $H5PART_VERSION)" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_H5PART_DIR \${VISITHOME}/h5part/\${H5PART_VERSION}/\${VISITARCH})" \
            >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_H5PART_LIBDEP HDF5_LIBRARY_DIR hdf5 \${VISIT_HDF5_LIBDEP} TYPE STRING)" \
            >> $HOSTCONF

    fi

}

function bv_h5part_ensure
{
    if [[ "$DO_H5PART" == "yes" ]] ; then
        ensure_built_or_ready "h5part" $H5PART_VERSION $H5PART_BUILD_DIR $H5PART_FILE $H5PART_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_H5PART="no"
            error "Unable to build H5Part.  ${H5PART_FILE} not found."
        fi
    fi
}

function apply_h5part_1_6_6_patch
{
    info "Patching H5Part"
    patch -p0 << \EOF
diff -rcN H5Part-1.6.6/src/H5PartTypes-orig.h  H5Part-1.6.6/src/H5PartTypes.h 
*** H5Part-1.6.6/src/H5PartTypes-orig.h	2016-12-14 14:04:41.000000000 -0700
--- H5Part-1.6.6/src/H5PartTypes.h	2016-12-14 14:00:57.000000000 -0700
***************
*** 19,28 ****
  #endif
   ;
  
- #ifndef PARALLEL_IO
- typedef unsigned long		MPI_Comm;
- #endif
- 
  #define H5PART_STEPNAME_LEN	64
  #define H5PART_DATANAME_LEN	64
  
--- 19,24 ----
***************
*** 86,93 ****
  	/**
  	   MPI communicator
  	*/
  	MPI_Comm comm;
! 
  	int throttle;
  
  	struct H5BlockStruct *block;
--- 82,90 ----
  	/**
  	   MPI communicator
  	*/
+ #ifdef PARALLEL_IO
  	MPI_Comm comm;
! #endif
  	int throttle;
  
  	struct H5BlockStruct *block;

diff -rcN H5Part-1.6.6/src/H5Part-orig.h  H5Part-1.6.6/src/H5Part.h
*** H5Part-1.6.6/src/H5Part-orig.h	2016-12-14 14:04:41.000000000 -0700
--- H5Part-1.6.6/src/H5Part.h	        2016-12-14 14:00:57.000000000 -0700
***************
*** 160,165 ****
--- 160,193 ----
  	const h5part_int32_t *array
  	);
  
+ h5part_int64_t
+ H5PartAppendDataFloat64 (
+ 	H5PartFile *f,
+ 	const char *name,
+ 	const h5part_float64_t *array
+ 	);
+ 
+ h5part_int64_t
+ H5PartAppendDataFloat32 (
+ 	H5PartFile *f,
+ 	const char *name,
+ 	const h5part_float32_t *array
+ 	);
+ 
+ h5part_int64_t
+ H5PartAppendDataInt64 (
+ 	H5PartFile *f,
+ 	const char *name,
+ 	const h5part_int64_t *array
+ 	);
+ 
+ h5part_int64_t
+ H5PartAppendDataInt32 (
+ 	H5PartFile *f,
+ 	const char *name,
+ 	const h5part_int32_t *array
+ 	);
+ 
  /*================== File Reading Routines =================*/
  h5part_int64_t
  H5PartSetStep (

diff -rcN H5Part-1.6.6/src/H5Part-orig.c  H5Part-1.6.6/src/H5Part.c
*** H5Part-1.6.6/src/H5Part-orig.c	2016-12-14 14:04:41.000000000 -0700
--- H5Part-1.6.6/src/H5Part.c	        2016-12-14 14:00:57.000000000 -0700
***************
*** 140,146 ****
--- 140,148 ----
  _H5Part_open_file (
  	const char *filename,	/*!< [in] The name of the data file to open. */
  	const char flags,	/*!< [in] The access mode for the file. */
+ #ifdef PARALLEL_IO
  	MPI_Comm comm,		/*!< [in] MPI communicator */
+ #endif	
  	int f_parallel,		/*!< [in] 0 for serial io otherwise parallel */
  	h5part_int64_t align	/*!< [in] Number of bytes for setting alignment,
  					  metadata block size, etc.
***************
*** 166,171 ****
--- 168,175 ----
  	f->xfer_prop = f->dcreate_prop = f->fcreate_prop = H5P_DEFAULT;
  
  	f->access_prop = H5Pcreate (H5P_FILE_ACCESS);
+         H5Pset_fclose_degree(f->access_prop, H5F_CLOSE_SEMI);
+ 	
  	if (f->access_prop < 0) {
  		HANDLE_H5P_CREATE_ERR;
  		goto error_cleanup;
***************
*** 282,288 ****
--- 286,294 ----
  #endif // PARALLEL_IO
  	} else {
  		_is_root_proc = 1;
+ #ifdef PARALLEL_IO
  		f->comm = 0;
+ #endif		
  		f->nprocs = 1;
  		f->myproc = 0;
  		f->pnparticles = 
***************
*** 481,491 ****
  	INIT
  	SET_FNAME ( "H5PartOpenFile" );
  
! 	MPI_Comm comm = 0;	/* dummy */
  	int f_parallel = 0;	/* serial open */
  	int align = 0;		/* no tuning parameters */
  
! 	return _H5Part_open_file ( filename, flags, comm, f_parallel, align );
  }
  
  /*!
--- 487,497 ----
  	INIT
  	SET_FNAME ( "H5PartOpenFile" );
  
! 	/* MPI_Comm comm = 0;	/\* dummy *\/ */
  	int f_parallel = 0;	/* serial open */
  	int align = 0;		/* no tuning parameters */
  
! 	return _H5Part_open_file ( filename, flags, /*comm,*/ f_parallel, align );
  }
  
  /*!
***************
*** 519,528 ****
  	INIT
  	SET_FNAME ( "H5PartOpenFileAlign" );
  
! 	MPI_Comm comm = 0;	/* dummy */
  	int f_parallel = 0;	/* serial open */
  
! 	return _H5Part_open_file ( filename, flags, comm, f_parallel, align );
  }
  
  /*!
--- 525,534 ----
  	INIT
  	SET_FNAME ( "H5PartOpenFileAlign" );
  
! 	/* MPI_Comm comm = 0;	/\* dummy *\/ */
  	int f_parallel = 0;	/* serial open */
  
! 	return _H5Part_open_file ( filename, flags, /*comm,*/ f_parallel, align );
  }
  
  /*!
***************
*** 1277,1282 ****
--- 1283,1487 ----
  	return H5PART_SUCCESS;
  }
  
+ static h5part_int64_t
+ _append_data (
+         H5PartFile *f,          /*!< IN: Handle to open file */
+         const char *name,       /*!< IN: Name to associate array with */
+         const void *array,      /*!< IN: Array to commit to disk */
+         const hid_t type        /*!< IN: Type of data */
+         ) {
+ 
+         herr_t herr;
+         hid_t dataset_id;
+ 
+         char name2[H5PART_DATANAME_LEN];
+         _normalize_dataset_name ( name, name2 );
+ 
+         _H5Part_print_debug (
+                      "Create a dataset[%s] mounted on "
+                      "timestep %lld",
+                      name2, (long long)f->timestep );
+ 
+         if ( f->shape == H5S_ALL ) {
+                 _H5Part_print_warn (
+                      "The view is unset or invalid: please "
+                      "set the view or specify a number of particles." );
+                 return HANDLE_H5PART_BAD_VIEW_ERR ( f->viewstart, f->viewend );
+           return -1;
+         }
+ 
+         H5E_BEGIN_TRY
+         dataset_id = H5Dopen ( f->timegroup, name2
+ #ifndef H5_USE_16_API
+                 , H5P_DEFAULT
+ #endif
+                 );
+         H5E_END_TRY
+ 
+         hid_t dataspace_id, filespace_id;
+ 
+         if ( dataset_id > 0 ) {
+ 
+           hsize_t dims[1] = {f->nparticles}; // dataset dimensions
+           hsize_t dims_in[1] = {0};          // incoming dimensions
+           hsize_t dims_out[1] = {0};         // outgoing dimensions
+ 
+           // Get the original dataspace.
+           dataspace_id = H5Dget_space(dataset_id);
+           if ( dataspace_id < 0 )
+             return HANDLE_H5D_CREATE_ERR ( name2, f->timestep );
+           herr = H5Sget_simple_extent_dims(dataspace_id, dims_in, NULL);
+ 
+           // Extend the dataset
+           dims_out[0] = dims_in[0] + dims[0];
+           herr = H5Dset_extent(dataset_id, dims_out);
+ 
+           // Create the hyperslab
+           filespace_id = H5Dget_space(dataset_id);
+           if ( filespace_id < 0 )
+             return HANDLE_H5D_CREATE_ERR ( name2, f->timestep );
+           herr = H5Sselect_hyperslab(filespace_id, H5S_SELECT_SET,
+                                      dims_in, NULL, dims, NULL);
+ 
+           // Define the memory space
+           dataspace_id = H5Screate_simple(1, dims, NULL);
+           if ( dataspace_id < 0 )
+             return HANDLE_H5D_CREATE_ERR ( name2, f->timestep );
+           
+           if ( herr < 0 )
+             return HANDLE_H5D_CREATE_ERR ( name2, f->timestep );
+         } else {          
+                 dataset_id = H5Dcreate (
+                         f->timegroup,
+                         name2,
+                         type,
+ 			// Use the memshape because it has unlimited bounds
+                         f->memshape, //f->shape,
+ #ifndef H5_USE_16_API
+                         H5P_DEFAULT,
+                         f->dcreate_prop,
+                         H5P_DEFAULT
+ #else
+                         f->dcreate_prop
+ #endif
+                );
+                 if ( dataset_id < 0 )
+                         return HANDLE_H5D_CREATE_ERR ( name2, f->timestep );
+ 
+                 // Create the hyperslab
+                 dataspace_id = f->memshape;
+                 filespace_id = f->diskshape;
+         }
+ 
+ #ifdef PARALLEL_IO
+         herr = _H5Part_start_throttle ( f );
+         if ( herr < 0 ) return herr;
+ #endif
+ 
+         herr = H5Dwrite(dataset_id,
+                         type,
+                         dataspace_id,   // f->memshape,
+                         filespace_id,   // f->diskshape,
+                         f->xfer_prop,
+                         array);
+ 
+ #ifdef PARALLEL_IO
+         herr = _H5Part_end_throttle ( f );
+         if ( herr < 0 ) return herr;
+ #endif
+ 
+         if ( herr < 0 ) return HANDLE_H5D_WRITE_ERR ( name2, f->timestep );
+ 
+         herr = H5Dclose ( dataset_id );
+         if ( herr < 0 ) return HANDLE_H5D_CLOSE_ERR;
+ 
+         f->empty = 0;
+ 
+         return H5PART_SUCCESS;
+ }
+ 
+ h5part_int64_t
+ H5PartAppendDataFloat32 (
+         H5PartFile *f,          /*!< [in] Handle to open file */
+         const char *name,       /*!< [in] Name to associate array with */
+         const h5part_float32_t *array   /*!< [in] Array to commit to disk */
+         ) {
+ 
+         SET_FNAME ( "H5PartWriteDataFloat64" );
+         h5part_int64_t herr;
+ 
+         CHECK_FILEHANDLE ( f );
+         CHECK_WRITABLE_MODE( f );
+         CHECK_TIMEGROUP( f );
+ 
+         herr = _append_data ( f, name, (void*)array, H5T_NATIVE_FLOAT );
+         if ( herr < 0 ) return herr;
+ 
+         return H5PART_SUCCESS;
+ }
+ 
+ h5part_int64_t
+ H5PartAppendDataFloat64 (
+         H5PartFile *f,          /*!< [in] Handle to open file */
+         const char *name,       /*!< [in] Name to associate array with */
+         const h5part_float64_t *array   /*!< [in] Array to commit to disk */
+         ) {
+ 
+         SET_FNAME ( "H5PartWriteDataFloat64" );
+         h5part_int64_t herr;
+ 
+         CHECK_FILEHANDLE ( f );
+         CHECK_WRITABLE_MODE( f );
+         CHECK_TIMEGROUP( f );
+ 
+         herr = _append_data ( f, name, (void*)array, H5T_NATIVE_DOUBLE );
+         if ( herr < 0 ) return herr;
+ 
+         return H5PART_SUCCESS;
+ }
+ 
+ 
+ h5part_int64_t
+ H5PartAppendDataInt32 (
+         H5PartFile *f,          /*!< [in] Handle to open file */
+         const char *name,       /*!< [in] Name to associate array with */
+         const h5part_int32_t *array   /*!< [in] Array to commit to disk */
+         ) {
+ 
+         SET_FNAME ( "H5PartWriteDataInt64" );
+         h5part_int64_t herr;
+ 
+         CHECK_FILEHANDLE ( f );
+         CHECK_WRITABLE_MODE( f );
+         CHECK_TIMEGROUP( f );
+ 
+         herr = _append_data ( f, name, (void*)array, H5T_NATIVE_INT32 );
+         if ( herr < 0 ) return herr;
+ 
+         return H5PART_SUCCESS;
+ }
+ 
+ h5part_int64_t
+ H5PartAppendDataInt64 (
+         H5PartFile *f,          /*!< [in] Handle to open file */
+         const char *name,       /*!< [in] Name to associate array with */
+         const h5part_int64_t *array   /*!< [in] Array to commit to disk */
+         ) {
+ 
+         SET_FNAME ( "H5PartWriteDataInt64" );
+         h5part_int64_t herr;
+ 
+         CHECK_FILEHANDLE ( f );
+         CHECK_WRITABLE_MODE( f );
+         CHECK_TIMEGROUP( f );
+ 
+         herr = _append_data ( f, name, (void*)array, H5T_NATIVE_INT64 );
+         if ( herr < 0 ) return herr;
+ 
+         return H5PART_SUCCESS;
+ }
+ 
+ 
  /********************** reading and writing attribute ************************/
  
  /********************** private functions to handle attributes ***************/

EOF

}

function apply_h5part_patch
{
    if [[ ${H5PART_VERSION} == 1.6.6 ]] ; then
        apply_h5part_1_6_6_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0
}

# ***************************************************************************
#                         Function 8.10, build_h5part
#
# Modifications:
#
#  Mark C. Miller, Tue Oct 28 11:10:36 PDT 2008
#  Added -DH5_USE_16_API to CFLAGS for configuring H5Part. This should be
#  harmless when building H5Part against versions of HDF5 before 1.8 and
#  necessary when building against versions of HDF5 1.8 or later. It tells
#  HDF5 which version of the HDF5 API H5Part was implemented with.
#
#  Gunther H. Weber, Wed Jul 27 14:48:12 PDT 2011
#  Adapted to H5Part 1.6.3 which can correctly build shared libraries, does
#  not require -DH5_USE_16_API in CFLAGS and has a new way to pass path to
#  HDF5.
#
# ***************************************************************************

function build_h5part
{
    #
    # Prepare build dir
    #
    prepare_build_dir $H5PART_BUILD_DIR $H5PART_FILE
    untarred_h5part=$?
    if [[ $untarred_h5part == -1 ]] ; then
        warn "Unable to prepare H5Part Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    apply_h5part_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_h5part == 1 ]] ; then
            warn "Giving up on H5part build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Apply configure
    #
    info "Configuring H5Part . . ."
    cd $H5PART_BUILD_DIR || error "Can't cd to h5part build dir."
    if [[ "$DO_HDF5" == "yes" ]] ; then
        export HDF5ROOT="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH"
        export SZIPROOT="$VISITDIR/szip/$SZIP_VERSION/$VISITARCH"
        WITHHDF5ARG="--with-hdf5=$HDF5ROOT"
        HDF5DYLIB="-L$HDF5ROOT/lib -L$SZIPROOT/lib -lhdf5 -lsz -lz"
    else
        WITHHDF5ARG="--with-hdf5"
        HDF5DYLIB=""
    fi

    if [[ "$OPSYS" == "Darwin" ]]; then
        export DYLD_LIBRARY_PATH="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/lib":\
               "$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib":\
               $DYLD_LIBRARY_PATH
        SOARG="--enable-shared"
    else
        export LD_LIBRARY_PATH="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/lib":\
               "$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib":\
               $LD_LIBRARY_PATH
        SOARG=""
    fi
    if [[ "$FC_COMPILER" == "no" ]] ; then
        FORTRANARGS=""
    else
        FORTRANARGS="FC=\"$FC_COMPILER\" F77=\"$FC_COMPILER\" FCFLAGS=\"$FCFLAGS\" FFLAGS=\"$FCFLAGS\" --enable-fortran"
    fi

    EXTRAARGS=""
    # detect coral and NVIDIA Grace CPU (ARM) systems, which older versions of 
    # autoconf don't detect
    if [[ "$(uname -m)" == "ppc64le" ]] ; then
         EXTRAARGS="ac_cv_build=powerpc64le-unknown-linux-gnu"
    elif [[ "$(uname -m)" == "aarch64" ]] ; then
         EXTRAARGS="ac_cv_build=aarch64-unknown-linux-gnu"
    fi

    info "Invoking command to configure H5Part"
    # In order to ensure $FORTRANARGS is expanded to build the arguments to
    # configure, we wrap the invokation in 'sh -c "..."' syntax
    set -x
    sh -c "./configure ${WITHHDF5ARG} ${OPTIONAL} CXX=\"$CXX_COMPILER\" \
       CC=\"$C_COMPILER\" CFLAGS=\"$CFLAGS $C_OPT_FLAGS\" CXXFLAGS=\"$CXXFLAGS $CXX_OPT_FLAGS\" \
       $FORTRANARGS $EXTRAARGS \
       --prefix=\"$VISITDIR/h5part/$H5PART_VERSION/$VISITARCH\""
    set +x
    if [[ $? != 0 ]] ; then
        warn "H5Part configure failed.  Giving up"
        return 1
    fi

    #
    # Build H5Part
    #
    info "Building H5Part . . . (~1 minutes)"

    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "H5Part build failed.  Giving up"
        return 1
    fi
    info "Installing H5Part . . ."

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "H5Part build (make install) failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        #
        # Make dynamic executable, need to patch up the install path and
        # version information.
        #
        info "Creating dynamic libraries for H5Part . . ."
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/h5part"
        chgrp -R ${GROUP} "$VISITDIR/h5part"
    fi
    cd "$START_DIR"
    info "Done with H5Part"
    return 0
}

function bv_h5part_is_enabled
{
    if [[ $DO_H5PART == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_h5part_is_installed
{
    check_if_installed "h5part" $H5PART_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_h5part_build
{
    cd "$START_DIR"
    if [[ "$DO_H5PART" == "yes" ]] ; then
        check_if_installed "h5part" $H5PART_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping H5Part build.  H5Part is already installed."
        else
            info "Building H5Part (~1 minutes)"
            build_h5part
            if [[ $? != 0 ]] ; then
                error "Unable to build or install H5Part.  Bailing out."
            fi
            info "Done building H5Part"
        fi
    fi

}
function bv_hdf5_initialize
{
    export DO_HDF5="no"
    export USE_SYSTEM_HDF5="no"
    add_extra_commandline_args "hdf5" "alt-hdf5-dir" 1 "Use alternative directory for hdf5"
}

function bv_hdf5_enable
{
    DO_HDF5="yes"
}

function bv_hdf5_disable
{
    DO_HDF5="no"
}

function bv_hdf5_alt_hdf5_dir
{
    bv_hdf5_enable
    USE_SYSTEM_HDF5="yes"
    HDF5_INSTALL_DIR="$1"
}

function bv_hdf5_depends_on
{
    if [[ "$USE_SYSTEM_HDF5" == "yes" ]]; then
        echo ""
    else
        local depends_on=""

        if [[ "$DO_ZLIB" == "yes" ]] ; then
            depends_on="$depends_on zlib"
        fi

        if [[ "$DO_SZIP" == "yes" ]] ; then
            depends_on="$depends_on szip"
        fi

        if [[ -n "$PAR_COMPILER" && "$DO_MOAB" == "yes"  && "$DO_MPICH" == "yes" ]]; then
            depends_on="$depends_on mpich"
        fi

        echo $depends_on
    fi
}

function bv_hdf5_initialize_vars
{
    if [[ "$USE_SYSTEM_HDF5" == "no" ]]; then
        HDF5_INSTALL_DIR="${VISITDIR}/hdf5/$HDF5_VERSION/${VISITARCH}"
        if [[ -n "$PAR_COMPILER" && "$DO_MOAB" == "yes" ]]; then
            HDF5_MPI_INSTALL_DIR="${VISITDIR}/hdf5_mpi/$HDF5_VERSION/${VISITARCH}"
        fi
    fi
}

function bv_hdf5_info
{
    export HDF5_VERSION=${HDF5_VERSION:-"1.8.14"}
    export HDF5_FILE=${HDF5_FILE:-"hdf5-${HDF5_VERSION}.tar.gz"}
    export HDF5_COMPATIBILITY_VERSION=${HDF5_COMPATIBILITY_VERSION:-"1.8"}
    export HDF5_BUILD_DIR=${HDF5_BUILD_DIR:-"hdf5-${HDF5_VERSION}"}
    export HDF5_SHA256_CHECKSUM="1dbefeeef7f591897c632b2b090db96bb8d35ad035beaa36bc39cb2bc67e0639"
}

function bv_hdf5_print
{
    printf "%s%s\n" "HDF5_FILE=" "${HDF5_FILE}"
    printf "%s%s\n" "HDF5_VERSION=" "${HDF5_VERSION}"
    printf "%s%s\n" "HDF5_COMPATIBILITY_VERSION=" "${HDF5_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "HDF5_BUILD_DIR=" "${HDF5_BUILD_DIR}"
}

function bv_hdf5_print_usage
{
    printf "%-20s %s [%s]\n" "--hdf5" "Build HDF5" "${DO_HDF5}"
    printf "%-20s %s [%s]\n" "--alt-hdf5-dir" "Use HDF5 from an alternative directory"
}

function bv_hdf5_host_profile
{
    if [[ "$DO_HDF5" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## HDF5" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        if [[ "$USE_SYSTEM_HDF5" == "yes" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_HDF5_DIR $HDF5_INSTALL_DIR)" \
                >> $HOSTCONF 
        else
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_HDF5_DIR \${VISITHOME}/hdf5/$HDF5_VERSION/\${VISITARCH})" \
                >> $HOSTCONF 

            if [[ -n "$HDF5_MPI_INSTALL_DIR" ]]; then
                echo \
                    "VISIT_OPTION_DEFAULT(VISIT_HDF5_MPI_DIR \${VISITHOME}/hdf5_mpi/$HDF5_VERSION/\${VISITARCH})" \
                    >> $HOSTCONF 
            fi

            ZLIB_LIBDEP=""
            if [[ "$DO_ZLIB" == "yes" ]] ; then
                ZLIB_LIBDEP="\${VISITHOME}/zlib/\${ZLIB_VERSION}/\${VISITARCH}/lib z"
            fi
            SZIP_LIBDEP=""
            if [[ "$DO_SZIP" == "yes" ]] ; then
                SZIP_LIBDEP="\${VISITHOME}/szip/$SZIP_VERSION/\${VISITARCH}/lib sz"
            fi
            
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_HDF5_LIBDEP $SZIP_LIBDEP $ZLIB_LIBDEP TYPE STRING)" \
                    >> $HOSTCONF
            if [[ -n "$HDF5_MPI_INSTALL_DIR" ]]; then
                echo \
                    "VISIT_OPTION_DEFAULT(VISIT_HDF5_MPI_LIBDEP $SZIP_LIBDEP $ZLIB_LIBDEP TYPE STRING)" \
                        >> $HOSTCONF
            fi
        fi
    fi
}

function bv_hdf5_ensure
{
    if [[ "$DO_HDF5" == "yes" && "$USE_SYSTEM_HDF5" == "no" ]] ; then
        ensure_built_or_ready "hdf5" $HDF5_VERSION $HDF5_BUILD_DIR $HDF5_FILE $HDF5_URL 
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_HDF5="no"
            error "Unable to build HDF5.  ${HDF5_FILE} not found."
        fi
    fi
}

function apply_hdf5_1814_static_patch
{
    info "Patching hdf5 1.8.14 for static build"
    patch -p0 << \EOF
*** src/H5PL.c.orig    2015-10-23 11:51:35.000000000 -0700
--- src/H5PL.c  2015-10-23 11:56:48.000000000 -0700
***************
*** 159,165 ****
      char        *preload_path;
  
      FUNC_ENTER_STATIC_NOERR
! 
      /* Retrieve pathnames from HDF5_PLUGIN_PRELOAD if the user sets it
       * to tell the library to load plugin libraries without search.
       */
--- 159,165 ----
      char        *preload_path;
  
      FUNC_ENTER_STATIC_NOERR
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* Retrieve pathnames from HDF5_PLUGIN_PRELOAD if the user sets it
       * to tell the library to load plugin libraries without search.
       */
***************
*** 168,174 ****
          if(!HDstrcmp(preload_path, H5PL_NO_PLUGIN))
              H5PL_no_plugin_g = TRUE;
      } /* end if */
! 
      FUNC_LEAVE_NOAPI(SUCCEED)
  } /* end H5PL__init_interface() */
  
--- 168,174 ----
          if(!HDstrcmp(preload_path, H5PL_NO_PLUGIN))
              H5PL_no_plugin_g = TRUE;
      } /* end if */
! #endif
      FUNC_LEAVE_NOAPI(SUCCEED)
  } /* end H5PL__init_interface() */
  
***************
*** 193,201 ****
      htri_t ret_value;
  
      FUNC_ENTER_NOAPI(FAIL)
! 
      ret_value = (htri_t)H5PL_no_plugin_g;
! 
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL_no_plugin() */
--- 193,201 ----
      htri_t ret_value;
  
      FUNC_ENTER_NOAPI(FAIL)
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      ret_value = (htri_t)H5PL_no_plugin_g;
! #endif
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL_no_plugin() */
***************
*** 224,230 ****
      int  i = 0;
      
      FUNC_ENTER_NOAPI_NOINIT_NOERR
! 
      if(H5_interface_initialize_g) {
          size_t u;       /* Local index variable */
  
--- 224,230 ----
      int  i = 0;
      
      FUNC_ENTER_NOAPI_NOINIT_NOERR
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      if(H5_interface_initialize_g) {
          size_t u;       /* Local index variable */
  
***************
*** 246,252 ****
        H5_interface_initialize_g = 0;
          i = 1;
      } /* end if */
! 
      FUNC_LEAVE_NOAPI(i)
  } /* end H5PL_term_interface() */
  
--- 246,252 ----
        H5_interface_initialize_g = 0;
          i = 1;
      } /* end if */
! #endif
      FUNC_LEAVE_NOAPI(i)
  } /* end H5PL_term_interface() */
  
***************
*** 273,279 ****
      const void  *ret_value = NULL;
  
      FUNC_ENTER_NOAPI(NULL)
! 
      /* Check for "no plugins" indicated" */
      if(H5PL_no_plugin_g)
          HGOTO_ERROR(H5E_PLUGIN, H5E_CANTLOAD, NULL, "required dynamically loaded plugin filter '%d' is not available", id)
--- 273,279 ----
      const void  *ret_value = NULL;
  
      FUNC_ENTER_NOAPI(NULL)
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* Check for "no plugins" indicated" */
      if(H5PL_no_plugin_g)
          HGOTO_ERROR(H5E_PLUGIN, H5E_CANTLOAD, NULL, "required dynamically loaded plugin filter '%d' is not available", id)
***************
*** 308,314 ****
      /* Check if we found the plugin */
      if(found)
          ret_value = plugin_info;
! 
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL_load() */
--- 308,314 ----
      /* Check if we found the plugin */
      if(found)
          ret_value = plugin_info;
! #endif
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL_load() */
***************
*** 335,341 ****
      herr_t      ret_value = SUCCEED;    /* Return value */
  
      FUNC_ENTER_STATIC
! 
      /* Retrieve paths from HDF5_PLUGIN_PATH if the user sets it
       * or from the default paths if it isn't set.
       */
--- 335,341 ----
      herr_t      ret_value = SUCCEED;    /* Return value */
  
      FUNC_ENTER_STATIC
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* Retrieve paths from HDF5_PLUGIN_PATH if the user sets it
       * or from the default paths if it isn't set.
       */
***************
*** 360,366 ****
      } /* end while */
  
      H5PL_path_found_g = TRUE;
! 
  done:
      if(dl_path)
          dl_path = (char *)H5MM_xfree(dl_path);
--- 360,366 ----
      } /* end while */
  
      H5PL_path_found_g = TRUE;
! #endif
  done:
      if(dl_path)
          dl_path = (char *)H5MM_xfree(dl_path);
***************
*** 396,402 ****
      htri_t         ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! 
      /* Open the directory */  
      if(!(dirp = HDopendir(dir)))
          HGOTO_ERROR(H5E_PLUGIN, H5E_OPENERROR, FAIL, "can't open directory")
--- 396,402 ----
      htri_t         ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* Open the directory */  
      if(!(dirp = HDopendir(dir)))
          HGOTO_ERROR(H5E_PLUGIN, H5E_OPENERROR, FAIL, "can't open directory")
***************
*** 438,444 ****
                  pathname = (char *)H5MM_xfree(pathname);
          } /* end if */
      } /* end while */
! 
  done:
      if(dirp) 
          if(HDclosedir(dirp) < 0)
--- 438,444 ----
                  pathname = (char *)H5MM_xfree(pathname);
          } /* end if */
      } /* end while */
! #endif
  done:
      if(dirp) 
          if(HDclosedir(dirp) < 0)
***************
*** 459,465 ****
      htri_t          ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! 
      /* Specify a file mask. *.* = We want everything! */
      sprintf(service, "%s\\*.dll", dir);
      if((hFind = FindFirstFile(service, &fdFile)) == INVALID_HANDLE_VALUE)
--- 459,465 ----
      htri_t          ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* Specify a file mask. *.* = We want everything! */
      sprintf(service, "%s\\*.dll", dir);
      if((hFind = FindFirstFile(service, &fdFile)) == INVALID_HANDLE_VALUE)
***************
*** 494,500 ****
                  pathname = (char *)H5MM_xfree(pathname);
          } /* end if */
      } while(FindNextFile(hFind, &fdFile)); /* Find the next file. */
! 
  done:
      if(hFind) 
          FindClose(hFind);
--- 494,500 ----
                  pathname = (char *)H5MM_xfree(pathname);
          } /* end if */
      } while(FindNextFile(hFind, &fdFile)); /* Find the next file. */
! #endif
  done:
      if(hFind) 
          FindClose(hFind);
***************
*** 529,535 ****
      htri_t         ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! 
      /* There are different reasons why a library can't be open, e.g. wrong architecture.
       * simply continue if we can't open it.
       */
--- 529,535 ----
      htri_t         ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* There are different reasons why a library can't be open, e.g. wrong architecture.
       * simply continue if we can't open it.
       */
***************
*** 588,594 ****
                      HGOTO_ERROR(H5E_PLUGIN, H5E_CLOSEERROR, FAIL, "can't close dynamic library")
          } /* end if */
      } /* end else */
! 
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL__open() */
--- 588,594 ----
                      HGOTO_ERROR(H5E_PLUGIN, H5E_CLOSEERROR, FAIL, "can't close dynamic library")
          } /* end if */
      } /* end else */
! #endif
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL__open() */
***************
*** 615,621 ****
      htri_t         ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! 
      /* Search in the table of already opened dynamic libraries */
      if(H5PL_table_used_g > 0) {
          size_t         i;
--- 615,621 ----
      htri_t         ret_value = FALSE;
  
      FUNC_ENTER_STATIC
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      /* Search in the table of already opened dynamic libraries */
      if(H5PL_table_used_g > 0) {
          size_t         i;
***************
*** 636,642 ****
              } /* end if */
          } /* end for */
      } /* end if */
! 
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL__search_table() */
--- 636,642 ----
              } /* end if */
          } /* end for */
      } /* end if */
! #endif
  done:
      FUNC_LEAVE_NOAPI(ret_value)
  } /* end H5PL__search_table() */
***************
*** 658,666 ****
  H5PL__close(H5PL_HANDLE handle)
  {
      FUNC_ENTER_STATIC_NOERR
! 
      H5PL_CLOSE_LIB(handle);
!    
      FUNC_LEAVE_NOAPI(SUCCEED)
  } /* end H5PL__close() */
  #endif /*H5_VMS*/
--- 658,666 ----
  H5PL__close(H5PL_HANDLE handle)
  {
      FUNC_ENTER_STATIC_NOERR
! #ifdef H5_SUPPORT_DYNAMIC_LOADING
      H5PL_CLOSE_LIB(handle);
! #endif
      FUNC_LEAVE_NOAPI(SUCCEED)
  } /* end H5PL__close() */
  #endif /*H5_VMS*/
EOF
    if [[ $? != 0 ]] ; then
        warn "HDF5 1.8.14 static patch failed."
        return 1
    fi

    return 0;
}


function apply_hdf5_1814_isatty_patch
{
    info "Patching hdf5 1.8.14 for isatty"
    patch -p0 << \EOF
--- hl/src/H5LTanalyze.c.orig	2014-11-07 04:53:42.000000000 -0800
+++ hl/src/H5LTanalyze.c	2021-02-01 13:40:36.000000000 -0800
@@ -40,6 +40,7 @@
 #include <string.h>
 #include <errno.h>
 #include <stdlib.h>
+#include <unistd.h>
 
 /* end standard C headers. */
EOF
    if [[ $? != 0 ]] ; then
        warn "HDF5 1.8.14 isatty patch failed."
        return 1
    fi

    return 0;
}

function apply_hdf5_patch
{
    # Apply a patch for static if we build statically.
    if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
        apply_hdf5_1814_static_patch
        if [[ $? != 0 ]]; then
            return 1
        fi
    fi

    apply_hdf5_1814_isatty_patch
    if [[ $? != 0 ]]; then
        return 1
    fi

    return 0
}

# *************************************************************************** #
#                          Function 8.1, build_hdf5                           #
# *************************************************************************** #

function build_hdf5
{
    #
    # Prepare build dir
    #
    prepare_build_dir $HDF5_BUILD_DIR $HDF5_FILE
    untarred_hdf5=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_hdf5 == -1 ]] ; then
        warn "Unable to prepare HDF5 Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    cd $HDF5_BUILD_DIR || error "Can't cd to HDF5 build dir."
    apply_hdf5_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_hdf5 == 1 ]] ; then
            warn "Giving up on HDF5 build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Fix a test failing to compile
    #
    if [[ "$OPSYS" == "Darwin" && $(uname -r | cut -d'.' -f1) -ge 23 ]]; then
        sed -i '' 's/{NULL}};/{0}};/' test/tmisc.c
    fi

    #
    # Configure HDF5
    #
    info "Configuring HDF5 . . ."
    if [[ "$OPSYS" == "Darwin" ]]; then
        export DYLD_LIBRARY_PATH="$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib":$DYLD_LIBRARY_PATH
    else
        export LD_LIBRARY_PATH="$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib":$LD_LIBRARY_PATH
    fi
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        cf_build_type="--disable-shared --enable-static"
    else
        cf_build_type="--enable-shared --disable-static"
    fi
    cf_szip=""
    if test "x${DO_SZIP}" = "xyes"; then
        info "SZip requested.  Configuring HDF5 with SZip support."
        sz_dir="${VISITDIR}/szip/${SZIP_VERSION}/${VISITARCH}"
        cf_szip="--with-szlib=${sz_dir}"
    fi
    cf_zlib=""
    if [[ "$DO_ZLIB" == "yes" ]]; then
        info "Configuring HDF5 with ZLib support."
        cf_zlib="--with-zlib=\"${VISITDIR}/zlib/${ZLIB_VERSION}/${VISITARCH}\""
    fi

    cf_extra_flags=""
    if [[ "$OPSYS" == "Darwin" ]]; then
        if [[ "$(uname -m)" == "arm64" ]]; then
            cf_extra_flags="-Wno-error=implicit-function-declaration"
        fi
    fi

    # Disable Fortran on Darwin since it causes HDF5 builds to fail.
    if [[ "$OPSYS" == "Darwin" ]]; then
        cf_fortranargs=""
    elif [[ "$FC_COMPILER" == "no" ]] ; then
        cf_fortranargs=""
    else
        cf_fortranargs="FC=\"$FC_COMPILER\" F77=\"$FC_COMPILER\" FCFLAGS=\"$FCFLAGS\" FFLAGS=\"$FCFLAGS\" --enable-fortran"
    fi

    cf_build_thread=""
    if [[ "$DO_THREAD_BUILD" == "yes" ]]; then
        cf_build_thread="--enable-threadsafe --with-pthread"
    fi

    build_mode=""
    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        build_mode="--disable-production"
    fi

    par_build_types="serial"
    if [[ -n "$PAR_COMPILER" && "$DO_MOAB" == "yes" ]]; then
        par_build_types="$par_build_types parallel"
    fi

    extra_ac_flags=""
    # detect coral and NVIDIA Grace CPU (ARM) systems, which older versions of 
    # autoconf don't detect
    if [[ "$(uname -m)" == "ppc64le" ]] ; then
         extra_ac_flags="ac_cv_build=powerpc64le-unknown-linux-gnu"
    elif [[ "$(uname -m)" == "aarch64" ]] ; then
         extra_ac_flags="ac_cv_build=aarch64-unknown-linux-gnu"
    fi 
    
    for bt in $par_build_types; do

        rm -rf build_$bt
        mkdir build_$bt
        pushd build_$bt

        cf_build_parallel=""
        cf_par_suffix=""
        if [[ "$bt" == "serial" ]]; then
            cf_build_parallel="--disable-parallel"
            cf_c_compiler="$C_COMPILER"
        elif [[ "$bt" == "parallel" ]]; then
            # these commands ruin the untar'd source code for 'normal' builds
            sed -e 's/libhdf5/libhdf5_mpi/g' -i.orig ../configure
            find .. -name Makefile.in -exec sed -e 's/libhdf5/libhdf5_mpi/g' -i.orig {} \;
            sed -e 's/libhdf5\.settings/libhdf5_mpi.settings/g' -i.orig ../src/H5make_libsettings.c
            pushd ../src; ln -s libhdf5.settings.in libhdf5_mpi.settings.in; popd
            cf_build_parallel="--enable-parallel"
            cf_par_suffix="_mpi"
            cf_c_compiler="$PAR_COMPILER"
        fi

        # In order to ensure $cf_fortranargs is expanded to build the arguments to
        C_OPT_FLAGS="-Wno-error=implicit-function-declaration"
	# ignore conversion of NULL to int.
	C_OPT_FLAGS="$C_OPT_FLAGS -Wno-error=int-conversion"
        info "Invoking command to configure $bt HDF5"
        set -x
        # configure, we wrap the invokation in 'sh -c "..."' syntax
        sh -c "../configure CC=\"$cf_c_compiler\" \
            CFLAGS=\"$CFLAGS $C_OPT_FLAGS $cf_extra_flags\" $cf_fortranargs \
            --prefix=\"$VISITDIR/hdf5${cf_par_suffix}/$HDF5_VERSION/$VISITARCH\" \
            ${cf_szip} ${cf_zlib} ${cf_build_type} ${cf_build_thread} \
            ${cf_build_parallel} ${extra_ac_flags} $build_mode"
        set +x
        if [[ $? != 0 ]] ; then
            warn "$bt HDF5 configure failed.  Giving up"
            return 1
        fi

        #
        # Build HDF5
        #
        info "Making $bt HDF5 . . ."
        set -x
        $MAKE $MAKE_OPT_FLAGS lib
        set +x
        if [[ $? != 0 ]] ; then
            warn "$bt HDF5 build failed.  Giving up"
            return 1
        fi
        #
        # Install into the VisIt third party location.
        #
        # Install all targets until we can figure out
        # how to avoid installing just the tests.
        #
        info "Installing $bt HDF5 . . ."
        $MAKE install

        if [[ $? != 0 ]] ; then
            warn "$bt HDF5 install failed.  Giving up"
            return 1
        fi

        if [[ "$DO_GROUP" == "yes" ]] ; then
            chmod -R ug+w,a+rX "$VISITDIR/hdf5"
            chgrp -R ${GROUP} "$VISITDIR/hdf5"
        fi

        popd
    done

    cd "$START_DIR"
    info "Done with HDF5"
    return 0
}

function bv_hdf5_is_enabled
{
    if [[ $DO_HDF5 == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_hdf5_is_installed
{

    if [[ "$USE_SYSTEM_HDF5" == "yes" ]]; then
        return 1
    fi

    check_if_installed "hdf5" $HDF5_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_hdf5_build
{
    cd "$START_DIR"
    
    if [[ "$DO_HDF5" == "yes" && "$USE_SYSTEM_HDF5" == "no" ]] ; then
        check_if_installed "hdf5" $HDF5_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping HDF5 build.  HDF5 is already installed."
        else
            info "Building HDF5 (~15 minutes)"
            build_hdf5
            if [[ $? != 0 ]] ; then
                error "Unable to build or install HDF5.  Bailing out."
            fi
            info "Done building HDF5"
        fi
    fi
}
function bv_icet_initialize
{
    export DO_ICET="no"
}

function bv_icet_enable
{
    DO_ICET="yes"
}

function bv_icet_disable
{
    DO_ICET="no"
}

function bv_icet_depends_on
{
    depends_on="cmake"
    if [[ "$DO_MPICH" == "yes" ]] ; then
        depends_on="$depends_on mpich"
    fi

    echo $depends_on
}

function bv_icet_info
{
    export ICET_FILE=${ICET_FILE:-"icet-master-77c708f9090236b576669b74c53e9f105eedbd7e.tar.gz"}
    export ICET_VERSION=${ICET_VERSION:-"77c708f9090236b576669b74c53e9f105eedbd7e"}
    export ICET_COMPATIBILITY_VERSION=${ICET_COMPATIBILITY_VERSION:-"77c708f9090236b576669b74c53e9f105eedbd7e"}
    export ICET_BUILD_DIR=${ICET_BUILD_DIR:-"icet-master-77c708f9090236b576669b74c53e9f105eedbd7e"}
    export ICET_SHA256_CHECKSUM="38ed9599b4815b376444223435905b66763912cb66749d90d377ef41d430ba77"
}

function bv_icet_print
{
    printf "%s%s\n" "ICET_FILE=" "${ICET_FILE}"
    printf "%s%s\n" "ICET_VERSION=" "${ICET_VERSION}"
    printf "%s%s\n" "ICET_COMPATIBILITY_VERSION=" "${ICET_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "ICET_BUILD_DIR=" "${ICET_BUILD_DIR}"
}

function bv_icet_print_usage
{
    printf "%-20s %s [%s]\n" "--icet" "Build IceT (parallel rendering lib)" "$DO_ICET"
    printf "%-20s %s [%s]\n" "--no-icet" "Prevent IceT from being built" "$PREVENT_ICET"
    printf "%-20s %s\n" "" "NOTE: IceT is automatically built with --enable-parallel."
}

function bv_icet_host_profile
{
    if [[ "$DO_ICET" == "yes" && "$PREVENT_ICET" != "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## IceT" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_ICET_DIR \${VISITHOME}/icet/$ICET_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi
}

function bv_icet_ensure
{
    if [[ "$DO_ICET" == "yes" && "$PREVENT_ICET" != "yes" ]] ; then
        ensure_built_or_ready "icet" $ICET_VERSION $ICET_BUILD_DIR $ICET_FILE "http://icet.sandia.gov/_assets/files"
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_ICET="no"
            error "Unable to build IceT.  ${ICET_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                           Function 8.13, build_icet                         #
# *************************************************************************** #

function apply_icet_patch
{
    info "Patching IceT . . ."
    return 0
}

function build_icet
{
    # We need to set MPI_COMPILER for CMake. We can get that from MPICH
    # or from PAR_COMPILER. Note that DO_MPICH causes PAR_COMPILER to be
    # set, so testing for that also catches using MPICH.
    if [[ "$PAR_COMPILER" == "" ]] ; then
        warn "To build IceT, you must either use MPICH (add --mpich) or set the PAR_COMPILER environment variable."
        warn "PAR_COMPILER should be of the form \"/path/to/mpi/bin/mpicc\""
        warn "Giving Up!"
        return 1
    fi

    #
    # CMake is the build system for IceT.  We already required CMake to be
    # built, so it should be there.
    #
    CMAKE_BIN="${CMAKE_COMMAND}"

    prepare_build_dir $ICET_BUILD_DIR $ICET_FILE
    untarred_icet=$?
    if [[ $untarred_icet == -1 ]] ; then
        warn "Unable to prepare IceT build directory. Giving Up!"
        return 1
    fi

    apply_icet_patch

    info "Executing CMake on IceT"
    cd $ICET_BUILD_DIR || error "Can't cd to IceT build dir."
    if [[ "$DO_STATIC_BUILD" == "no" ]]; then
        LIBEXT="${SO_EXT}"
    else
        LIBEXT="a"
    fi
    rm -f CMakeCache.txt

    iopts=""
    if [[ "$OPSYS" == "Darwin" ]] ; then
        ${CMAKE_BIN} \
        iopts="${iopts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
        iopts="${iopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
        iopts="${iopts} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"
        iopts="${iopts} -DCMAKE_C_FLAGS:STRING=\"${CFLAGS} ${C_OPT_FLAGS}\""
        iopts="${iopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXXFLAGS} ${CXX_OPT_FLAGS}\""
        iopts="${iopts} -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON"
        iopts="${iopts} -DCMAKE_INSTALL_PREFIX:PATH=$VISITDIR/icet/${ICET_VERSION}/${VISITARCH}"
        iopts="${iopts} -DCMAKE_C_FLAGS:STRING=\"-fPIC ${CFLAGS} ${C_OPT_FLAGS}\""
        iopts="${iopts} -DMPI_COMPILER:PATH=${PAR_COMPILER}"
        iopts="${iopts} -DBUILD_TESTING:BOOL=OFF"
    else
        if [[ "$DO_MESAGL" == "yes" ]] ; then
            iopts="${iopts} -DOPENGL_INCLUDE_DIR:PATH=$VISITDIR/mesagl/${MESAGL_VERSION}/${VISITARCH}/include"
            iopts="${iopts} -DOPENGL_gl_LIBRARY:FILEPATH=$VISITDIR/mesagl/${MESAGL_VERSION}/${VISITARCH}/lib/libOSMesa.${LIBEXT}"
        elif [[ "$DO_OSMESA" == "yes" ]] ; then
            iopts="${iopts} -DOPENGL_INCLUDE_DIR:PATH=$VISITDIR/osmesa/${OSMESA_VERSION}/${VISITARCH}/include"
            iopts="${iopts} -DOPENGL_gl_LIBRARY:FILEPATH=$VISITDIR/osmesa/${OSMESA_VERSION}/${VISITARCH}/lib/libOSMesa.${LIBEXT}"
        fi
        iopts="${iopts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
        iopts="${iopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
        iopts="${iopts} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"
        iopts="${iopts} -DCMAKE_C_FLAGS:STRING=\"${CFLAGS} ${C_OPT_FLAGS}\""
        iopts="${iopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXXFLAGS} ${CXX_OPT_FLAGS}\""
        iopts="${iopts} -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON"
        iopts="${iopts} -DCMAKE_INSTALL_PREFIX:PATH=$VISITDIR/icet/${ICET_VERSION}/${VISITARCH}"
        iopts="${iopts} -DCMAKE_C_FLAGS:STRING=\"-fPIC ${CFLAGS} ${C_OPT_FLAGS}\""
        iopts="${iopts} -DMPI_COMPILER:PATH=${PAR_COMPILER}"
        iopts="${iopts} -DBUILD_TESTING:BOOL=OFF"
    fi

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\"" ${iopts} . > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "IceT configuration failed."

    #
    # Now build IceT.
    #
    info "Building IceT . . . (~2 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "IceT did not build correctly.  Giving up."
        return 1
    fi

    info "Installing IceT . . ."

    ${CMAKE_COMMAND} --install .
    if [[ $? != 0 ]] ; then
        warn "IceT: 'make install' failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/icet"
        chgrp -R ${GROUP} "$VISITDIR/icet"
    fi

    cd "$START_DIR"
    echo "Done with IceT"
    return 0
}

function bv_icet_is_enabled
{
    if [[ $DO_ICET == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_icet_is_installed
{
    check_if_installed "icet" $ICET_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_icet_build
{
    cd "$START_DIR"
    if [[ "$DO_ICET" == "yes" && "$PREVENT_ICET" != "yes" ]] ; then
        check_if_installed "icet" $ICET_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping IceT build.  IceT is already installed."
        else
            info "Building IceT (~2 minutes)"
            build_icet
            if [[ $? != 0 ]] ; then
                error "Unable to build or install IceT.  Bailing out."
            fi
            info "Done building IceT"
        fi
    fi
}
function bv_llvm_initialize
{
    export DO_LLVM="yes"
}

function bv_llvm_enable
{
    DO_LLVM="yes"
}

function bv_llvm_disable
{
    DO_LLVM="no"
}

function bv_llvm_depends_on
{
    depends_on="cmake"
    if [[ $DO_PYTHON == "yes" ]] ; then
        depends_on="$depends_on python"
    fi

    echo ${depends_on}
}

function bv_llvm_info
{
    export BV_LLVM_VERSION=${BV_LLVM_VERSION:-"6.0.1"}
    export BV_LLVM_FILE=${BV_LLVM_FILE:-"llvm-${BV_LLVM_VERSION}.src.tar.xz"}
    export BV_LLVM_BUILD_DIR=${BV_LLVM_BUILD_DIR:-"llvm-${BV_LLVM_VERSION}.src"}
    export BV_LLVM_SHA256_CHECKSUM="b6d6c324f9c71494c0ccaf3dac1f16236d970002b42bb24a6c9e1634f7d0f4e2"

    export BV_CLANG_FILE="cfe-${BV_LLVM_VERSION}.src.tar.xz"
    export BV_CLANG_BUILD_DIR="cfe-${BV_LLVM_VERSION}.src"
    export BV_CLANG_SHA256_CHECKSUM="7c243f1485bddfdfedada3cd402ff4792ea82362ff91fbdac2dae67c6026b667"
}

function bv_llvm_print
{
    printf "%s%s\n" "BV_LLVM_FILE=" "${BV_LLVM_FILE}"
    printf "%s%s\n" "BV_LLVM_VERSION=" "${BV_LLVM_VERSION}"
    printf "%s%s\n" "LLVM_TARGET=" "${LLVM_TARGET}"
    printf "%s%s\n" "BV_LLVM_BUILD_DIR=" "${BV_LLVM_BUILD_DIR}"
}

function bv_llvm_print_usage
{
    printf "%-20s %s [%s]\n" "--llvm" "Build LLVM" "$DO_LLVM"
}

function bv_llvm_host_profile
{
    if [[ "$DO_LLVM" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## LLVM" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_LLVM_DIR \${VISITHOME}/llvm/$BV_LLVM_VERSION/\${VISITARCH})" >> $HOSTCONF
    fi
}

function bv_llvm_initialize_vars
{
    export VISIT_LLVM_DIR=${VISIT_LLVM_DIR:-"$VISITDIR/llvm/${BV_LLVM_VERSION}/${VISITARCH}"}
    LLVM_INCLUDE_DIR="${VISIT_LLVM_DIR}/include"
    LLVM_LIB_DIR="${VISIT_LLVM_DIR}/lib"
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        LLVM_LIB="${LLVM_LIB_DIR}/libLLVM.a"
    else
        LLVM_LIB="${LLVM_LIB_DIR}/libLLVM.${SO_EXT}"
    fi
    # needed for clang and pyside
    export LLVM_INSTALL_DIR="${VISIT_LLVM_DIR}"
}

function bv_llvm_selected
{
    args=$@
    if [[ $args == "--llvm" ]]; then
        DO_LLVM="yes"
        return 1
    fi

    return 0
}

function bv_llvm_ensure
{
    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        if [[ "$DO_LLVM" == "yes" ]] ; then
            if [[ "$DOWNLOAD_ONLY" == "yes" ]] ; then
                download_file ${BV_CLANG_FILE} ${BV_CLANG_URL}
            fi
            ensure_built_or_ready "llvm"   $BV_LLVM_VERSION   $BV_LLVM_BUILD_DIR   $BV_LLVM_FILE $BV_LLVM_URL
            if [[ $? != 0 ]] ; then
                return 1
            fi
        fi
    fi
}

function apply_llvm_patch
{
    info "Currently no patches for llvm"
}

function build_llvm
{
    #
    # prepare build dir
    #
    prepare_build_dir $BV_LLVM_BUILD_DIR $BV_LLVM_FILE
    untarred_llvm=$?
    if [[ $untarred_llvm == -1 ]] ; then
        warn "Unable to prepare LLVM build directory. Giving Up!"
        return 1
    fi

    # download clang
    if ! test -f ${BV_CLANG_FILE} ; then
        download_file ${BV_CLANG_FILE} ${BV_CLANG_URL}
        if [[ $? != 0 ]] ; then
            warn "Could not download ${BV_CLANG_FILE}"
            return 1
        fi
    fi

    # extract clang
    if ! test -d clang ; then
        info "Extracting clang ..."
        uncompress_untar ${BV_CLANG_FILE}
        if test $? -ne 0 ; then
            warn "Could not extract ${BV_CLANG_FILE}"
            return 1
        fi
        # llvm build system expects the directory to be named clang
        mv ${BV_CLANG_BUILD_DIR} clang
    fi

    #
    # Build LLVM.
    #

    #
    # LLVM must be built with an out of source build.
    #
    BV_LLVM_SRC_DIR=${BV_LLVM_BUILD_DIR}
    BV_LLVM_BUILD_DIR="${BV_LLVM_SRC_DIR}-build"
    if [[ ! -d ${BV_LLVM_BUILD_DIR} ]] ; then
        info "Making build directory ${BV_LLVM_BUILD_DIR}"
        mkdir ${BV_LLVM_BUILD_DIR}
    fi

    #
    # Patch LLVM
    #
    
    cd "$BV_LLVM_SRC_DIR" || error "Couldn't cd to llvm src dir."
    apply_llvm_patch
    if [[ $? != 0 ]] ; then
	if [[ $untarred_llvm == 1 ]] ; then
	    warn "Giving up on LLVM build because the patch failed."
	    return 1
	else
	    warn "Patch failed, but continuing.  I believe that this script\n" \
		 "tried to apply a patch to an existing directory that had\n" \
		 "already been patched ... that is, the patch is\n" \
		 "failing harmlessly on a second application."
        fi
    fi

    cd "$START_DIR"
    cd ${BV_LLVM_BUILD_DIR} || error "Couldn't cd to llvm build dir."

    #
    # Remove any CMakeCache.txt files just to be safe.
    #
    rm -f CMakeCache.txt */CMakeCache.txt

    info "Configuring LLVM . . ."

    llvm_opts=""
    # standard cmake options
    llvm_opts="${llvm_opts} -DCMAKE_INSTALL_PREFIX:PATH=${VISIT_LLVM_DIR}"
    llvm_opts="${llvm_opts} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"
    llvm_opts="${llvm_opts} -DCMAKE_BUILD_WITH_INSTALL_RPATH:BOOL=ON"
    llvm_opts="${llvm_opts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    llvm_opts="${llvm_opts} -DCMAKE_CXX_FLAGS:STRING=\"${CXXFLAGS} ${CXX_OPT_FLAGS}\""
    llvm_opts="${llvm_opts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    llvm_opts="${llvm_opts} -DCMAKE_C_FLAGS:STRING=\"${CFLAGS} ${C_OPT_FLAGS}\""

    # python?
    if [[ $DO_PYTHON == "yes" ]] ; then
        llvm_opts="${llvm_opts} -DPYTHON_EXECUTABLE:FILEPATH=$PYTHON_COMMAND"
    fi

    #
    # Determine the LLVM_TARGET_TO_BUILD.
    #
    if [[ "$(uname -m)" == "ppc64" || "$(uname -m)" == "ppc64le" ]]; then
        llvm_opts="${llvm_opts} -DLLVM_TARGETS_TO_BUILD:STRING=PowerPC"
    else
        llvm_opts="${llvm_opts} -DLLVM_TARGETS_TO_BUILD:STRING=X86"
    fi

    llvm_opts="${llvm_opts} -DLLVM_ENABLE_RTTI:BOOL=ON"
    llvm_opts="${llvm_opts} -DLLVM_BUILD_LLVM_DYLIB:BOOL=ON"

    # turn off things we don't need?
    llvm_opts="${llvm_opts} -DLLVM_INCLUDE_DOCS:BOOL=OFF"
    llvm_opts="${llvm_opts} -DLLVM_INCLUDE_EXAMPLES:BOOL=OFF"
    llvm_opts="${llvm_opts} -DLLVM_INCLUDE_GO_TESTS:BOOL=OFF"
    llvm_opts="${llvm_opts} -DLLVM_INCLUDE_TESTS:BOOL=OFF"
    llvm_opts="${llvm_opts} -DLLVM_INCLUDE_UTILS:BOOL=OFF"


    # options for building libclang
    llvm_opts="${llvm_opts} -DLLVM_ENABLE_PROJECTS:STRING=clang"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_LIBCLANG_BUILD:BOOL=ON"
    # turning off unnecessary tools
    llvm_opts="${llvm_opts} -DCLANG_BUILD_TOOLS:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_ENABLE_ARCMT:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_ENABLE_STATIC_ANALYZER:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_INSTALL_SCANBUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_INSTALL_SCANVIEW:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_PLUGIN_SUPPORT:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_ARCMT_TEST_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_CHECK_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_DIFF_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_FORMAT_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_FUNC_MAPPING_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_FUZZER_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_REFACTOR_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_CLANG_RENAME_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_C_ARCMT_TEST_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_C_INDEX_TEST_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_DIAGTOOL_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_DRIVER_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_HANDLE_CXX_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_SCAN_BUILD_BUILD:BOOL=OFF"
    llvm_opts="${llvm_opts} -DCLANG_TOOL_SCAN_VIEW_BUILD:BOOL=OFF"

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_COMMAND}\"" ${llvm_opts} ../${BV_LLVM_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "LLVM configuration failed"

    info "Building LLVM . . ."
    ${MAKE} ${MAKE_OPT_FLAGS}
    if [[ $? != 0 ]] ; then
        warn "LLVM build failed.  Giving up"
        return 1
    fi

    info "Installing LLVM . . ."
    ${MAKE} ${MAKE_OPT_FLAGS} install
    if [[ $? != 0 ]] ; then
        warn "LLVM install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/llvm"
        chgrp -R ${GROUP} "$VISITDIR/llvm"
    fi
    cd "$START_DIR"
    info "Done with LLVM"
    return 0
}

function bv_llvm_is_enabled
{
    if [[ $DO_LLVM == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_llvm_is_installed
{
    check_if_installed "llvm" $BV_LLVM_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_llvm_build
{
    #
    # Build LLVM
    #
    cd "$START_DIR"
    if [[ "$DO_LLVM" == "yes" ]] ; then
        check_if_installed "llvm" $BV_LLVM_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping LLVM build.  LLVM is already installed."
        else
            info "Building LLVM (~60 minutes)"
            build_llvm
            if [[ $? != 0 ]] ; then
                error "Unable to build or install LLVM.  Bailing out."
            fi
            info "Done building LLVM"
        fi
    fi
}
function bv_mesagl_initialize
{
    export DO_MESAGL="no"
}

function bv_mesagl_enable
{
    DO_MESAGL="yes"
    bv_glu_enable
    bv_llvm_enable
}

function bv_mesagl_disable
{
    DO_MESAGL="no"
}

function bv_mesagl_depends_on
{
    echo "llvm"
}

function bv_mesagl_info
{
    export MESAGL_VERSION=${MESAGL_VERSION:-"17.3.9"}
    export MESAGL_FILE=${MESAGL_FILE:-"mesa-$MESAGL_VERSION.tar.xz"}
    export MESAGL_BUILD_DIR=${MESAGL_BUILD_DIR:-"mesa-$MESAGL_VERSION"}
    export MESAGL_SHA256_CHECKSUM="c5beb5fc05f0e0c294fefe1a393ee118cb67e27a4dca417d77c297f7d4b6e479"
}

function bv_mesagl_print
{
    printf "%s%s\n" "MESAGL_FILE=" "${MESAGL_FILE}"
    printf "%s%s\n" "MESAGL_VERSION=" "${MESAGL_VERSION}"
    printf "%s%s\n" "MESAGL_BUILD_DIR=" "${MESAGL_BUILD_DIR}"
}

function bv_mesagl_print_usage
{
    printf "%-20s %s [%s]\n" "--mesagl" "Build MesaGL" "$DO_MESAGL"
}

function bv_mesagl_host_profile
{
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## MesaGL" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_MESAGL_DIR \${VISITHOME}/mesagl/$MESAGL_VERSION/\${VISITARCH})" >> $HOSTCONF
    fi
}

function bv_mesagl_selected
{
    args=$@
    if [[ $args == "--mesagl" ]]; then
        DO_MESAGL="yes"
        return 1
    fi

    return 0
}

function bv_mesagl_initialize_vars
{
    info "initalizing mesagl vars"
    if [[ "$DO_MESAGL" == "yes" ]]; then
        MESAGL_INSTALL_DIR="${VISITDIR}/mesagl/${MESAGL_VERSION}/${VISITARCH}"
        MESAGL_INCLUDE_DIR="${MESAGL_INSTALL_DIR}/include"
        MESAGL_LIB_DIR="${MESAGL_INSTALL_DIR}/lib"
        if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
            MESAGL_OPENGL_LIB="${MESAGL_LIB_DIR}/libGL.a"
            MESAGL_OSMESA_LIB="${MESAGL_LIB_DIR}/libOSMesa.a"
            # initialized here, because glu's initialize_vars is called first
            # and install location won't be set properly for use with VTK
            MESAGL_GLU_LIB="${MESAGL_LIB_DIR}/libGLU.a"
        else
            MESAGL_OPENGL_LIB="${MESAGL_LIB_DIR}/libGL.${SO_EXT}"
            MESAGL_OSMESA_LIB="${MESAGL_LIB_DIR}/libOSMesa.${SO_EXT}"
            # initialized here, because glu's initialize_vars is called first
            # and install location won't be set properly for use with VTK
            MESAGL_GLU_LIB="${MESAGL_LIB_DIR}/libGLU.${SO_EXT}"
        fi
    fi
}

function bv_mesagl_ensure
{
    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        if [[ "$DO_MESAGL" == "yes" ]] ; then
            ensure_built_or_ready "mesagl"   $MESAGL_VERSION   $MESAGL_BUILD_DIR   $MESAGL_FILE $MESAGL_URL
            if [[ $? != 0 ]] ; then
                return 1
            fi
        fi
    fi
}

function apply_mesagl_patch
{
    patch -p0 << \EOF
diff -c configure.ac.orig configure.ac
*** configure.ac.orig   Mon Jul 13 09:47:20 2020
--- configure.ac        Mon Jul 13 09:50:37 2020
***************
*** 2653,2659 ****
      dnl ourselves.
      dnl (See https://llvm.org/bugs/show_bug.cgi?id=6823)
      dnl We can't use $LLVM_VERSION because it has 'svn' stripped out,
!     LLVM_SO_NAME=LLVM-`$LLVM_CONFIG --version`
      AS_IF([test -f "$LLVM_LIBDIR/lib$LLVM_SO_NAME.$IMP_LIB_EXT"], [llvm_have_one_so=yes])

      if test "x$llvm_have_one_so" = xyes; then
--- 2653,2659 ----
      dnl ourselves.
      dnl (See https://llvm.org/bugs/show_bug.cgi?id=6823)
      dnl We can't use $LLVM_VERSION because it has 'svn' stripped out,
!     LLVM_SO_NAME=LLVM-$LLVM_VERSION
      AS_IF([test -f "$LLVM_LIBDIR/lib$LLVM_SO_NAME.$IMP_LIB_EXT"], [llvm_have_one_so=yes])

      if test "x$llvm_have_one_so" = xyes; then
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 1 failed."
        return 1
    fi

    #
    # Patch so that displaying graphics to the XWin-32 2018 X server
    # works properly.
    #
    patch -p0 << \EOF
diff -c src/gallium/winsys/sw/xlib/xlib_sw_winsys.c.orig src/gallium/winsys/sw/xlib/xlib_sw_winsys.c
*** src/gallium/winsys/sw/xlib/xlib_sw_winsys.c.orig	Thu Mar  4 13:12:20 2021
--- src/gallium/winsys/sw/xlib/xlib_sw_winsys.c	Thu Mar  4 13:14:11 2021
***************
*** 396,401 ****
--- 396,402 ----
  {
     struct xlib_displaytarget *xlib_dt;
     unsigned nblocksy, size;
+    int ignore;
  
     xlib_dt = CALLOC_STRUCT(xlib_displaytarget);
     if (!xlib_dt)
***************
*** 410,416 ****
     xlib_dt->stride = align(util_format_get_stride(format, width), alignment);
     size = xlib_dt->stride * nblocksy;
  
!    if (!debug_get_option_xlib_no_shm()) {
        xlib_dt->data = alloc_shm(xlib_dt, size);
        if (xlib_dt->data) {
           xlib_dt->shm = True;
--- 411,418 ----
     xlib_dt->stride = align(util_format_get_stride(format, width), alignment);
     size = xlib_dt->stride * nblocksy;
  
!    if (!debug_get_option_xlib_no_shm() &&
!        XQueryExtension(xlib_dt->display, "MIT-SHM", &ignore, &ignore, &ignore)) {
        xlib_dt->data = alloc_shm(xlib_dt, size);
        if (xlib_dt->data) {
           xlib_dt->shm = True;
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 2 failed."
        return 1
    fi

    #
    # Patch so that building with gcc-10 will work.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/swr/rasterizer/common/os.h.orig src/gallium/drivers/swr/rasterizer/common/os.h
--- src/gallium/drivers/swr/rasterizer/common/os.h.orig 2021-06-28 08:51:12.252643000 -0700
+++ src/gallium/drivers/swr/rasterizer/common/os.h      2021-06-28 08:55:32.676722000 -0700
@@ -166,14 +166,15 @@
 #endif
 
 #if !defined( __clang__) && !defined(__INTEL_COMPILER)
-// Intrinsic not defined in gcc
+// Intrinsic not defined in gcc < 10
+#if (__GNUC__) && (GCC_VERSION < 100000)
 static INLINE
 void _mm256_storeu2_m128i(__m128i *hi, __m128i *lo, __m256i a)
 {
     _mm_storeu_si128((__m128i*)lo, _mm256_castsi256_si128(a));
     _mm_storeu_si128((__m128i*)hi, _mm256_extractf128_si256(a, 0x1));
 }
-
+#endif
 // gcc prior to 4.9 doesn't have _mm*_undefined_*
 #if (__GNUC__) && (GCC_VERSION < 409000)
 #define _mm_undefined_si128 _mm_setzero_si128
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 3 failed."
        return 1
    fi

    #
    # Patch to increase the maximum image size in the llvmpipe
    # driver to 32K x 32K. There are 2 changes. The first is to
    # the number of 2D levels to 16 (2^(16-1)) = 32K. The second is
    # to the maximum texture size - 32768 x 32768 is the maximum
    # number of pixels, the 4 is 4 bytes per pixel, and the 2 is from
    # the fact that a texture can actually store a multi-resolution
    # representation of the image. For example if the image size
    # is 256x256, it has storage for textures of size 256x256,
    # 128x128, 64x64, 32x32, 16x16, 8x8, 4x4, 2x2 and 1x1.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/llvmpipe/lp_limits.h.orig src/gallium/drivers/llvmpipe/lp_limits.h
--- src/gallium/drivers/llvmpipe/lp_limits.h.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/gallium/drivers/llvmpipe/lp_limits.h	2024-11-13 13:47:04.388202316 -0800
@@ -43,8 +43,8 @@
 /**
  * Max texture sizes
  */
-#define LP_MAX_TEXTURE_SIZE (1 * 1024 * 1024 * 1024ULL)  /* 1GB for now */
-#define LP_MAX_TEXTURE_2D_LEVELS 14  /* 8K x 8K for now */
+#define LP_MAX_TEXTURE_SIZE (2 * 4 * 32768 * 32768ULL)  /* 8GB for now */
+#define LP_MAX_TEXTURE_2D_LEVELS 16  /* 32K x 32K for now */
 #define LP_MAX_TEXTURE_3D_LEVELS 12  /* 2K x 2K x 2K for now */
 #define LP_MAX_TEXTURE_CUBE_LEVELS 14  /* 8K x 8K for now */
 #define LP_MAX_TEXTURE_ARRAY_LAYERS 512 /* 8K x 512 / 8K x 8K x 512 */
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 4 failed."
        return 1
    fi

    #
    # Patch to increase the maximum scene temporary storage in the llvmpipe
    # driver. This is required for large image sizes.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/llvmpipe/lp_scene.h.orig src/gallium/drivers/llvmpipe/lp_scene.h
--- src/gallium/drivers/llvmpipe/lp_scene.h.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/gallium/drivers/llvmpipe/lp_scene.h	2024-11-13 13:57:33.700075750 -0800
@@ -60,12 +60,12 @@

 /* Scene temporary storage is clamped to this size:
  */
-#define LP_SCENE_MAX_SIZE (9*1024*1024)
+#define LP_SCENE_MAX_SIZE (256*1024*1024)

 /* The maximum amount of texture storage referenced by a scene is
  * clamped to this size:
  */
-#define LP_SCENE_MAX_RESOURCE_SIZE (64*1024*1024)
+#define LP_SCENE_MAX_RESOURCE_SIZE (256*1024*1024)


 /* switch to a non-pointer value for this:
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 5 failed."
        return 1
    fi

    #
    # Patch to increase the maximum image size in mesa to 32K x 32K.
    #
    patch -p0 << \EOF
diff -u src/mesa/main/config.h.orig src/mesa/main/config.h
--- src/mesa/main/config.h.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/mesa/main/config.h	2024-11-13 14:00:35.358860569 -0800
@@ -91,19 +91,19 @@
 #define LINE_WIDTH_GRANULARITY 0.1

 /** Max memory to allow for a single texture image (in megabytes) */
-#define MAX_TEXTURE_MBYTES 1024
+#define MAX_TEXTURE_MBYTES 8196

 /** Number of 1D/2D texture mipmap levels */
-#define MAX_TEXTURE_LEVELS 15
+#define MAX_TEXTURE_LEVELS 16

 /** Number of 3D texture mipmap levels */
-#define MAX_3D_TEXTURE_LEVELS 15
+#define MAX_3D_TEXTURE_LEVELS 16

 /** Number of cube texture mipmap levels - GL_ARB_texture_cube_map */
-#define MAX_CUBE_TEXTURE_LEVELS 15
+#define MAX_CUBE_TEXTURE_LEVELS 16

 /** Maximum rectangular texture size - GL_NV_texture_rectangle */
-#define MAX_TEXTURE_RECT_SIZE 16384
+#define MAX_TEXTURE_RECT_SIZE 32768

 /**
  * Maximum number of layers in a 1D or 2D array texture - GL_MESA_texture_array
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 6 failed."
        return 1
    fi

    #
    # Patch to fix an arithmetic overflow error calculating the size
    # of a texture.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/llvmpipe/lp_texture.c.orig src/gallium/drivers/llvmpipe/lp_texture.c
--- src/gallium/drivers/llvmpipe/lp_texture.c.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/gallium/drivers/llvmpipe/lp_texture.c	2024-11-13 14:17:18.979693408 -0800
@@ -155,7 +155,7 @@

       lpr->mip_offsets[level] = total_size;

-      total_size += align((unsigned)mipsize, mip_align);
+      total_size += align64(mipsize, mip_align);
       if (total_size > LP_MAX_TEXTURE_SIZE) {
          goto fail;
       }
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 7 failed."
        return 1
    fi

    # Patch to address VTK texture buffer error.
    # Taken from https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/9750
    #
    patch -p0 << \EOF
diff -c src/gallium/drivers/llvmpipe/lp_screen.c.orig src/gallium/drivers/llvmpipe/lp_screen.c
*** src/gallium/drivers/llvmpipe/lp_screen.c.orig        Fri Dec 15 14:33:53 PST 2023
--- src/gallium/drivers/llvmpipe/lp_screen.c     Fri Dec 15 14:33:53 PST 2023
***************
*** 236,242 ****
     case PIPE_CAP_TEXTURE_BUFFER_OBJECTS:
        return 1;
     case PIPE_CAP_MAX_TEXTURE_BUFFER_SIZE:
!       return 65536;
     case PIPE_CAP_TEXTURE_BUFFER_OFFSET_ALIGNMENT:
        return 1;
     case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
--- 236,242 ----
     case PIPE_CAP_TEXTURE_BUFFER_OBJECTS:
        return 1;
     case PIPE_CAP_MAX_TEXTURE_BUFFER_SIZE:
!       return 134217728;
     case PIPE_CAP_TEXTURE_BUFFER_OFFSET_ALIGNMENT:
        return 1;
     case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
EOF
    if [[ $? != 0 ]] ; then
        warn "MesaGL patch 8 failed."
        return 1
    fi

    return 0;
}

function build_mesagl
{
    #
    # prepare build dir
    #
    prepare_build_dir $MESAGL_BUILD_DIR $MESAGL_FILE
    untarred_mesagl=$?
    if [[ $untarred_mesagl == -1 ]] ; then
        warn "Unable to prepare MesaGL build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    cd $MESAGL_BUILD_DIR || error "Couldn't cd to mesagl build dir."

    info "Patching MesaGL"
    apply_mesagl_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_mesagl == 1 ]] ; then
            warn "Giving up on MesaGL build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Handle case where python doesn't exist.
    # The magic to determine if python exist comes from
    # https://stackoverflow.com/questions/592620/how-can-i-check-if-a-program-exists-from-a-bash-script
    #
    if ! command -v python > /dev/null 2>&1 ; then
        sed -i "s/python2.7/python3 python2.7/" configure.ac
    fi

    #
    # Build MESAGL.
    #
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        MESAGL_STATIC_DYNAMIC="--disable-shared --disable-shared-glapi --enable-static --enable-static-glapi"
    fi
    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        MESAGL_DEBUG_BUILD="--enable-debug"
    fi
    if [[ "$(uname -m)" == "x86_64" ]] ; then
        MESAGL_GALLIUM_DRIVERS="swrast,swr"
    else
        MESAGL_GALLIUM_DRIVERS="swrast"
    fi

    info "Configuring MesaGL . . ."

    # add -fcommon if gcc >=10 to work around changes in compiler behavior
    # see: https://wiki.gentoo.org/wiki/Project:Toolchain/Gcc_10_porting_notes/fno_common
    # otherwise we would need to patch mesa to fix build problems

    mesa_c_opt_flags=""
    if [[ "$CXX_COMPILER" == "g++" ]] ; then
        VERSION=$(g++ -v 2>&1 | grep "gcc version" | cut -d' ' -f3 | cut -d'.' -f1-1)
        if [[ ${VERSION} -ge 10 ]] ; then
            mesa_c_opt_flags="-fcommon"
        fi
    fi

    set -x
    env CXXFLAGS="${CXXFLAGS} ${CXX_OPT_FLAGS}" \
        CXX=${CXX_COMPILER} \
        CFLAGS="${CFLAGS} ${C_OPT_FLAGS} ${mesa_c_opt_flags}" \
        CC=${C_COMPILER} \
        ./autogen.sh \
        --prefix=${VISITDIR}/mesagl/${MESAGL_VERSION}/${VISITARCH} \
        --with-platforms=x11 \
        --disable-dri \
        --disable-dri3 \
        --disable-egl \
        --disable-gbm \
        --disable-gles1 \
        --disable-gles2 \
        --disable-xvmc \
        --disable-vdpau \
        --disable-va \
        --enable-glx \
        --enable-llvm \
        --with-gallium-drivers=${MESAGL_GALLIUM_DRIVERS} \
        --enable-gallium-osmesa $MESAGL_STATIC_DYNAMIC $MESAGL_DEBUG_BUILD \
        --disable-llvm-shared-libs \
        --with-llvm-prefix=${VISIT_LLVM_DIR}
    set +x

    if [[ $? != 0 ]] ; then
        warn "MesaGL configure failed.  Giving up"
        return 1
    fi

    info "Building MesaGL . . ."
    ${MAKE} ${MAKE_OPT_FLAGS}
    if [[ $? != 0 ]] ; then
        warn "MesaGL build failed.  Giving up"
        return 1
    fi

    info "Installing MesaGL ..."
    ${MAKE} ${MAKE_OPT_FLAGS} install
    if [[ $? != 0 ]] ; then
        warn "MesaGL install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/mesagl"
        chgrp -R ${GROUP} "$VISITDIR/mesagl"
    fi
    cd "$START_DIR"
    info "Done with MesaGL"
    return 0
}

function bv_mesagl_is_enabled
{
    if [[ $DO_MESAGL == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_mesagl_is_installed
{
    check_if_installed "mesagl" $MESAGL_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_mesagl_build
{
    #
    # Build MesaGL
    #
    cd "$START_DIR"
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        check_if_installed "mesagl" $MESAGL_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping MesaGL build.  MesaGL is already installed."
        else
            info "Building MesaGL (~20 minutes)"
            build_mesagl
            if [[ $? != 0 ]] ; then
                error "Unable to build or install MesaGL.  Bailing out."
            fi
            info "Done building MesaGL"
        fi
    fi
}
function bv_meson_initialize
{
    export DO_MESON="no"
    export USE_SYSTEM_MESON="no"
    add_extra_commandline_args "meson" "alt-meson-dir" 1 "Use alternative directory for meson"
}

function bv_meson_enable
{
    DO_MESON="yes"
}

function bv_meson_disable
{
    DO_MESON="no"
}

function bv_meson_alt_meson_dir
{
    bv_meson_enable
    USE_SYSTEM_MESON="yes"
    MESON_INSTALL_DIR="$1"
    info "Using Alternate meson: $MESON_INSTALL_DIR"
}

function bv_meson_depends_on
{
    local depends_on="ninja python"

    echo ${depends_on}
}

function bv_meson_initialize_vars
{
    if [[ "$USE_SYSTEM_MESON" == "no" ]]; then
        MESON_INSTALL_DIR="${VISITDIR}/meson/${MESON_VERSION}/${VISITARCH}"
    fi
}

function bv_meson_info
{
    export MESON_VERSION=${MESON_VERSION:-"1.6.1"}
    export MESON_FILE=${MESON_FILE:-"meson-${MESON_VERSION}.tar.gz"}
    export MESON_BUILD_DIR=${MESON_BUILD_DIR:-"meson-${MESON_VERSION}"}
    export MESON_SHA256_CHECKSUM="1eca49eb6c26d58bbee67fd3337d8ef557c0804e30a6d16bfdf269db997464de"
}

function bv_meson_print
{
    printf "%s%s\n" "MESON_FILE=" "${MESON_FILE}"
    printf "%s%s\n" "MESON_VERSION=" "${MESON_VERSION}"
    printf "%s%s\n" "MESON_BUILD_DIR=" "${MESON_BUILD_DIR}"
}

function bv_meson_print_usage
{
    printf "%-20s %s [%s]\n" "--meson" "Build meson support" "$DO_MESON"
    printf "%-20s %s [%s]\n" "--alt-meson-dir" "Use meson from an alternative directory"
}

function bv_meson_host_profile
{
    # Nothing added to the host profile since meson is only used for
    # building third party libraries.
    return 0
}

function bv_meson_ensure
{
    if [[ "$DO_MESON" == "yes" && "$USE_SYSTEM_MESON" == "no" ]] ; then
        ensure_built_or_ready "meson" $MESON_VERSION $MESON_BUILD_DIR $MESON_FILE $MESON_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_MESON="no"
            error "Unable to build meson. ${MESON_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_meson
#
#
# *************************************************************************** #
function build_meson
{
    #
    # Build meson
    #
    info "Installing Meson . . . (~2 minutes)"

    # Install the python meson package.
    check_if_py_module_installed "meson"
    if [[ $? != 0 ]] ; then
        download_py_module ${MESON_FILE} ${MESON_URL}
        if [[ $? != 0 ]] ; then
            return 1
        fi

        extract_py_module ${MESON_BUILD_DIR} ${MESON_FILE} "meson"
        if [[ $? != 0 ]] ; then
            return 1
        fi

        install_py_module ${MESON_BUILD_DIR} "meson"
        if [[ $? != 0 ]] ; then
            return 1
        fi

        fix_py_permissions
    fi

    # Create a python script that loads the meson package.
    if [[ ! -d ${MESON_INSTALL_DIR}/bin ]] ; then
        mkdir -p ${MESON_INSTALL_DIR}/bin
    fi
    MESON_CMD="${MESON_INSTALL_DIR}/bin/meson"
    if [[ -f $MESON_CMD ]] ; then
        rm $MESON_CMD
    fi
    echo "#!${PYTHON_COMMAND}" > $MESON_CMD
    echo "# -*- coding: utf-8 -*-" >> $MESON_CMD
    echo "import re" >> $MESON_CMD
    echo "import sys" >> $MESON_CMD
    echo "from mesonbuild.mesonmain import main" >> $MESON_CMD
    echo "if __name__ == '__main__':" >> $MESON_CMD
    echo "    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])" >> $MESON_CMD
    echo "    sys.exit(main())" >> $MESON_CMD

    chmod 700 $MESON_CMD

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/meson"
        chgrp -R ${GROUP} "$VISITDIR/meson"
    fi
    cd "$START_DIR"
    info "Done with meson"
    return 0
}

function bv_meson_is_enabled
{
    if [[ $DO_MESON == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_meson_is_installed
{
    if [[ "$USE_SYSTEM_MESON" == "yes" ]]; then
        return 1
    fi

    check_if_installed "meson" $MESON_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_meson_build
{
    cd "$START_DIR"
    if [[ "$DO_MESON" == "yes" && "$USE_SYSTEM_MESON" == "no" ]] ; then
        check_if_installed "meson" $MESON_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping meson build. Meson is already installed."
        else
            info "Building meson (~2 minutes)"
            build_meson
            if [[ $? != 0 ]] ; then
                error "Unable to build or install meson.  Bailing out."
            fi
            info "Done building meson"
        fi
    fi
}
function bv_mfem_initialize
{
    export DO_MFEM="no"
}

function bv_mfem_enable
{
    DO_MFEM="yes"
}

function bv_mfem_disable
{
    DO_MFEM="no"
}

function bv_mfem_depends_on
{
    local depends_on="zlib"

    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        depends_on="$depends_on conduit"
    fi
    if [[ "$DO_FMS" == "yes" ]] ; then
        depends_on="$depends_on fms"
    fi
    if [[ "$DO_HDF5" == "yes" ]] ; then
        depends_on="$depends_on hdf5"
    fi

    echo $depends_on
}

function bv_mfem_info
{
    export MFEM_VERSION=${MFEM_VERSION:-"4.8"}
    export MFEM_FILE=${MFEM_FILE:-"mfem-${MFEM_VERSION}.tar.gz"}
    export MFEM_BUILD_DIR=${MFEM_BUILD_DIR:-"mfem-${MFEM_VERSION}"}
    export MFEM_SHA256_CHECKSUM="65472f732d273832c64b2c39460649dd862df674222c71bfa82cf2da76705052"
}

function bv_mfem_print
{
    printf "%s%s\n" "MFEM_FILE=" "${MFEM_FILE}"
    printf "%s%s\n" "MFEM_VERSION=" "${MFEM_VERSION}"
    printf "%s%s\n" "MFEM_BUILD_DIR=" "${MFEM_BUILD_DIR}"
}

function bv_mfem_print_usage
{
    printf "%-20s %s [%s]\n" "--mfem" "Build mfem support" "$DO_MFEM"
}

function bv_mfem_host_profile
{
    if [[ "$DO_MFEM" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## MFEM" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_MFEM_DIR \${VISITHOME}/mfem/$MFEM_VERSION/\${VISITARCH})" \
            >> $HOSTCONF

        ZLIB_LIBDEP="\${VISITHOME}/zlib/\${ZLIB_VERSION}/\${VISITARCH}/lib z"

        CONDUIT_LIBDEP=""
        INCDEP=""
        if [[ "$DO_CONDUIT" == "yes" ]] ; then
            CONDUIT_LIBDEP="\${VISIT_CONDUIT_LIBDEP}"
            INCDEP="CONDUIT_INCLUDE_DIR"
        fi
        if [[ "$DO_FMS" == "yes" ]] ; then
            INCDEP="$INCDEP FMS_INCLUDE_DIR"
        fi

        if [[ "$INCDEP" != "" ]] ; then
             echo \
                "VISIT_OPTION_DEFAULT(VISIT_MFEM_INCDEP $INCDEP TYPE STRING)" \
                    >> $HOSTCONF
        fi
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_MFEM_LIBDEP $CONDUIT_LIBDEP $ZLIB_LIBDEP TYPE STRING)" \
                >> $HOSTCONF
    fi
}

function bv_mfem_ensure
{
    if [[ "$DO_MFEM" == "yes" ]] ; then
        ensure_built_or_ready "mfem" $MFEM_VERSION $MFEM_BUILD_DIR $MFEM_FILE $MFEM_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_MFEM="no"
            error "Unable to build mfem.  ${MFEM_FILE} not found."
        fi
    fi
}

function apply_mfem_patch
{
    # On IBM PPC systems the system defines "__VSX__" but some of the
    # VSX functions are not defined with gcc, which VisIt typically
    # uses. To avoid this we disable all the VSX coding. This is ok
    # since VSX just optimizes performance, so no functionality is lost.
    patch -p0 << \EOF
diff -c ./linalg/simd/vsx128.hpp.orig ./linalg/simd/vsx128.hpp
*** ./linalg/simd/vsx128.hpp.orig	Tue Mar  9 06:55:45 2021
--- ./linalg/simd/vsx128.hpp	Tue Mar  9 06:57:37 2021
***************
*** 12,18 ****
  #ifndef MFEM_SIMD_VSX128_HPP
  #define MFEM_SIMD_VSX128_HPP
  
! #ifdef __VSX__
  
  #include "../../config/tconfig.hpp"
  #include <altivec.h>
--- 12,18 ----
  #ifndef MFEM_SIMD_VSX128_HPP
  #define MFEM_SIMD_VSX128_HPP
  
! #ifdef __VSX_NOMATCH__
  
  #include "../../config/tconfig.hpp"
  #include <altivec.h>
EOF
    if [[ $? != 0 ]] ; then
        warn "MFEM patch failed."
        return 1
    fi

    return 0;
}

function apply_mfem_patches
{
    apply_mfem_patch
    if [[ $? != 0 ]] ; then
        warn "MFEM patch failed."
        return 1
    fi

    return 0
}

# *************************************************************************** #
#                            Function 8, build_mfem
# *************************************************************************** #
function build_mfem
{
    #
    # Prepare build dir
    #
    prepare_build_dir $MFEM_BUILD_DIR $MFEM_FILE
    untarred_mfem=$?
    if [[ $untarred_mfem == -1 ]] ; then
        warn "Unable to prepare mfem build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches.
    #
    cd $MFEM_BUILD_DIR || error "Can't cd to mfem build dir."

    info "Patching MFEM"
    apply_mfem_patches
    if [[ $? != 0 ]] ; then
        if [[ $untarred_mfem == 1 ]] ; then
            warn "Giving up on MFEM build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Build MFEM.
    #
    mkdir build
    cd build || error "Can't cd to MFEM build dir."

    vopts="-DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    vopts="${vopts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS} $CFLAGS\""
    vopts="${vopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    vopts="${vopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS} $CXXFLAGS\""
    vopts="${vopts} -DMFEM_ENABLE_MINIAPPS:BOOL=OFF"
    # MFEM 4.6 is hard coded to use C++11
    #  In the future, we want to change this to C++14
    vopts="${vopts} -DCMAKE_CXX_STANDARD=11"
    vopts="${vopts} -DCMAKE_CXX_STANDARD_REQUIRED:BOOL=ON"
    vopts="${vopts} -DCMAKE_INSTALL_PREFIX:PATH=${VISITDIR}/mfem/${MFEM_VERSION}/${VISITARCH}"
    if test "x${DO_STATIC_BUILD}" = "xyes" ; then
        vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
        vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi
    vopts="${vopts} -DMFEM_USE_EXCEPTIONS:BOOL=ON"

    if [[ "$DO_ZLIB" == "yes" ]] ; then
        vopts="${vopts} -DMFEM_USE_ZLIB=ON"
        vopts="${vopts} -DCMAKE_PREFIX_PATH:PATH=${VISITDIR}/zlib/${ZLIB_VERSION}/${VISITARCH}"
    else
        vopts="${vopts} -DMFEM_USE_ZLIB=OFF"
    fi

    if [[ "$DO_CONDUIT" == "yes" ]] ; then
        vopts="${vopts} -DMFEM_USE_CONDUIT=ON -DCONDUIT_DIR=${VISITDIR}/conduit/${CONDUIT_VERSION}/${VISITARCH}"
    fi

    # when using conduit, mfem's cmake logic requires HDF5_DIR to find HDF5
    # (NOTE: mfem could use CONDUIT_HDF5_DIR)
    if [[ "$DO_HDF5" == "yes" ]] ; then
        vopts="${vopts} -DHDF5_DIR=${VISITDIR}/hdf5/${HDF5_VERSION}/${VISITARCH}"
    fi

    if [[ "$DO_FMS" == "yes" ]] ; then
        vopts="${vopts} -DMFEM_USE_FMS=ON -DFMS_DIR=${VISITDIR}/fms/${FMS_VERSION}/${VISITARCH}"
    else
        vopts="${vopts} -DMFEM_USE_FMS=OFF"
    fi
    #
    # Call configure
    #
    info "Configuring mfem . . ."
    CMAKE_BIN="${CMAKE_INSTALL}/cmake"
    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    CMS=bv_run_cmake.sh
    echo "#!/bin/bash" > $CMS
    echo "\"${CMAKE_BIN}\" ${vopts} .." >> $CMS
    cat $CMS
    issue_command bash $CMS || error "MFEM configuration failed."

    #
    # Build mfem
    #
    info "Building mfem . . . (~2 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "mfem build failed.  Giving up"
        return 1
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing mfem"
    ${CMAKE_COMMAND} --install .

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/mfem"
        chgrp -R ${GROUP} "$VISITDIR/mfem"
    fi
    cd "$START_DIR"
    info "Done with mfem"
    return 0
}


function bv_mfem_is_enabled
{
    if [[ $DO_MFEM == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_mfem_is_installed
{
    check_if_installed "mfem" $MFEM_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_mfem_build
{
    cd "$START_DIR"
    if [[ "$DO_MFEM" == "yes" ]] ; then
        check_if_installed "mfem" $MFEM_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping mfem build.  mfem is already installed."
        else
            info "Building mfem (~2 minutes)"
            build_mfem
            if [[ $? != 0 ]] ; then
                error "Unable to build or install mfem.  Bailing out."
            fi
            info "Done building mfem"
        fi
    fi
}
function bv_mili_initialize
{
    export DO_MILI="no"
}

function bv_mili_enable
{
    DO_MILI="yes"
}

function bv_mili_disable
{
    DO_MILI="no"
}

function bv_mili_depends_on
{
    echo ""
}

function bv_mili_info
{
    export MILI_FILE=${MILI_FILE:-"mili-23.02.tar.gz"}
    export MILI_VERSION=${MILI_VERSION:-"23.02"}
    export MILI_COMPATIBILITY_VERSION=${MILI_COMPATIBILITY_VERSION:-"23.02"}
    export MILI_BUILD_DIR=${MILI_BUILD_DIR:-"mili-${MILI_VERSION}"}
    export MILI_SHA256_CHECKSUM="4973680e377f400a9fac12740b77c2297a4fcbcea7d6a4317d72b08dcffd4def"
}

function bv_mili_print
{
    printf "%s%s\n" "MILI_FILE=" "${MILI_FILE}"
    printf "%s%s\n" "MILI_VERSION=" "${MILI_VERSION}"
    printf "%s%s\n" "MILI_COMPATIBILITY_VERSION=" "${MILI_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "MILI_BUILD_DIR=" "${MILI_BUILD_DIR}"
}

function bv_mili_print_usage
{
    printf "%-20s %s [%s]\n" "--mili" "Build Mili" "$DO_MILI"
}

function bv_mili_host_profile
{
    if [[ "$DO_MILI" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Mili" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_MILI_DIR \${VISITHOME}/mili/$MILI_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi
}

function bv_mili_ensure
{
    if [[ "$DO_MILI" == "yes" ]] ; then
        ensure_built_or_ready "mili" $MILI_VERSION $MILI_BUILD_DIR $MILI_FILE
        if [[ $? != 0 ]] ; then
            warn "Unable to build Mili.  ${MILI_FILE} not found."
            ANY_ERRORS="yes"
            DO_MILI="no"
        fi
    fi
}

# *************************************************************************** #
#                          Function 8.2, build_mili                           #
# *************************************************************************** #

function apply_mili_2302_darwin_patch1
{
    info "Applying Mili 23.02 darwin patch 1."
    patch -p0 << \EOF
*** mili-23.02/Makefile.Library.orig	2024-02-09 10:50:45.000000000 -0800
--- mili-23.02/Makefile.Library	2024-02-09 10:51:03.000000000 -0800
*************** install-chmod:
*** 407,416 ****
  	           echo "[$$dir] \t\t Mili version $(MILI_VERSION) is missing"; \
  	        fi; \
  	done
- 
- uninstall:
- 
- ifneq ($(OS_NAME),Linux)
- include $(OBJS:.o=.d)
- endif
- 
--- 407,409 ----
EOF
    if [[ $? != 0 ]] ; then
        warn "Unable to apply Darwin patch 1 to Mili 23.02"
        return 1
    fi

    return 0
}

function apply_mili_2302_darwin_patch2
{
    info "Applying Mili 23.02 darwin patch 2."
    patch -p0 << \EOF
*** mili-23.02/src/mesh_u.c.orig	2024-02-09 11:02:26.000000000 -0800
--- mili-23.02/src/mesh_u.c	2024-02-09 11:02:35.000000000 -0800
***************
*** 38,44 ****
  
  #include <string.h>
  #ifndef _MSC_VER
- #include <values.h>
  #include <sys/time.h>
  #endif
  #include <time.h>
--- 38,43 ----
EOF
    if [[ $? != 0 ]] ; then
        warn "Unable to apply Darwin patch 2 to Mili 23.02"
        return 1
    fi

    return 0
}

function apply_mili_2302_cflags_patch
{
    info "Applying Mili 23.02 CFLAGS patch."
    patch -p0 << \EOF
diff -u mili-23.02/configure.orig mili-23.02/configure
--- mili-23.02/configure.orig   2023-05-09 09:51:35.931686000 -0700
+++ mili-23.02/configure        2023-05-09 09:54:38.169814000 -0700
@@ -4361,24 +4361,28 @@

     case $CC in
       *icc)
-        CC_FLAGS_DEBUG="-g $WORD_SIZE "
-        CC_FLAGS_OPT="-O3 $WORD_SIZE "
-        CC_FLAGS_LD_DEBUG="-g $WORD_SIZE"
-        CC_FLAGS_LD_OPT="-O3 $WORD_SIZE"
+        CC_FLAGS_DEBUG="$CFLAGS -g $WORD_SIZE "
+        CC_FLAGS_OPT="$CFLAGS -O3 $WORD_SIZE "
+        CC_FLAGS_LD_DEBUG="$CFLAGS -g $WORD_SIZE"
+        CC_FLAGS_LD_OPT="$CFLAGS -O3 $WORD_SIZE"
         ;;
       *xlc)
-        CC_FLAGS_DEBUG="-g $WORD_SIZE "
-        CC_FLAGS_OPT="-O4 $WORD_SIZE "
-        CC_FLAGS_LD_DEBUG="-g $WORD_SIZE"
-        CC_FLAGS_LD_OPT="-O4"
+        CC_FLAGS_DEBUG="$CFLAGS -g $WORD_SIZE "
+        CC_FLAGS_OPT="$CFLAGS -O4 $WORD_SIZE "
+        CC_FLAGS_LD_DEBUG="$CFLAGS -g $WORD_SIZE"
+        CC_FLAGS_LD_OPT="$CFLAGS -O4"
         ;;
       *gcc)
-        CC_FLAGS_DEBUG="-g $WORD_SIZE "
-        CC_FLAGS_OPT="-O4 $WORD_SIZE "
-        CC_FLAGS_LD_DEBUG="-g $WORD_SIZE"
-        CC_FLAGS_LD_OPT="-O4 $WORD_SIZE"
-        ;;
-      *cc)
+        CC_FLAGS_DEBUG="$CFLAGS -g $WORD_SIZE "
+        CC_FLAGS_OPT="$CFLAGS -O4 $WORD_SIZE "
+        CC_FLAGS_LD_DEBUG="$CFLAGS -g $WORD_SIZE"
+        CC_FLAGS_LD_OPT="$CFLAGS -O4 $WORD_SIZE"
+        ;;
+      *)
+        CC_FLAGS_DEBUG="$CFLAGS -g $WORD_SIZE "
+        CC_FLAGS_OPT="$CFLAGS -O3 $WORD_SIZE "
+        CC_FLAGS_LD_DEBUG="$CFLAGS -g $WORD_SIZE"
+        CC_FLAGS_LD_OPT="$CFLAGS -O3 $WORD_SIZE"
         ;;
     esac
     case $F77 in
@@ -4395,12 +4399,16 @@
         FC_FLAGS_LD_OPT="-O3 $WORD_SIZE -WF,-DAIX"
         ;;
       *gfortran)
-        CC_FLAGS_DEBUG="-g $WORD_SIZE "
-        CC_FLAGS_OPT="-O3 $WORD_SIZE "
-        CC_FLAGS_LD_DEBUG="-g $WORD_SIZE"
-        CC_FLAGS_LD_OPT="-O3 $WORD_SIZE"
+        FC_FLAGS_DEBUG="-g $WORD_SIZE "
+        FC_FLAGS_OPT="-O3 $WORD_SIZE "
+        FC_FLAGS_LD_DEBUG="-g $WORD_SIZE"
+        FC_FLAGS_LD_OPT="-O3 $WORD_SIZE"
         ;;
-      *cc)
+      *)
+        FC_FLAGS_DEBUG="-g $WORD_SIZE "
+        FC_FLAGS_OPT="-O3 $WORD_SIZE "
+        FC_FLAGS_LD_DEBUG="-g $WORD_SIZE"
+        FC_FLAGS_LD_OPT="-O3 $WORD_SIZE"
         ;;
     esac
     SHELL="/bin/sh"
EOF
    if [[ $? != 0 ]] ; then
        warn "Unable to apply CFLAGS patch to Mili 23.02"
        return 1
    fi

    return 0
}

function apply_mili_2302_blueos_patch
{
    info "Applying Mili 23.02 blueos patch."
    patch -p0 << \EOF
diff -u mili-23.02/src/eprtf.c.orig mili-23.02/src/eprtf.c
--- mili-23.02/src/eprtf.c.orig 2023-05-09 09:47:16.860814000 -0700
+++ mili-23.02/src/eprtf.c      2023-05-09 09:48:11.209704000 -0700
@@ -89,27 +89,23 @@
 #include "win32-regex.h"
 #endif

-#include "mili_enum.h"
+#include "mili_internal.h"
 #include "eprtf.h"

 static char destbuf[CMAX];
 static char *p_cur;
 static int cur_len;
 static va_list val;
-#ifdef HAVE_EPRINT
 static char *t_pattern = "%([0-9]+|[*])t";
 static regex_t all_re;
 static char *all_pattern =
    "%[0 -+#]*([0-9]*|[*])([.]([0-9]*|[*]))?[hlL]?[dioxXucsfeEgGpn%]";

-#endif
 static regex_t t_re;
 static regmatch_t t_match[1];


-#ifdef NOOPTERON
 static regmatch_t all_match[1];
-#endif


 /*****************************************************************
EOF
    if [[ $? != 0 ]] ; then
        warn "Unable to apply blueos patch to Mili 23.02"
        return 1
    fi

    return 0
}

function apply_mili_2302_write_funcs_patch
{
    #
    # write_funcs is not needed and having it in the header leads to
    # multiple definitions, which gcc 10.2 on Debian 11 doesn't like.
    #
    info "Applying Mili 23.02 write funcs patch."
    patch -p0 << \EOF
diff -u mili-23.02/src/mili_internal.h.orig mili-23.02/src/mili_internal.h
--- mili-23.02/src/mili_internal.h.orig 2023-05-09 09:41:20.347561000 -0700
+++ mili-23.02/src/mili_internal.h      2023-05-09 09:42:12.478771000 -0700
@@ -647,7 +647,6 @@
 /* dep.c - routines for handling architecture dependencies. */
 Return_value set_default_io_routines( Mili_family *fam );
 Return_value set_state_data_io_routines( Mili_family *fam );
-extern void (*write_funcs[QTY_PD_ENTRY_TYPES + 1])();

 /* svar.c - routines for managing state variables. */
 Bool_type valid_svar_data( Aggregate_type atype, char *name,
EOF
    if [[ $? != 0 ]] ; then
        warn "Unable to apply write funcs patch to Mili 23.02"
        return 1
    fi

    return 0
}

function apply_mili_2302_buildinfo_patch
{
    info "Applying Mili 23.02 buildinfo patch."
    patch -p0 << \EOF
diff -u mili-23.02/src/buildinfo.c.orig mili-23.02/src/buildinfo.c
--- mili-23.02/src/buildinfo.c.orig	2025-06-05 15:24:33.266799000 -0700
+++ mili-23.02/src/buildinfo.c	2025-06-05 15:25:22.203867000 -0700
@@ -120,7 +120,7 @@
 
    fprintf(outfile, "#define BI_CONFIG \"%s\"\n",
            CONFIG_CMD);
-   fp = popen( "module 2> /dev/null", "r");
+   fp = NULL; /*popen( "module 2> /dev/null", "r");*/
    if (fp == NULL)
    {
       fprintf(outfile, "#define BI_MODULES \"none\"\n");

EOF
    if [[ $? != 0 ]] ; then
        warn "Unable to apply buildinfo patch to Mili 23.02"
        return 1
    fi

    return 0
}

function apply_mili_patch
{
    if [[ "$OPSYS" == "Darwin" ]]; then
        apply_mili_2302_darwin_patch1
        if [[ $? != 0 ]] ; then
            return 1
        fi
        apply_mili_2302_darwin_patch2
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    apply_mili_2302_cflags_patch
    if [[ $? != 0 ]] ; then
        return 1
    fi
    apply_mili_2302_blueos_patch
    if [[ $? != 0 ]] ; then
        return 1
    fi
    apply_mili_2302_write_funcs_patch
    if [[ $? != 0 ]] ; then
        return 1
    fi

    apply_mili_2302_buildinfo_patch
    if [[ $? != 0 ]] ; then
        return 1
    fi

    return 0
}

function build_mili
{
    #
    # Prepare build dir
    #
    prepare_build_dir $MILI_BUILD_DIR $MILI_FILE
    untarred_mili=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_mili == -1 ]] ; then
        warn "Unable to prepare Mili Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching mili . . ."
    apply_mili_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_mili == 1 ]] ; then
            warn "Giving up on Mili build because the patches failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Configure Mili
    #
    info "Configuring Mili . . ."
    cd $MILI_BUILD_DIR || error "Can't cd to mili build dir."

    extra_ac_flags=""
    # detect coral systems, which older versions of autoconf don't detect
    if [[ "$(uname -m)" == "ppc64le" ]] ; then
         extra_ac_flags="ac_cv_build=powerpc64le-unknown-linux-gnu"
    elif [[ "$(uname -m)" == "aarch64" ]] ; then
         extra_ac_flags="ac_cv_build=aarch64-unknown-linux-gnu"
    fi

    F77_ARG=""
    TYPEDEFS_ARG=""
    config_script=configure
    if [[ ${MILI_VERSION} == 19.2 && "$OPSYS" == "Darwin" ]]; then
        config_script=configure_15_1
    elif [[ ${MILI_VERSION} == 22.01 && "$OPSYS" == "Darwin" ]] ||
         [[ ${MILI_VERSION} == 23.02 && "$OPSYS" == "Darwin" ]] ; then
        # Mili 22.1/23.02 configure expects fortran compiler even if no intention to use it.
        # We spoof fortran compiler here to fool configure.
       cat << \EOF > spoof_f77.sh
#!/bin/sh
echo "#!/bin/sh" > conftest.out
chmod 755 conftest.out
EOF
        chmod 755 spoof_f77.sh
        F77_ARG="F77=./spoof_f77.sh"
        TYPEDEFS_ARG="ac_cv_type_mode_t=yes ac_cv_type_off_t=yes ac_cv_type_size_t=yes"
    fi

    info "Invoking command to configure Mili"
    set -x
    ./${config_script} CXX="$CXX_COMPILER" CC="$C_COMPILER" \
                CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
                ac_cv_prog_FOUND_GMAKE=make $extra_ac_flags $F77_ARG $TYPEDEFS_ARG \
                LDFLAGS="-lm" \
                --prefix="$VISITDIR/mili/$MILI_VERSION/$VISITARCH"
    set +x
    if [[ $? != 0 ]] ; then
        warn "Mili configure failed.  Giving up"
        return 1
    fi

    #
    # Build Mili
    #
    info "Building Mili . . . (~2 minutes)"
    cd MILI-*-*
    $MAKE opt fortran=false

    #
    # Install into the VisIt third party location.
    #
    info "Installing Mili . . ." 

    mkdir "$VISITDIR/mili"
    mkdir "$VISITDIR/mili/$MILI_VERSION"
    mkdir "$VISITDIR/mili/$MILI_VERSION/$VISITARCH"
    mkdir "$VISITDIR/mili/$MILI_VERSION/$VISITARCH/lib"
    mkdir "$VISITDIR/mili/$MILI_VERSION/$VISITARCH/include"
    cp src/{mili.h,mili_enum.h,misc.h}  "$VISITDIR/mili/$MILI_VERSION/$VISITARCH/include"
    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        INSTALLNAMEPATH="$VISITDIR/mili/${MILI_VERSION}/$VISITARCH/lib"

        $C_COMPILER -dynamiclib -o libmili.$SO_EXT objs_opt/*.o \
                    -Wl,-headerpad_max_install_names \
                    -Wl,-install_name,$INSTALLNAMEPATH/libmili.${SO_EXT} \
                    -Wl,-compatibility_version,$MILI_COMPATIBILITY_VERSION \
                    -Wl,-current_version,$MILI_VERSION
        if [[ $? != 0 ]] ; then
            warn "Mili dynamic library build failed.  Giving up"
            return 1
        fi
        cp libmili.$SO_EXT "$VISITDIR/mili/$MILI_VERSION/$VISITARCH/lib"
    else
        cp lib_opt/libmili.a "$VISITDIR/mili/$MILI_VERSION/$VISITARCH/lib"
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/mili"
        chgrp -R ${GROUP} "$VISITDIR/mili"
    fi
    cd "$START_DIR"
    info "Done with Mili"
    return 0
}

function bv_mili_is_enabled
{
    if [[ $DO_MILI == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_mili_is_installed
{
    check_if_installed "mili" $MILI_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_mili_build
{
    cd "$START_DIR"
    if [[ "$DO_MILI" == "yes" ]] ; then
        check_if_installed "mili" $MILI_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Mili build.  Mili is already installed."
        else
            info "Building Mili (~2 minutes)"
            build_mili
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Mili.  Bailing out."
            fi
            info "Done building Mili"
        fi
    fi
}
function bv_moab_initialize
{
    export DO_MOAB="no"
}

function bv_moab_enable
{
    DO_MOAB="yes"
}

function bv_moab_disable
{
    DO_MOAB="no"
}

function bv_moab_depends_on
{
    local depends_on="hdf5 zlib"

    if [[ "$DO_SZIP" == "yes" ]] ; then
        depends_on="$depends_on szip"
    fi

    echo $depends_on
}

function bv_moab_info
{
    export MOAB_VERSION=${MOAB_VERSION:-"5.5.0"}
    export MOAB_FILE=${MOAB_FILE:-"moab-${MOAB_VERSION}.tar.gz"}
    export MOAB_BUILD_DIR=${MOAB_BUILD_DIR:-"moab-5.5.0"}
    export MOAB_SHA256_CHECKSUM="58969f8a1b209ec9036c08c53a6b7078b368eb3bf99d0368a4de5a2f2a8db678"
}

function bv_moab_print
{
    printf "%s%s\n" "MOAB_FILE=" "${MOAB_FILE}"
    printf "%s%s\n" "MOAB_VERSION=" "${MOAB_VERSION}"
    printf "%s%s\n" "MOAB_BUILD_DIR=" "${MOAB_BUILD_DIR}"
}

function bv_moab_print_usage
{
    printf "%-20s %s [%s]\n" "--moab" "Build moab support" "$DO_MOAB"
}

function bv_moab_host_profile
{
    if [[ "$DO_MOAB" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## MOAB" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_MOAB_DIR \${VISITHOME}/moab/$MOAB_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_MOAB_LIBDEP HDF5_LIBRARY_DIR hdf5 \${VISIT_HDF5_LIBDEP} TYPE STRING)" \
            >> $HOSTCONF
        if [[ -n "$PAR_COMPILER" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_MOAB_MPI_DIR \${VISITHOME}/moab_mpi/$MOAB_VERSION/\${VISITARCH})" \
                >> $HOSTCONF
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_MOAB_MPI_LIBDEP HDF5_MPI_LIBRARY_DIR hdf5_mpi \${VISIT_HDF5_MPI_LIBDEP} TYPE STRING)" \
                >> $HOSTCONF
        fi
    fi
}

function bv_moab_ensure
{
    if [[ "$DO_MOAB" == "yes" ]] ; then
        ensure_built_or_ready "moab" $MOAB_VERSION $MOAB_BUILD_DIR $MOAB_FILE $MOAB_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_MOAB="no"
            error "Unable to build moab.  ${MOAB_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_moab
# *************************************************************************** #
function build_moab
{
    #
    # Prepare build dir
    #
    prepare_build_dir $MOAB_BUILD_DIR $MOAB_FILE
    untarred_moab=$?
    if [[ $untarred_moab == -1 ]] ; then
        warn "Unable to prepare moab build directory. Giving Up!"
        return 1
    fi

    cd $MOAB_BUILD_DIR || error "Can't cd to moab build dir."
    rm -f src/moab/MOABConfig.h # work around a potential issue in MOAB tarball

    par_build_types="serial"
    if [[ -n "$PAR_COMPILER_CXX" ]]; then
        par_build_types="$par_build_types parallel"
    fi

    for bt in $par_build_types; do 

        mkdir build_$bt
        pushd build_$bt

        cf_mpi_arg=""
        cf_par_suffix=""
        if [[ "$bt" == "serial" ]]; then
            cf_c_compiler="$C_COMPILER"
            cf_cxx_compiler="$CXX_COMPILER"
        elif [[ "$bt" == "parallel" ]]; then
            # these commands ruin the untar'd source code for normal builds
            sed -i.orig -e 's/libhdf5/libhdf5_mpi/g' ../configure
            sed -i.orig -e 's/libMOAB/libMOAB_mpi/g' ../configure
            sed -i.orig -e 's/=hdf5/=hdf5_mpi/' ../configure
            sed -i.orig -e 's/^LIBS = @LIBS@/LIBS = @HDF5_LIBS@ @LIBS@/' ../tools/Makefile.in
            find .. -name Makefile.in -exec sed -e 's/libMOAB/libMOAB_mpi/g' -i.orig {} \;
            cf_mpi_arg="--with-mpi"
            cf_par_suffix="_mpi"
            cf_c_compiler="$PAR_COMPILER"
            cf_cxx_compiler="$PAR_COMPILER_CXX"
        fi

        cf_prefix_arg="--prefix=$VISITDIR/moab${cf_par_suffix}/$MOAB_VERSION/$VISITARCH"
        cf_common_args="--with-pic --disable-fortran --disable-imesh --disable-cgns"

        if [[ "DO_STATIC_BUILD" == "yes" ]]; then
            cf_static_args="--enable-static --disable-shared"
        else
            cf_static_args="--disable-static --enable-shared"
        fi

        cf_hdf5_ldflags_arg=""
        cf_szip_arg=""
        cf_zlib_arg=""
        cf_hdf5_arg="--with-hdf5=$VISITDIR/hdf5${cf_par_suffix}/$HDF5_VERSION/$VISITARCH"
        if [[ "$DO_SZIP" == "yes" ]] ; then
            cf_szip_arg="--with-szip=$VISITDIR/szip/$SZIP_VERSION/$VISITARCH"
            cf_hdf5_ldflags_arg="-lsz"
        fi
        cf_zlib_arg="--with-zlib=$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH"
        cf_hdf5_ldflags_arg="$cf_hdf5_ldflags_arg -lz"
        if [[ -n "$cf_hdf5_ldflags_arg" ]]; then
            cf_hdf5_ldflags_arg="--with-hdf5-ldflags=\"$cf_hdf5_ldflags_arg\""
        fi

        info "Configuring $bt moab . . ."
        set -x
        sh -c "../configure \
            CXX=\"$cf_cxx_compiler\" CXXFLAGS=\"$CXXFLAGS $CXX_OPT_FLAGS\" \
            CC=\"$cf_c_compiler\" CFLAGS=\"$CFLAGS $C_OPT_FLAGS\" \
            ${cf_prefix_arg} ${cf_mpi_arg} ${cf_common_args} ${cf_static_args} \
            ${cf_hdf5_arg} ${cf_hdf5_ldflags_arg} \
            ${cf_szip_arg} ${cf_zlib_arg}"
        set +x
        if [[ $? != 0 ]] ; then
            warn "$bt MOAB configure failed.  Giving up"
            return 1
        fi

        #
        # Build moab
        #

        info "Building $bt moab . . . (~2 minutes)"
        $MAKE $MAKE_OPT_FLAGS
        if [[ $? != 0 ]] ; then
            warn "$bt moab build failed.  Giving up"
            return 1
        fi

        #
        # Install into the VisIt third party location.
        #
        info "Installing $bt moab"
        $MAKE install

        if [[ "$DO_GROUP" == "yes" ]] ; then
            chmod -R ug+w,a+rX "$VISITDIR/moab${cf_par_suffix}"
            chgrp -R ${GROUP} "$VISITDIR/moab${cf_par_suffix}"
        fi

        #
        # Change name of installed lib to libXXX_mpi.whatever
        #
        if [[ "$bt" == "parallel" ]]; then
            pushd $VISITDIR/moab${cf_par_suffix}/$MOAB_VERSION/$VISITARCH/lib
            if [[ "$OPSYS" == "Darwin" ]]; then
                install_name_tool -id $VISITDIR/moab${cf_par_suffix}/$MOAB_VERSION/$VISITARCH/lib/libMOAB_mpi.dylib libMOAB_mpi.dylib
            fi
            popd
        fi

        popd
    done

    cd "$START_DIR"
    info "Done with moab"
    return 0
}


function bv_moab_is_enabled
{
    if [[ $DO_MOAB == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_moab_is_installed
{
    check_if_installed "moab" $MOAB_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_moab_build
{
    cd "$START_DIR"
    if [[ "$DO_MOAB" == "yes" ]] ; then
        check_if_installed "moab" $MOAB_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping moab build.  moab is already installed."
        else
            info "Building moab (~2 minutes)"
            build_moab
            if [[ $? != 0 ]] ; then
                error "Unable to build or install moab.  Bailing out."
            fi
            info "Done building moab"
        fi
    fi
}
function bv_mpich_initialize
{
    export DO_MPICH="no"
}

function bv_mpich_enable
{
    DO_MPICH="yes"
}

function bv_mpich_disable
{
    DO_MPICH="no"
}

function bv_mpich_depends_on
{
    local depends_on=""

    echo $depends_on
}

function bv_mpich_info
{
    export MPICH_VERSION=${MPICH_VERSION:-"3.3.1"}
    export MPICH_FILE=${MPICH_FILE:-"mpich-${MPICH_VERSION}.tar.gz"}
    export MPICH_COMPATIBILITY_VERSION=${MPICH_COMPATIBILITY_VERSION:-"3.3"}
    export MPICH_BUILD_DIR=${MPICH_BUILD_DIR:-"mpich-${MPICH_VERSION}"}
    export MPICH_SHA256_CHECKSUM="fe551ef29c8eea8978f679484441ed8bb1d943f6ad25b63c235d4b9243d551e5"
}

function bv_mpich_print
{
    printf "%s%s\n" "MPICH_FILE=" "${MPICH_FILE}"
    printf "%s%s\n" "MPICH_VERSION=" "${MPICH_VERSION}"
    printf "%s%s\n" "MPICH_COMPATIBILITY_VERSION=" "${MPICH_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "MPICH_BUILD_DIR=" "${MPICH_BUILD_DIR}"
}

function bv_mpich_print_usage
{
    printf "%-20s %s [%s]\n" "--mpich" "Build MPICH support" "$DO_MPICH"
}

function bv_mpich_host_profile
{
    if [[ "$DO_MPICH" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## MPICH" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "SETUP_APP_VERSION(MPICH $MPICH_VERSION)" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_MPICH_DIR \${VISITHOME}/mpich/\${MPICH_VERSION}/\${VISITARCH})" \
            >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_MPICH_INSTALL ON TYPE BOOL)" >> $HOSTCONF
        echo "" >> $HOSTCONF
        echo "# Tell VisIt the parallel compiler so it can deduce parallel flags" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_MPI_COMPILER \${VISIT_MPICH_DIR}/bin/mpicc TYPE FILEPATH)"  >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_PARALLEL ON TYPE BOOL)" >> $HOSTCONF
    fi
}

function bv_mpich_ensure
{
    if [[ "$DO_MPICH" == "yes" ]] ; then
        ensure_built_or_ready "mpich" $MPICH_VERSION $MPICH_BUILD_DIR $MPICH_FILE $MPICH_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_MPICH="no"
            error "Unable to build MPICH.  ${MPICH_FILE} not found."
        fi
    fi
}

function apply_mpich_slurm_patch
{
    #
    # Patch for building on a system with slurm. The type of hostlist_t
    # was changed from a pointer to an opaque structure between 23.2.8
    # and 23.11.0. This was determined by comparing releases from the
    # site https://download.schedmd.com/slurm/.
    # 
   patch -p0 << \EOF
diff -c src/pm/hydra/tools/bootstrap/external/slurm_query_node_list.c.orig src/pm/hydra/tools/bootstrap/external/slurm_query_node_list.c
*** src/pm/hydra/tools/bootstrap/external/slurm_query_node_list.c.orig	2025-02-18 09:23:02.009141000 -0800
--- src/pm/hydra/tools/bootstrap/external/slurm_query_node_list.c	2025-02-18 09:24:54.077110000 -0800
***************
*** 10,16 ****
  #include "slurm.h"
  
  #if defined(HAVE_SLURM_SLURM_H)
! #include <slurm/slurm.h>        /* for slurm_hostlist_create */
  #elif defined(HAVE_POSIX_REGCOMP)
  #include <regex.h>      /* for POSIX regular expressions */
  
--- 10,17 ----
  #include "slurm.h"
  
  #if defined(HAVE_SLURM_SLURM_H)
! #include <slurm/slurm.h>         /* for slurm_hostlist_create */
! #include <slurm/slurm_version.h> /* for slurm version macros */
  #elif defined(HAVE_POSIX_REGCOMP)
  #include <regex.h>      /* for POSIX regular expressions */
  
***************
*** 26,32 ****
--- 27,37 ----
  #if defined(HAVE_LIBSLURM)
  static HYD_status list_to_nodes(char *str)
  {
+ #if SLURM_VERSION_NUMBER > SLURM_VERSION_NUM(23,2,8)
+     hostlist_t *hostlist;
+ #else
      hostlist_t hostlist;
+ #endif
      char *host;
      int k = 0;
      HYD_status status = HYD_SUCCESS;
EOF

    if [[ $? != 0 ]] ; then
      warn "mpich slurm patch failed."
      return 1
    fi
    return 0;
}

function apply_mpich_patch
{
    info "Patching MPICH . . ."

    apply_mpich_slurm_patch
    if [[ $? != 0 ]] ; then
        return 1
    fi

    return 0
}

# *************************************************************************** #
#                            Function 8, build_mpich
#
# Modfications:
#   Eric Brugger, Tue Feb 18 09:40:26 PST 2025
#   I added a patch for building on a system with a newer slurm.
#
# *************************************************************************** #

function build_mpich
{
    #
    # Prepare build dir
    #
    prepare_build_dir $MPICH_BUILD_DIR $MPICH_FILE
    untarred_mpich=$?
    if [[ $untarred_mpich == -1 ]] ; then
        warn "Unable to prepare MPICH build directory. Giving Up!"
        return 1
    fi
    
    cd $MPICH_BUILD_DIR || error "Can't cd to MPICH build dir."

    #
    # Apply patches
    #
    apply_mpich_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_mpich == 1 ]] ; then
            warn "Giving up on MPICH build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Call configure
    #
    info "Configuring MPICH . . ."
    info "Invoking command to configure MPICH"

    #
    # Turning off maintainer mode avoids need for any local autotools tools.
    # We should not ever need them because we are not developing mpich.
    # I guess we need shared libs.
    #
    mpich_opts="--disable-maintainer-mode --enable-shared"
    if [[ "$OPSYS" == "Darwin" ]]; then
        mpich_opts="${mpich_opts} --enable-threads=single"
    fi

    #
    # MPICH will fail to build if we disable common blocks '-fno-common'
    # Screen the flags vars to make sure we don't use this option for MPICH
    #
    MPICH_CFLAGS=`echo $CFLAGS | sed -e 's/-fno-common//g'`
    MPICH_C_OPT_FLAGS=`echo $C_OPT_FLAGS | sed -e 's/-fno-common//g'`
    MPICH_CXXFLAGS=`echo $CXXFLAGS | sed -e 's/-fno-common//g'`
    MPICH_CXX_OPT_FLAGS=`echo $CXX_OPT_FLAGS | sed -e 's/-fno-common//g'`
    MPICH_FCFLAGS=`echo $FCFLAGS | sed -e 's/-fno-common//g'`

    #
    # Enable/disable fortran as needed.
    #
    if [[ "$FC_COMPILER" == "no" ]] ; then
        mpich_opts="${mpich_opts} --enable-fortran=no"
    else
        mpich_opts="${mpich_opts} --enable-fortran=all"	
    fi

    set -x
    issue_command env CXX="$CXX_COMPILER" \
                  CC="$C_COMPILER" \
                  CFLAGS="$MPICH_CFLAGS $MPICH_C_OPT_FLAGS" \
                  CXXFLAGS="$MPICH_CXXFLAGS $MPICH_CXX_OPT_FLAGS"\
                  FFLAGS="$MPICH_FCFLAGS"\
                  ./configure ${mpich_opts} \
                  --prefix="$VISITDIR/mpich/$MPICH_VERSION/$VISITARCH"
    set +x
    if [[ $? != 0 ]] ; then
        warn "MPICH configure failed.  Giving up"
        return 1
    fi

    #
    # Build MPICH
    #
    info "Building MPICH . . . (~5 minutes)"
    env $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        if [[ "$OPSYS" == "Darwin" ]]; then
            warn "MPICH build failed but maybe due to LDFLAGS.\n" \
                 "Retrying MPICH build with LDFLAGS set."
            env $MAKE $MAKE_OPT_FLAGS LDFLAGS="-Wl,-flat_namespace -Wl,-undefined -Wl,suppress"
            if [[ $? != 0 ]] ; then
                warn "MPICH build failed.  Giving up"
                return 1
            fi
        else
            warn "MPICH build failed.  Giving up"
            return 1
        fi
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing MPICH"
    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "MPICH install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/mpich"
        chgrp -R ${GROUP} "$VISITDIR/mpich"
    fi
    cd "$START_DIR"
    info "Done with MPICH"
    return 0
}

function bv_mpich_is_enabled
{
    if [[ $DO_MPICH == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_mpich_is_installed
{
    check_if_installed "mpich" $MPICH_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_mpich_build
{
    cd "$START_DIR"
    if [[ "$DO_MPICH" == "yes" ]] ; then
        check_if_installed "mpich" $MPICH_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping MPICH build.  MPICH is already installed."
        else
            info "Building MPICH (~2 minutes)"
            build_mpich
            if [[ $? != 0 ]] ; then
                error "Unable to build or install MPICH.  Bailing out."
            fi
            info "Done building MPICH"
        fi
    fi
}
function bv_nektarpp_initialize
{
    export DO_NEKTAR_PLUS_PLUS="no"
    export USE_SYSTEM_NEKTAR_PLUS_PLUS="no"
    add_extra_commandline_args "nektarpp" "alt-nektarpp-dir" 1 "Use alternative directory for nektar++"
}

function bv_nektarpp_enable
{
    DO_NEKTAR_PLUS_PLUS="yes"
}

function bv_nektarpp_disable
{
    DO_NEKTAR_PLUS_PLUS="no"
}

function bv_nektarpp_alt_nektarpp_dir
{
    bv_nektarpp_enable
    USE_SYSTEM_NEKTAR_PLUS_PLUS="yes"
    NEKTAR_PLUS_PLUS_INSTALL_DIR="$1"
}

function bv_nektarpp_depends_on
{
    if [[ "$USE_SYSTEM_NEKTAR_PLUS_PLUS" == "yes" ]]; then
        echo ""
    else
        echo "cmake boost zlib"
    fi
}

function bv_nektarpp_initialize_vars
{
    if [[ "$USE_SYSTEM_NEKTAR_PLUS_PLUS" == "no" ]]; then
        NEKTAR_PLUS_PLUS_INSTALL_DIR="${VISITDIR}/nektar++/$NEKTAR_PLUS_PLUS_VERSION/${VISITARCH}"
    fi
}

function bv_nektarpp_info
{
    export NEKTAR_PLUS_PLUS_VERSION=${NEKTAR_PLUS_PLUS_VERSION:-"5.0.0"}
    export NEKTAR_PLUS_PLUS_FILE=${NEKTAR_PLUS_PLUS_FILE:-"nektar-v${NEKTAR_PLUS_PLUS_VERSION}.tar.gz"}
    export NEKTAR_PLUS_PLUS_COMPATIBILITY_VERSION=${NEKTAR_PLUS_PLUS_COMPATIBILITY_VERSION:-"5.0"}
    export NEKTAR_PLUS_PLUS_BUILD_DIR=${NEKTAR_PLUS_PLUS_BUILD_DIR:-"nektar-v${NEKTAR_PLUS_PLUS_VERSION}"}
    export NEKTAR_PLUS_PLUS_SHA256_CHECKSUM="c1e60c015258eb906351c7503c416aaee0e754ec4fa39feaf176c12ba6fc5c73"
}

function bv_nektarpp_print
{
    printf "%s%s\n" "NEKTAR_PLUS_PLUS_FILE=" "${NEKTAR_PLUS_PLUS_FILE}"
    printf "%s%s\n" "NEKTAR_PLUS_PLUS_VERSION=" "${NEKTAR_PLUS_PLUS_VERSION}"
    printf "%s%s\n" "NEKTAR_PLUS_PLUS_COMPATIBILITY_VERSION=" "${NEKTAR_PLUS_PLUS_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "NEKTAR_PLUS_PLUS_BUILD_DIR=" "${NEKTAR_PLUS_PLUS_BUILD_DIR}"
}

function bv_nektarpp_print_usage
{
    printf "%-20s %s [%s]\n" "--nektarpp" "Build Nektar++" "${DO_NEKTAR_PLUS_PLUS}"
    printf "%-20s %s [%s]\n" "--alt-nektarpp-dir" "Use Nektar++ from an alternative directory"
}

function bv_nektarpp_host_profile
{
    if [[ "$DO_NEKTAR_PLUS_PLUS" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Nektar++" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        echo "SETUP_APP_VERSION(NEKTAR++ $NEKTAR_PLUS_PLUS_VERSION)" >> $HOSTCONF

        if [[ "$USE_SYSTEM_NEKTAR_PLUS_PLUS" == "yes" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_NEKTAR++_DIR $NEKTAR_PLUS_PLUS_INSTALL_DIR)" \
                >> $HOSTCONF
        else
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_NEKTAR++_DIR \${VISITHOME}/nektar++/\${NEKTAR++_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF

            ZLIB_LIBDEP="\${VISITHOME}/zlib/\${ZLIB_VERSION}/\${VISITARCH}/lib z"

            echo \
                "VISIT_OPTION_DEFAULT(VISIT_NEKTAR++_LIBDEP $ZLIB_LIBDEP TYPE STRING)" \
                >> $HOSTCONF
        fi
    fi
}

function bv_nektarpp_ensure
{
    if [[ "$DO_NEKTAR_PLUS_PLUS" == "yes" && "$USE_SYSTEM_NEKTAR_PLUS_PLUS" == "no" ]] ; then
        ensure_built_or_ready "nektar++" $NEKTAR_PLUS_PLUS_VERSION $NEKTAR_PLUS_PLUS_BUILD_DIR $NEKTAR_PLUS_PLUS_FILE $NEKTAR_PLUS_PLUS_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_NEKTAR_PLUS_PLUS="no"
            error "Unable to build Netar++.  ${NEKTAR_PLUS_PLUS_FILE} not found."
        fi
    fi
}


function apply_nektarpp_5_0_0_patch
{
    info "Patching Nektar++ 5.0.0"
    patch -p0 << \EOF
diff -rcN nektar-v5.0.0/library/LibUtilities/Communication/CommDataType_orig.h nektar-v5.0.0/library/LibUtilities/Communication/CommDataType.h
*** nektar-v5.0.0/library/LibUtilities/Communication/CommDataType_orig.h	2020-02-10 17:12:37.037503006 -0700
--- nektar-v5.0.0/library/LibUtilities/Communication/CommDataType.h	2020-02-10 17:14:00.179539468 -0700
***************
*** 67,85 ****
  {
  namespace LibUtilities
  {
! enum CommDataType
! {
!     MPI_CHAR,
!     MPI_INT,
!     MPI_UNSIGNED,
!     MPI_LONG,
!     MPI_UNSIGNED_LONG,
!     MPI_LONG_LONG,
!     MPI_UNSIGNED_LONG_LONG,
!     MPI_FLOAT,
!     MPI_DOUBLE,
!     MPI_LONG_DOUBLE
! };
  }
  }
  #endif
--- 67,113 ----
  {
  namespace LibUtilities
  {
! typedef int CommDataType;
!
! #ifndef MPI_CHAR
!     #define MPI_CHAR            ((CommDataType)0x4c000101)
! #endif
!
! #ifndef MPI_INT
!     #define MPI_INT            ((CommDataType)0x4c000405)
! #endif
!
! #ifndef MPI_UNSIGNED
!     #define MPI_UNSIGNED       ((CommDataType)0x4c000406)
! #endif
!
! #ifndef MPI_LONG
!     #define MPI_LONG           ((CommDataType)0x4c000807)
! #endif
!
! #ifndef MPI_UNSIGNED_LONG
!     #define MPI_UNSIGNED_LONG  ((CommDataType)0x4c000808)
! #endif
!
! #ifndef MPI_LONG_LONG
!     #define MPI_LONG_LONG      ((CommDataType)0x4c000809)
! #endif
!
! #ifndef MPI_UNSIGNED_LONG_LONG
!     #define MPI_UNSIGNED_LONG_LONG ((CommDataType)0x4c000819)
! #endif
!
! #ifndef MPI_FLOAT
!     #define MPI_FLOAT          ((CommDataType)0x4c00040a)
! #endif
!
! #ifndef MPI_DOUBLE
!     #define MPI_DOUBLE         ((CommDataType)0x4c00080b)
! #endif
!
! #ifndef MPI_LONG_DOUBLE
!     #define MPI_LONG_DOUBLE    ((CommDataType)0x4c00100c)
! #endif
  }
  }
  #endif
EOF
}

function apply_nektarpp_patch
{

    if [[ "${NEKTAR_PLUS_PLUS_VERSION}" == 5.0.0 ]] ; then
        apply_nektarpp_5_0_0_patch
        if [[ $? != 0 ]]; then
           return 1
        fi
    fi

    return 0
}

# *************************************************************************** #
#              Function 8.1, build_nektarpp                                   #
# *************************************************************************** #
function build_nektarpp
{
    #
    # CMake is the build system for VTK.  Call another script that will build
    # that program.
    #
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}
    if [[ -e ${CMAKE_INSTALL}/cmake ]] ; then
        info "Nektar++: CMake found"
    else
        warn "Unable to find cmake, cannot build Nektar++. Giving up."
        return 1
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $NEKTAR_PLUS_PLUS_BUILD_DIR $NEKTAR_PLUS_PLUS_FILE
    untarred_nektar_plus_plus=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_nektar_plus_plus == -1 ]] ; then
        warn "Unable to prepare Nektar++ Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching Nektar++ . . ."
    apply_nektarpp_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_nektar_plus_plus == 1 ]] ; then
            warn "Giving up on Nektar++ build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    cd $NEKTAR_PLUS_PLUS_BUILD_DIR || error "Can't cd to Nektar++ build dir." $NEKTAR_PLUS_PLUS_BUILD_DIR

    #
    # Configure Nektar++
    #
    info "Configuring Nektar++ . . ."

    ntopts=""
    nektar_plus_plus_build_mode="${VISIT_BUILD_MODE}"
    nektar_plus_plus_inst_path="${NEKTAR_PLUS_PLUS_INSTALL_DIR}"

    ntopts="${ntopts} -DCMAKE_BUILD_TYPE:STRING=${nektar_plus_plus_build_mode}"
    ntopts="${ntopts} -DCMAKE_INSTALL_PREFIX:PATH=${nektar_plus_plus_inst_path}"

    ntopts="${ntopts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    ntopts="${ntopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    ntopts="${ntopts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS}\""
    ntopts="${ntopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS}\""
#    ntopts="${ntopts} -DCMAKE_EXE_LINKER_FLAGS:STRING=${lf}"
#    ntopts="${ntopts} -DCMAKE_MODULE_LINKER_FLAGS:STRING=${lf}"
#    ntopts="${ntopts} -DCMAKE_SHARED_LINKER_FLAGS:STRING=${lf}"

    # Nektar++ specific options for a faster build.
#    ntopts="${ntopts} -DTHIRDPARTY_BUILD_BOOST:BOOL=ON"
    ntopts="${ntopts} -DNEKTAR_BUILD_DEMOS:BOOL=OFF"
    ntopts="${ntopts} -DNEKTAR_BUILD_SOLVERS:BOOL=OFF"
    ntopts="${ntopts} -DNEKTAR_BUILD_UTILITIES:BOOL=OFF"
    ntopts="${ntopts} -DNEKTAR_BUILD_TESTS:BOOL=OFF"
    ntopts="${ntopts} -DNEKTAR_BUILD_UNIT_TESTS:BOOL=OFF"
    ntopts="${ntopts} -DNEKTAR_USE_SCOTCH:BOOL=OFF"
    ntopts="${ntopts} -DNEKTAR_ERROR_ON_WARNINGS:BOOL=OFF"

#    if test "${OPSYS}" = "Darwin" ; then
#        ntopts="${ntopts} -DCMAKE_INSTALL_NAME_DIR:PATH=${nektar_plus_plus_inst_path}/lib"
#    fi

    if [[ "$DO_BOOST" == "yes" ]] ; then
        info "boost requested.  Configuring NEKTAR++ with boost support."
        ntopts="${ntopts} -DBOOST_ROOT:PATH=${VISITDIR}/boost/${BOOST_VERSION}/${VISITARCH}"

        if [[ "$OPSYS" == "Darwin" ]]; then
            export DYLD_LIBRARY_PATH="$VISITDIR/boost/$BOOST_VERSION/$VISITARCH/lib":$DYLD_LIBRARY_PATH
        else
            export LD_LIBRARY_PATH="$VISITDIR/boost/$BOOST_VERSION/$VISITARCH/lib":$LD_LIBRARY_PATH
        fi
    fi

    info "Configuring NEKTAR++ with zlib support."
    ntopts="${ntopts} -DZLIB_ROOT:PATH=${VISITDIR}/zlib/${ZLIB_VERSION}/${VISITARCH}"

    if [[ "$OPSYS" == "Darwin" ]]; then
        export DYLD_LIBRARY_PATH="$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/lib":$DYLD_LIBRARY_PATH
    else
        export LD_LIBRARY_PATH="$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/lib":$LD_LIBRARY_PATH
    fi

#    if test "${DO_MPICH}" = "yes"; then
#        info "mpich requested.  Configuring NEKTAR++ with mpich support."
#        ntopts="${ntopts} -DMPI_ROOT:PATH=${VISITDIR}/mpich/${MPICH_VERSION}/${VISITARCH}"

#        if [[ "$OPSYS" == "Darwin" ]]; then
#            export DYLD_LIBRARY_PATH="$VISITDIR/mpich/$MPICH_VERSION/$VISITARCH/lib":$DYLD_LIBRARY_PATH
#        else
#            export LD_LIBRARY_PATH="$VISITDIR/mpich/$MPICH_VERSION/$VISITARCH/lib":$LD_LIBRARY_PATH
#        fi
#    fi

#        if test "${DO_VTK}" = "yes"; then
#            info "vtk requested.  Configuring NEKTAR++ with vtk support."
#            ntopts="${ntopts} -DNEKTAR_USE_VTK=ON -DVTK_DIR:PATH=${VISITDIR}/${VTK_INSTALL_DIR}/${VTK_VERSION}/${VISITARCH}/lib/cmake/vtk-${VTK_SHORT_VERSION}"

#            if [[ "$OPSYS" == "Darwin" ]]; then
#                export DYLD_LIBRARY_PATH="$VISITDIR/$VTK_INSTALL_DIR/$VTK_VERSION/$VISITARCH/lib":$DYLD_LIBRARY_PATH
#            else
#                export LD_LIBRARY_PATH="$VISITDIR/$VTK_INSTALL_DIR/$VTK_VERSION/$VISITARCH/lib":$LD_LIBRARY_PATH
#            fi
#        fi

    cd "$START_DIR"

    # Make a build directory for an out-of-source build.. Change the
    # VISIT_BUILD_DIR variable to represent the out-of-source build directory.
    NEKTAR_PLUS_PLUS_SRC_DIR=$NEKTAR_PLUS_PLUS_BUILD_DIR
    NEKTAR_PLUS_PLUS_BUILD_DIR="${NEKTAR_PLUS_PLUS_SRC_DIR}-build"
    if [[ ! -d $NEKTAR_PLUS_PLUS_BUILD_DIR ]] ; then
        echo "Making build directory $NEKTAR_PLUS_PLUS_BUILD_DIR"
        mkdir $NEKTAR_PLUS_PLUS_BUILD_DIR
    fi

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"

    cd ${NEKTAR_PLUS_PLUS_BUILD_DIR}

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi

    #
    # Remove the CMakeCache.txt files ... existing files sometimes prevent
    # fields from getting overwritten properly.
    #
    rm -Rf ${NEKTAR_PLUS_PLUS_BUILD_DIR}/CMakeCache.txt ${NEKTAR_PLUS_PLUS_BUILD_DIR}/*/CMakeCache.txt

    echo "\"${CMAKE_BIN}\"" ${ntopts} ../${NEKTAR_PLUS_PLUS_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "Nektar++ configuration failed."

    #
    # Build NEKTAR_PLUS_PLUS
    #
    info "Making Nektar++ . . ."
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Nektar++ build failed.  Giving up"
        return 1
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing Nektar++ . . ."
    ${CMAKE_COMMAND} --install .
    if [[ $? != 0 ]] ; then
        warn "Nektar++ install failed.  Giving up"
        return 1
    fi

    #    mv ${nektar_plus_plus_inst_path}/lib64/* ${nektar_plus_plus_inst_path}/lib

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/nektar++"
        chgrp -R ${GROUP} "$VISITDIR/nektar++"
    fi
    cd "$START_DIR"
    info "Done with Nektar++"
    return 0
}

function bv_nektarpp_is_enabled
{
    if [[ $DO_NEKTAR_PLUS_PLUS == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_nektarpp_is_installed
{

    if [[ "$USE_SYSTEM_NEKTAR_PLUS_PLUS" == "yes" ]]; then
        return 1
    fi

    check_if_installed "nektar++" $NEKTAR_PLUS_PLUS_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_nektarpp_build
{
    cd "$START_DIR"

    if [[ "$DO_NEKTAR_PLUS_PLUS" == "yes" && "$USE_SYSTEM_NEKTAR_PLUS_PLUS" == "no" ]] ; then
        check_if_installed "nektar++" $NEKTAR_PLUS_PLUS_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Nektar++ build.  Nektar++ is already installed."
        else
            info "Building Nektar++ (~10 minutes)"
            build_nektarpp
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Nektar++.  Bailing out."
            fi
            info "Done building Nektar++"
        fi
    fi
}
function bv_netcdf_initialize
{
    export DO_NETCDF="no"
    export USE_SYSTEM_NETCDF="no"
    add_extra_commandline_args "netcdf" "alt-netcdf-dir" 1 "Use alternative directory for netcdf"
}

function bv_netcdf_enable
{
    DO_NETCDF="yes"
}

function bv_netcdf_disable
{
    DO_NETCDF="no"
}

function bv_netcdf_alt_netcdf_dir
{
    bv_netcdf_enable
    USE_SYSTEM_NETCDF="yes"
    NETCDF_INSTALL_DIR="$1"
}

function bv_netcdf_depends_on
{
    if [[ "$USE_SYSTEM_NETCDF" == "yes" ]]; then
        echo ""
    else
        local depends_on="zlib"
        if [[ "$DO_HDF5" == "yes" ]] ; then
            depends_on="hdf5"        
            if [[ "$DO_SZIP" == "yes" ]] ; then
                depends_on="${depends_on} szip"        
            fi
        fi
        echo ${depends_on}
    fi
}

function bv_netcdf_initialize_vars
{
    if [[ "$USE_SYSTEM_NETCDF" == "no" ]]; then
        NETCDF_INSTALL_DIR="${VISITDIR}/netcdf/$NETCDF_VERSION/${VISITARCH}"
    fi
}

function bv_netcdf_info
{
    export NETCDF_VERSION=${NETCDF_VERSION-"4.1.1"}
    export NETCDF_FILE=${NETCDF_FILE-"netcdf-${NETCDF_VERSION}.tar.gz"}
    export NETCDF_COMPATIBILITY_VERSION=${NETCDF_COMPATIBILITY_VERSION-"4.1"}
    export NETCDF_BUILD_DIR=${NETCDF_BUILD_DIR-"netcdf-4.1.1"}
    export NETCDF_SHA256_CHECKSUM="7933d69d378c57f038375bae4dd78c52442a06e2647fce4b75c13a225e342fb0"
}

function bv_netcdf_print
{
    printf "%s%s\n" "NETCDF_FILE=" "${NETCDF_FILE}"
    printf "%s%s\n" "NETCDF_VERSION=" "${NETCDF_VERSION}"
    printf "%s%s\n" "NETCDF_COMPATIBILITY_VERSION=" "${NETCDF_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "NETCDF_BUILD_DIR=" "${NETCDF_BUILD_DIR}"
}

function bv_netcdf_print_usage
{
    printf "%-20s %s [%s]\n" "--netcdf" "Build NetCDF" "${DO_NETCDF}"
    printf "%-20s %s [%s]\n" "--alt-netcdf-dir" "Use NetCDF from an alternative directory"
}

function bv_netcdf_host_profile
{
    if [[ "$DO_NETCDF" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## NetCDF" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        if [[ "$USE_SYSTEM_NETCDF" == "yes" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_NETCDF_DIR $NETCDF_INSTALL_DIR)" \
                >> $HOSTCONF
        else
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_NETCDF_DIR \${VISITHOME}/netcdf/$NETCDF_VERSION/\${VISITARCH})" \
                >> $HOSTCONF
            if [[ "$DO_HDF5" == "yes" ]] ; then
                echo \
                    "VISIT_OPTION_DEFAULT(VISIT_NETCDF_LIBDEP HDF5_LIBRARY_DIR hdf5_hl HDF5_LIBRARY_DIR hdf5 \${VISIT_HDF5_LIBDEP} TYPE STRING)" \
                    >> $HOSTCONF
            fi
        fi
    fi
}

function bv_netcdf_ensure
{
    if [[ "$DO_NETCDF" == "yes" && "$USE_SYSTEM_NETCDF" == "no" ]] ; then
        ensure_built_or_ready "netcdf" $NETCDF_VERSION $NETCDF_BUILD_DIR \
                              $NETCDF_FILE \
                              http://www.unidata.ucar.edu/downloads/netcdf/ftp/
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_NETCDF="no"
            error "Unable to build NetCDF.  ${NETCDF_FILE} not found."
        fi
    fi
}

function apply_netcdf_411_macOS_patch
{
    patch -p0 << \EOF
diff -c netcdf-4.1.1/ncgen3/orig/genlib.h netcdf-4.1.1/ncgen3/genlib.h 
*** netcdf-4.1.1/ncgen3/orig/genlib.h	Thu Aug 23 21:46:38 2018
--- netcdf-4.1.1/ncgen3/genlib.h	Thu Aug 23 21:07:33 2018
***************
*** 5,10 ****
--- 5,11 ----
   *   See netcdf/COPYRIGHT file for copying and redistribution conditions.
   *   $Header: /upc/share/CVS/netcdf-3/ncgen3/genlib.h,v 1.15 2009/12/29 18:42:35 dmh Exp $
   *********************************************************************/
+ #include <config.h>
  #include <stdlib.h>
  #include <limits.h>
  
EOF
    if [[ $? != 0 ]] ; then
        warn "netcdf 4.1.1 OSX 10.13 patch failed."
        return 1
    fi

    return 0;
}

function apply_netcdf_411_darwin_patch
{
    patch -p0 << \EOF
diff -c netcdf-4.1.1/ncgen3/genlib.h.orig netcdf-4.1.1/ncgen3/genlib.h
*** netcdf-4.1.1/ncgen3/genlib.h.orig   2014-11-13 17:16:23.000000000 -0800
--- netcdf-4.1.1/ncgen3/genlib.h        2014-11-13 16:27:08.000000000 -0800
***************
*** 81,87 ****
  
  /* In case we are missing strlcat */
  #ifndef HAVE_STRLCAT
! extern size_t strlcat(char *dst, const char *src, size_t siz);
  #endif
  
  #ifdef __cplusplus
--- 81,87 ----
  
  /* In case we are missing strlcat */
  #ifndef HAVE_STRLCAT
! /* extern size_t strlcat(char *dst, const char *src, size_t siz); */
  #endif
  
  #ifdef __cplusplus
EOF

    if [[ $? == 0 ]] ; then
        return 0;
    fi

    return 1;
}

function apply_netcdf_patch_for_exodusii
{
    local retval=0
    pushd $NETCDF_BUILD_DIR 1>/dev/null 2>&1
    patch -p0 << \EOF
*** libsrc/netcdf.h     Wed Oct 27 11:50:22 2010
--- libsrc/netcdf.h.ex  Wed Oct 27 11:50:31 2010
***************
*** 141,151 ****
   * applications and utilities.  However, nothing is statically allocated to
   * these sizes internally.
   */
! #define NC_MAX_DIMS   1024     /* max dimensions per file */
! #define NC_MAX_ATTRS  8192     /* max global or per variable attributes */
! #define NC_MAX_VARS   8192     /* max variables per file */
! #define NC_MAX_NAME   256      /* max length of a name */
! #define NC_MAX_VAR_DIMS       NC_MAX_DIMS /* max per variable dimensions */
  
  /*
   * The netcdf version 3 functions all return integer error status.
--- 141,152 ----
   * applications and utilities.  However, nothing is statically allocated to
   * these sizes internally.
   */
! #define NC_MAX_DIMS   65536    /* max dimensions per file */
! #define NC_MAX_ATTRS  8192     /* max global or per variable attributes */
! #define NC_MAX_VARS   524288   /* max variables per file */
! #define NC_MAX_NAME   256      /* max length of a name */
! #define NC_MAX_VAR_DIMS 8      /* max per variable dimensions */
! 
  
  /*
   * The netcdf version 3 functions all return integer error status.
EOF
    retval1=$?
    patch -p0 << \EOF
*** libsrc4/netcdf.h    2010-04-12 11:48:02.000000000 -0700
--- libsrc4/netcdf.h.ex 2011-01-03 15:51:46.000000000 -0800
***************
*** 199,209 ****
   * applications and utilities.  However, nothing is statically allocated to
   * these sizes internally.
   */
! #define NC_MAX_DIMS   1024     /* max dimensions per file */
  #define NC_MAX_ATTRS  8192     /* max global or per variable attributes */
! #define NC_MAX_VARS   8192     /* max variables per file */
  #define NC_MAX_NAME   256      /* max length of a name */
! #define NC_MAX_VAR_DIMS       NC_MAX_DIMS /* max per variable dimensions */
  
  /* In HDF5 files you can set the endianness of variables with
   * nc_def_var_endian(). These defines are used there. */   
--- 199,209 ----
   * applications and utilities.  However, nothing is statically allocated to
   * these sizes internally.
   */
! #define NC_MAX_DIMS   65536    /* max dimensions per file */
  #define NC_MAX_ATTRS  8192     /* max global or per variable attributes */
! #define NC_MAX_VARS   524288   /* max variables per file */
  #define NC_MAX_NAME   256      /* max length of a name */
! #define NC_MAX_VAR_DIMS       8        /* max per variable dimensions */
  
  /* In HDF5 files you can set the endianness of variables with
   * nc_def_var_endian(). These defines are used there. */   
EOF
    retval2=$?
    patch -p0 << \EOF
*** libsrc4/netcdf_base.h       2010-01-21 08:00:18.000000000 -0800
--- libsrc4/netcdf_base.h.ex    2011-01-03 16:03:36.000000000 -0800
***************
*** 192,202 ****
   * applications and utilities.  However, nothing is statically allocated to
   * these sizes internally.
   */
! #define NC_MAX_DIMS   1024     /* max dimensions per file */
  #define NC_MAX_ATTRS  8192     /* max global or per variable attributes */
! #define NC_MAX_VARS   8192     /* max variables per file */
  #define NC_MAX_NAME   256      /* max length of a name */
! #define NC_MAX_VAR_DIMS       NC_MAX_DIMS /* max per variable dimensions */
  
  /* In HDF5 files you can set the endianness of variables with
   * nc_def_var_endian(). These defines are used there. */   
--- 192,202 ----
   * applications and utilities.  However, nothing is statically allocated to
   * these sizes internally.
   */
! #define NC_MAX_DIMS   65536    /* max dimensions per file */
  #define NC_MAX_ATTRS  8192     /* max global or per variable attributes */
! #define NC_MAX_VARS   524288   /* max variables per file */
  #define NC_MAX_NAME   256      /* max length of a name */
! #define NC_MAX_VAR_DIMS       8        /* max per variable dimensions */
  
  /* In HDF5 files you can set the endianness of variables with
   * nc_def_var_endian(). These defines are used there. */   
EOF
    retval3=$?
    popd 1>/dev/null 2>&1
    if [[ $retval1 -eq 0 && $retval2 -eq 0 && $retval3 -eq 0 ]]; then
        return 0
    fi
    return 1
}

function apply_netcdf_strlcat_patch
{
    info "Patching netcdf for strlcat"
    local retval=0
    pushd $NETCDF_BUILD_DIR 1>/dev/null 2>&1
    patch -p0 << \EOF
*** ncgen3/genlib.h.orig	2023-04-14 11:00:05.000000000 -0700
--- ncgen3/genlib.h	2023-04-07 17:04:37.000000000 -0700
*************** extern void nc_fill ( nc_type  type, siz
*** 81,89 ****
--- 81,91 ----
  extern void clearout(void);
  
  /* In case we are missing strlcat */
+ #if 0
  #ifndef HAVE_STRLCAT
  extern size_t strlcat(char *dst, const char *src, size_t siz);
  #endif
+ #endif
  
  #ifdef __cplusplus
  }
EOF
    retval=$?
    popd 1>/dev/null 2>&1

    if [[ $retval != 0 ]] ; then
      warn "netcdf patch for strlcat failed."
      return 1
    fi
    return 0;
}

function apply_netcdf_patch
{
    apply_netcdf_patch_for_exodusii

    if [[ ${NETCDF_VERSION} == 4.1.1 ]] ; then
        if [[ "$OPSYS" == "Darwin" ]] ; then
            productVersion=`sw_vers -productVersion`
            if [[ $productVersion == 10.9.[0-9]* ||
                  $productVersion == 10.10.[0-9]* ||
                  $productVersion == 10.11.[0-9]* ||
                  $productVersion == 10.12.[0-9]* ]] ; then
                info "Applying OS X 10.9 and up patch . . ."
                apply_netcdf_411_darwin_patch
            fi
            
            if [[ $productVersion == 10.13.[0-9]* ||
                  $productVersion == 10.14.[0-9]* || 
                  $productVersion == 10.15.[0-9]* ]] ; then
                info "Applying macOS 10.13 and up patch . . ."
                apply_netcdf_411_macOS_patch
            fi
        fi
    fi
    
    if [[ "$OPSYS" == "Darwin" ]] ; then
        apply_netcdf_strlcat_patch
        if [[ $? != 0 ]] ; then
           return 1
        fi
    fi

    return $?
}

# *************************************************************************** #
#                         Function 8.4, build_netcdf                          #
#                                                                             #
# Mark C. Miller, Wed Oct 27 19:25:09 PDT 2010                                #
# Added patch for exodusII. This way, a single netcdf installation should     #
# work for 'normal' netcdf operations as well as for ExodusII.                #
#                                                                             #
# Kevin Griffin, Mon Nov 17 11:31:52 PST 2014                                 #
# Added patch for OS X 10.9 Mavericks. HAVE_STRLCAT is not getting defined    #
# in this version so its trying to add a duplicate strlcat definition. This   #
# patch comments out the duplicate strlcat definition.                        #
# *************************************************************************** #
function build_netcdf
{
    # Prepare build dir
    #
    prepare_build_dir $NETCDF_BUILD_DIR $NETCDF_FILE
    untarred_netcdf=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_netcdf == -1 ]] ; then
        warn "Unable to prepare NetCDF Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching NetCDF . . ."
    apply_netcdf_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_netcdf == 1 ]] ; then
            warn "Giving up on NetCDF build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Configure NetCDF
    #
    info "Configuring NetCDF . . ."
    cd $NETCDF_BUILD_DIR || error "Can't cd to netcdf build dir."
    info "Invoking command to configure NetCDF"
    EXTRA_FLAGS=""
    if [[ "$OPSYS" == "Darwin" ]]; then
        if [[ "$DO_STATIC_BUILD" == "no" ]]; then
            EXTRA_FLAGS="--enable-largefile --enable-shared --disable-static"
        else
            EXTRA_FLAGS="--enable-largefile"
        fi
    fi
    EXTRA_AC_FLAGS=""
    # detect coral and NVIDIA Grace CPU (ARM) systems, which older versions of 
    # autoconf don't detect
    if [[ "$(uname -m)" == "ppc64le" ]] ; then
         EXTRA_AC_FLAGS="ac_cv_build=powerpc64le-unknown-linux-gnu"
    elif [[ "$(uname -m)" == "aarch64" ]] ; then
         EXTRA_AC_FLAGS="ac_cv_build=aarch64-unknown-linux-gnu"
    fi
    H5ARGS=""
    if [[ "$DO_HDF5" == "yes" ]] ; then
        H5ARGS="--enable-netcdf4"
        H5ARGS="$H5ARGS --with-hdf5=$HDF5_INSTALL_DIR"
        if [[ "$DO_SZIP" == "yes" ]] ; then
            H5ARGS="$H5ARGS --with-szlib=$VISITDIR/szip/$SZIP_VERSION/$VISITARCH"
        fi
    fi
    ZLIBARGS="--with-zlib=$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH"

    C_OPT_FLAGS="-Wno-error=implicit-function-declaration"
    set -x
    env ./configure CXX="$CXX_COMPILER" CC="$C_COMPILER" \
                CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
                FC="" FCFLAGS="" $EXTRA_AC_FLAGS $EXTRA_FLAGS --enable-cxx-4 $H5ARGS $ZLIBARGS \
                --disable-dap --disable-fortran \
                --prefix="$VISITDIR/netcdf/$NETCDF_VERSION/$VISITARCH"
    set +x


    if [[ $? != 0 ]] ; then
        warn "NetCDF configure failed.  Giving up"
        return 1
    fi

    if [[ "$OPSYS" == "Darwin" ]] ; then
        # there is an include file on newer macOS #include <version> which case-clashes
        # with any file living in a dir that is -I included on the compilation line
        mv -f VERSION VERSION.orig

        # Apparently, netCDF is often compiled with undefined refs to methods that should not
        # be used in the current configuration. However, sometimes it won't set the flags needed
        # so the linker will ignore those. Here, we just override libtool with what it would have
        # had specified if it had configured correctly.
        sed -I "" -E -e 's@^allow_undefined_flag="?([^"]*)"?$@allow_undefined_flag="\1 \\${wl}-flat_namespace \\${wl}-undefined \\${wl}suppress"@' libtool
    fi

    #
    # Build NetCDF
    #
    info "Building NetCDF . . . (~2 minutes)"
    $MAKE
    if [[ $? != 0 ]] ; then
        warn "NetCDF build failed.  Giving up"
        return 1
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing NetCDF . . ."
    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "NetCDF install failed.  Giving up"
        return 1
    fi

    #
    # Patch up the library names on Darwin.
    #
    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        info "Creating dynamic libraries for NetCDF . . ."
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/netcdf"
        chgrp -R ${GROUP} "$VISITDIR/netcdf"
    fi
    cd "$START_DIR"
    info "Done with NetCDF"
    return 0
}

function bv_netcdf_is_enabled
{
    if [[ $DO_NETCDF == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_netcdf_is_installed
{
    if [[ "$USE_SYSTEM_NETCDF" == "yes" ]]; then
        return 1
    fi

    check_if_installed "netcdf" $NETCDF_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_netcdf_build
{
    cd "$START_DIR"
    if [[ "$DO_NETCDF" == "yes" && "$USE_SYSTEM_NETCDF" == "no" ]] ; then
        check_if_installed "netcdf" $NETCDF_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping NetCDF build.  NetCDF is already installed."
        else
            info "Building NetCDF (~5 minutes)"
            build_netcdf
            if [[ $? != 0 ]] ; then
                error "Unable to build or install NetCDF.  Bailing out."
            fi
            info "Done building NetCDF"
        fi
    fi
}
function bv_ninja_initialize
{
    export DO_NINJA="no"
    export USE_SYSTEM_NINJA="no"
    add_extra_commandline_args "ninja" "alt-ninja-dir" 1 "Use alternative directory for ninja"
}

function bv_ninja_enable
{
    DO_NINJA="yes"
}

function bv_ninja_disable
{
    DO_NINJA="no"
}

function bv_ninja_alt_ninja_dir
{
    bv_ninja_enable
    USE_SYSTEM_NINJA="yes"
    NINJA_INSTALL_DIR="$1"
    info "Using Alternate ninja: $NINJA_INSTALL_DIR"
}

function bv_ninja_depends_on
{
    depends_on="cmake"

    echo ${depends_on}
}

function bv_ninja_initialize_vars
{
    if [[ "$USE_SYSTEM_NINJA" == "no" ]]; then
        NINJA_INSTALL_DIR="${VISITDIR}/ninja/$NINJA_VERSION/${VISITARCH}"
    fi
}

function bv_ninja_info
{
    export NINJA_VERSION=${NINJA_VERSION:-"1.12.1"}
    export NINJA_FILE=${NINJA_FILE:-"ninja-${NINJA_VERSION}.tar.gz"}
    export NINJA_BUILD_DIR=${NINJA_BUILD_DIR:-"ninja-${NINJA_VERSION}"}
    export NINJA_SHA256_CHECKSUM="821bdff48a3f683bc4bb3b6f0b5fe7b2d647cf65d52aeb63328c91a6c6df285a"
}

function bv_ninja_print
{
    printf "%s%s\n" "NINJA_FILE=" "${NINJA_FILE}"
    printf "%s%s\n" "NINJA_VERSION=" "${NINJA_VERSION}"
    printf "%s%s\n" "NINJA_BUILD_DIR=" "${NINJA_BUILD_DIR}"
}

function bv_ninja_print_usage
{
    printf "%-20s %s [%s]\n" "--ninja" "Build ninja support" "$DO_NINJA"
    printf "%-20s %s [%s]\n" "--alt-ninja-dir" "Use ninja from an alternative directory"
}

function bv_ninja_host_profile
{
    # Nothing added to the host profile since ninja is only used for
    # building third party libraries.
    return 0
}

function bv_ninja_ensure
{
    if [[ "$DO_NINJA" == "yes" && "$USE_SYSTEM_NINJA" == "no" ]] ; then
        ensure_built_or_ready "ninja" $NINJA_VERSION $NINJA_BUILD_DIR $NINJA_FILE $NINJA_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_NINJA="no"
            error "Unable to build ninja. ${NINJA_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_ninja
#
#
# *************************************************************************** #
function build_ninja
{
    #
    # Prepare build dir
    #
    prepare_build_dir $NINJA_BUILD_DIR $NINJA_FILE
    untarred_ninja=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_ninja == -1 ]] ; then
        warn "Unable to prepare ninja build directory. Giving Up!"
        return 1
    fi

    #
    # Configure NINJA
    #
    info "Configuring ninja . . ."

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"

    cd $NINJA_BUILD_DIR || error "Can't cd to ninja build dir."

    vopts=""
    vopts="${vopts} -DCMAKE_INSTALL_PREFIX:PATH=${VISITDIR}/ninja/${NINJA_VERSION}/${VISITARCH}"
    vopts="${vopts} -DBUILD_TESTING:BOOL=OFF"
    vopts="${vopts} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\"" ${vopts} . > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "ninja configuration failed."

    #
    # Build ninja
    #
    info "Building ninja . . . (~2 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS  || error "Ninja did not build correctly. Giving up."

    info "Installing Ninja . . . (~2 minutes)"
    ${CMAKE_COMMAND} --install . || error "Ninja did not install correctly."

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/ninja"
        chgrp -R ${GROUP} "$VISITDIR/ninja"
    fi
    cd "$START_DIR"
    info "Done with ninja"
    return 0
}

function bv_ninja_is_enabled
{
    if [[ $DO_NINJA == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_ninja_is_installed
{
    if [[ "$USE_SYSTEM_NINJA" == "yes" ]]; then
        return 1
    fi

    check_if_installed "ninja" $NINJA_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_ninja_build
{
    cd "$START_DIR"
    if [[ "$DO_NINJA" == "yes" && "$USE_SYSTEM_NINJA" == "no" ]] ; then
        check_if_installed "ninja" $NINJA_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping ninja build. Ninja is already installed."
        else
            info "Building ninja (~2 minutes)"
            build_ninja
            if [[ $? != 0 ]] ; then
                error "Unable to build or install ninja.  Bailing out."
            fi
            info "Done building ninja"
        fi
    fi
}
function bv_openexr_initialize
{
    export DO_OPENEXR="no"
}

function bv_openexr_enable
{
    DO_OPENEXR="yes"
}

function bv_openexr_disable
{
    DO_OPENEXR="no"
}

function bv_openexr_depends_on
{
    echo "cmake"
}

function bv_openexr_info
{
    export OPENEXR_VERSION=${OPENEXR_VERSION:-"3.3.4"}
    export OPENEXR_FILE=${OPENEXR_FILE:-"openexr-${OPENEXR_VERSION}.tar.gz"}
    export OPENEXR_COMPATIBILITY_VERSION=${OPENEXR_COMPATIBILITY_VERSION:-"3.3"}
    export OPENEXR_BUILD_DIR=${OPENEXR_BUILD_DIR:-"openexr-${OPENEXR_VERSION}"}
    export OPENEXR_SHA256_CHECKSUM="73a6d83edcc68333afb95e133f6e12012073815a854bc41abc1a01c1db5f124c"

    export IMATH_VERSION=${IMATH_VERSION:-"3.1.12"}
    export IMATH_FILE=${IMATH_FILE:-"Imath-${IMATH_VERSION}.tar.gz"}
    export IMATH_COMPATIBILITY_VERSION=${IMATH_COMPATIBILITY_VERSION:-"3.1"}
    export IMATH_BUILD_DIR=${IMATH_BUILD_DIR:-"Imath-${IMATH_VERSION}"}
    export IMATH_SHA256_CHECKSUM="cb8ca9ca77ac4338ebbee911fc90c886011ac5b00088630bacf8ef6c6e522f0a"
}

function bv_openexr_print
{
    printf "%s%s\n" "OPENEXR_FILE=" "${OPENEXR_FILE}"
    printf "%s%s\n" "OPENEXR_VERSION=" "${OPENEXR_VERSION}"
    printf "%s%s\n" "OPENEXR_COMPATIBILITY_VERSION=" "${OPENEXR_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "OPENEXR_BUILD_DIR=" "${OPENEXR_BUILD_DIR}"

    printf "%s%s\n" "IMATH_FILE=" "${IMATH_FILE}"
    printf "%s%s\n" "IMATH_VERSION=" "${IMATH_VERSION}"
    printf "%s%s\n" "IMATH_COMPATIBILITY_VERSION=" "${IMATH_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "IMATH_BUILD_DIR=" "${IMATH_BUILD_DIR}"
}

function bv_openexr_host_profile
{
    if [[ "$DO_OPENEXR" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## OpenEXR" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "SETUP_APP_VERSION(OPENEXR $OPENEXR_VERSION)" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_OPENEXR_DIR \${VISITHOME}/openexr/$OPENEXR_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi
}

function bv_openexr_print_usage
{
    #openexr does not have an option, it is only dependent on openexr.
    printf "%-20s %s [%s]\n" "--openexr" "Build OpenEXR" "$DO_OPENEXR"
}

function bv_openexr_ensure
{
    if [[ "$DO_OPENEXR" == "yes" ]] ; then
        ensure_built_or_ready "openexr" $OPENEXR_VERSION $OPENEXR_BUILD_DIR $OPENEXR_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_OPENEXR="no"
            error "Unable to build OpenEXR.  ${OPENEXR_FILE} not found."
        fi
        ensure_built_or_ready "openexr" $IMATH_VERSION $IMATH_BUILD_DIR $IMATH_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_OPENEXR="no"
            error "Unable to build OpenEXR.  ${IMATH_FILE} not found."
        fi
    fi
}

# ***************************************************************************
# build_imath
#
# Modifications:
#
# ***************************************************************************

function build_imath
{
    #
    # Prepare build dir
    #
    prepare_build_dir $IMATH_BUILD_DIR $IMATH_FILE
    untarred_imath=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_imath == -1 ]] ; then
        warn "Unable to prepare Imath Build Directory. Giving Up"
        return 1
    fi

    # Make a build directory for an out-of-source build. Change the
    # IMATH_BUILD_DIR variable to represent the out-of-source build directory.
    IMATH_SRC_DIR=$IMATH_BUILD_DIR
    IMATH_BUILD_DIR="${IMATH_SRC_DIR}-build"
    if [[ ! -d $IMATH_BUILD_DIR ]] ; then
        echo "Making build directory $IMATH_BUILD_DIR"
        mkdir $IMATH_BUILD_DIR
    fi

   
    #
    # Configure Imath
    #
    cd $IMATH_BUILD_DIR || error "Can't cd to Imath build dir."

    #
    # Remove the CMakeCache.txt files ... existing files sometimes prevent
    # fields from getting overwritten properly.
    #
    rm -Rf ${IMATH_BUILD_DIR}/CMakeCache.txt 

    imathopts=""
    imathopts="${imathopts} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"

    if test "x${DO_STATIC_BUILD}" == "xyes" ; then
        imathopts="${imathopts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
        imathopts="${imathopts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi

    imathopts="${imathopts} -DBUILD_TESTING:BOOL=OFF"
    imathopts="${imathopts} -DCMAKE_INSTALL_PREFIX:PATH=${VISITDIR}/openexr/${OPENEXR_VERSION}/${VISITARCH}"

    imathopts="${imathopts} -DIMATH_CXX_STANDARD:STRING=17"
    imathopts="${imathopts} -DIMATH_OUTPUT_SUBDIR:STRING="
    imathopts="${imathopts} -DIMATH_INSTALL_PKG_CONFIG:BOOL=OFF"

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_INSTALL}/cmake\"" ${imathopts} ../${IMATH_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "Imath configuration failed."

    #
    # Build Imath
    #
    info "Building Imath . . . (~1 minutes)"

    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Imath build failed.  Giving up"
        return 1
    fi
    info "Installing Imath . . ."

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "Imath build (make install) failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/openexr"
        chgrp -R ${GROUP} "$VISITDIR/openexr"
    fi
    cd "$START_DIR"
    info "Done with Imath"
    return 0
}

# ***************************************************************************
# build_openexr
#
# Modifications:
#
# ***************************************************************************


function apply_openexr_cmakelists_patch
{
    info "Patching OpenEXR to disable website/src which fails to compile with gcc 10"
    patch -p0 << \EOF
--- CMakeLists.txt.orig	2025-07-07 08:28:50.888000000 -0700
+++ CMakeLists.txt	2025-07-07 08:28:18.097045000 -0700
@@ -146,10 +146,10 @@
   add_subdirectory(website)
 endif()
 
-if (OPENEXR_BUILD_LIBS AND NOT OPENEXR_IS_SUBPROJECT)
+#if (OPENEXR_BUILD_LIBS AND NOT OPENEXR_IS_SUBPROJECT)
   # Even if not building the website, still make sure the website example code compiles.
-  add_subdirectory(website/src)
-endif()
+#  add_subdirectory(website/src)
+#endif()
 
 if (OPENEXR_BUILD_PYTHON AND OPENEXR_BUILD_LIBS AND NOT OPENEXR_IS_SUBPROJECT)
   add_subdirectory(src/wrappers/python)
EOF
    if [[ $? != 0 ]] ; then
        warn "OpenEXR patch for CMakeLists.txt failed."
        return 1
    fi

    return 0;
}

function apply_openexr_patch
{
    if [[ ${OPENEXR_VERSION} == 3.3.4 ]] ; then
        apply_openexr_cmakelists_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0;
}


function build_openexr
{
    #
    # Prepare build dir
    #
    prepare_build_dir $OPENEXR_BUILD_DIR $OPENEXR_FILE
    untarred_openexr=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_openexr == -1 ]] ; then
        warn "Unable to prepare OpenEXR Build Directory. Giving Up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching OpenEXR . . ."
    cd $OPENEXR_BUILD_DIR
    apply_openexr_patch

    if [[ $? != 0 ]] ; then
        if [[ $untarred_openexr == 1 ]] ; then
            warn "Giving up on OpenEXR build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi
    cd ../

    # Make a build directory for an out-of-source build. Change the
    # OPENEXR_BUILD_DIR variable to represent the out-of-source build directory.
    OPENEXR_SRC_DIR=$OPENEXR_BUILD_DIR
    OPENEXR_BUILD_DIR="${OPENEXR_SRC_DIR}-build"
    if [[ ! -d $OPENEXR_BUILD_DIR ]] ; then
        echo "Making build directory $OPENEXR_BUILD_DIR"
        mkdir $OPENEXR_BUILD_DIR
    fi

   
    #
    # Configure OpenEXR
    #
    cd $OPENEXR_BUILD_DIR || error "Can't cd to Imath build dir."

    #
    # Remove the CMakeCache.txt files ... existing files sometimes prevent
    # fields from getting overwritten properly.
    #
    rm -Rf ${OPENEXR_BUILD_DIR}/CMakeCache.txt 

    openexr_dir="${VISITDIR}/openexr/${OPENEXR_VERSION}/${VISITARCH}"
    openexropts="-DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"

    if test "x${DO_STATIC_BUILD}" = "xyes"; then
        openexropts="${openexropts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
        openexropts="${openexropts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi
    openexropts="${openexropts} -DBUILD_TESTING:BOOL=OFF"
    openexropts="${openexropts} -DCMAKE_INSTALL_PREFIX:PATH=${openexr_dir}"

    openexropts="${openexropts} -DOPENEXR_BUILD_EXAMPLES:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_BUILD_TOOLS:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_BUILD_TOOLS:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_INSTALL_PKG_CONFIG:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_INSTALL_TOOLS:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_OUTPUT_SUBDIR:STRING="
    openexropts="${openexropts} -DOPENEXR_TEST_LIBRARIES:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_TEST_PYTHON:BOOL=OFF"
    openexropts="${openexropts} -DOPENEXR_TEST_TOOLS:BOOL=OFF"

    openexropts="${openexropts} -DFETCHCONTENT_FULL_DISCONNECTED:BOOL=ON"
    if [[ -d ${openexr_dir}/lib64/cmake ]] ; then
        openexropts="${openexropts} -DImath_DIR:PATH=${openexr_dir}/lib64/cmake"
    else
        openexropts="${openexropts} -DImath_DIR:PATH=${openexr_dir}/lib/cmake"
    fi

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_INSTALL}/cmake\"" ${openexropts} ../${OPENEXR_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "OpenEXR configuration failed."
    
    #
    # Build OpenEXR
    #
    info "Building OpenEXR . . . (~5 minutes)"

    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "OpenEXR build failed.  Giving up"
        return 1
    fi
    info "Installing OpenEXR . . ."

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "OpenEXR build (make install) failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/openexr"
        chgrp -R ${GROUP} "$VISITDIR/openexr"
    fi
    cd "$START_DIR"
    info "Done with OpenEXR"
    return 0
}

function bv_openexr_is_enabled
{
    if [[ $DO_OPENEXR == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_openexr_is_installed
{
    check_if_installed "openexr" $OPENEXR_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_openexr_build
{
    if [[ "$DO_OPENEXR" == "yes" ]] ; then
        check_if_installed "openexr" $OPENEXR_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping build of OpenEXR"
        else
            build_imath
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Imath for OpenEXR.  Bailing out."
            fi
            info "Done building Imath"
            build_openexr
            if [[ $? != 0 ]] ; then
                error "Unable to build or install OpenEXR.  Bailing out."
            fi
            info "Done building OpenEXR"
        fi
    fi
}

function bv_osmesa_initialize
{
    export DO_OSMESA="yes"
}

function bv_osmesa_enable
{
    DO_OSMESA="yes"
}

function bv_osmesa_disable
{
    DO_OSMESA="no"
}

function bv_osmesa_depends_on
{
    echo "llvm"
}

function bv_osmesa_info
{
    export OSMESA_VERSION=${OSMESA_VERSION:-"17.3.9"}
    export OSMESA_FILE=${OSMESA_FILE:-"mesa-$OSMESA_VERSION.tar.xz"}
    export OSMESA_BUILD_DIR=${OSMESA_BUILD_DIR:-"mesa-$OSMESA_VERSION"}
    export OSMESA_SHA256_CHECKSUM="c5beb5fc05f0e0c294fefe1a393ee118cb67e27a4dca417d77c297f7d4b6e479"
}

function bv_osmesa_print
{
    printf "%s%s\n" "OSMESA_FILE=" "${OSMESA_FILE}"
    printf "%s%s\n" "OSMESA_VERSION=" "${OSMESA_VERSION}"
    printf "%s%s\n" "OSMESA_BUILD_DIR=" "${OSMESA_BUILD_DIR}"
}

function bv_osmesa_print_usage
{
    printf "%-20s %s [%s]\n" "--osmesa" "Build OSMesa" "$DO_OSMESA"
}

function bv_osmesa_host_profile
{
    # If we are using osmesa as the GL for VTK in a static build, we'll tell
    # VisIt about osmesa using a different mechanism.
    addhp="yes"
    if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
        if [[ "$DO_SERVER_COMPONENTS_ONLY" == "yes" || "$DO_ENGINE_ONLY" == "yes" ]] ; then
            addhp="no"
        fi
    fi

    if [[ "$DO_OSMESA" == "yes" && "$addhp" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## OSMesa" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_OSMESA_DIR \${VISITHOME}/osmesa/$OSMESA_VERSION/\${VISITARCH})" >> $HOSTCONF
    fi
}

function bv_osmesa_selected
{
    args=$@
    if [[ $args == "--osmesa" ]]; then
        DO_OSMESA="yes"
        return 1
    fi

    return 0
}

function bv_osmesa_initialize_vars
{
    info "initalizing osmesa vars"
    if [[ "$DO_OSMESA" == "yes" ]]; then
        OSMESA_INSTALL_DIR="${VISITDIR}/osmesa/${OSMESA_VERSION}/${VISITARCH}"
        OSMESA_INCLUDE_DIR="${OSMESA_INSTALL_DIR}/include"
        OSMESA_LIB_DIR="${OSMESA_INSTALL_DIR}/lib"
        if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
            OSMESA_LIB="${OSMESA_LIB_DIR}/libOSMesa.a"
        else
            OSMESA_LIB="${OSMESA_LIB_DIR}/libOSMesa.${SO_EXT}"
        fi
    fi
}

function bv_osmesa_ensure
{
    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        if [[ "$DO_OSMESA" == "yes" ]] ; then
            ensure_built_or_ready "osmesa"   $OSMESA_VERSION   $OSMESA_BUILD_DIR   $OSMESA_FILE $OSMESA_URL
            if [[ $? != 0 ]] ; then
                return 1
            fi
        fi
    fi
}

function apply_osmesa_patch
{
    patch -p0 << \EOF
diff -c configure.ac.orig configure.ac
*** configure.ac.orig   Mon Jul 13 09:47:20 2020
--- configure.ac        Mon Jul 13 09:50:37 2020
***************
*** 2653,2659 ****
      dnl ourselves.
      dnl (See https://llvm.org/bugs/show_bug.cgi?id=6823)
      dnl We can't use $LLVM_VERSION because it has 'svn' stripped out,
!     LLVM_SO_NAME=LLVM-`$LLVM_CONFIG --version`
      AS_IF([test -f "$LLVM_LIBDIR/lib$LLVM_SO_NAME.$IMP_LIB_EXT"], [llvm_have_one_so=yes])

      if test "x$llvm_have_one_so" = xyes; then
--- 2653,2659 ----
      dnl ourselves.
      dnl (See https://llvm.org/bugs/show_bug.cgi?id=6823)
      dnl We can't use $LLVM_VERSION because it has 'svn' stripped out,
!     LLVM_SO_NAME=LLVM-$LLVM_VERSION
      AS_IF([test -f "$LLVM_LIBDIR/lib$LLVM_SO_NAME.$IMP_LIB_EXT"], [llvm_have_one_so=yes])

      if test "x$llvm_have_one_so" = xyes; then
EOF

    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 1 failed."
        return 1
    fi

    #
    # Patch so that displaying graphics to the XWin-32 2018 X server
    # works properly.
    #
    patch -p0 << \EOF
diff -c src/gallium/winsys/sw/xlib/xlib_sw_winsys.c.orig src/gallium/winsys/sw/xlib/xlib_sw_winsys.c
*** src/gallium/winsys/sw/xlib/xlib_sw_winsys.c.orig    Thu Mar  4 13:12:20 2021
--- src/gallium/winsys/sw/xlib/xlib_sw_winsys.c Thu Mar  4 13:14:11 2021
***************
*** 396,401 ****
--- 396,402 ----
  {
     struct xlib_displaytarget *xlib_dt;
     unsigned nblocksy, size;
+    int ignore;
  
     xlib_dt = CALLOC_STRUCT(xlib_displaytarget);
     if (!xlib_dt)
***************
*** 410,416 ****
     xlib_dt->stride = align(util_format_get_stride(format, width), alignment);
     size = xlib_dt->stride * nblocksy;
  
!    if (!debug_get_option_xlib_no_shm()) {
        xlib_dt->data = alloc_shm(xlib_dt, size);
        if (xlib_dt->data) {
           xlib_dt->shm = True;
--- 411,418 ----
     xlib_dt->stride = align(util_format_get_stride(format, width), alignment);
     size = xlib_dt->stride * nblocksy;
  
!    if (!debug_get_option_xlib_no_shm() &&
!        XQueryExtension(xlib_dt->display, "MIT-SHM", &ignore, &ignore, &ignore)) {
        xlib_dt->data = alloc_shm(xlib_dt, size);
        if (xlib_dt->data) {
           xlib_dt->shm = True;
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 2 failed."
        return 1
    fi

    #
    # Patch so that building with gcc-10 will work.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/swr/rasterizer/common/os.h.orig src/gallium/drivers/swr/rasterizer/common/os.h
--- src/gallium/drivers/swr/rasterizer/common/os.h.orig 2021-06-28 08:51:12.252643000 -0700
+++ src/gallium/drivers/swr/rasterizer/common/os.h      2021-06-28 08:55:32.676722000 -0700
@@ -166,14 +166,15 @@
 #endif
 
 #if !defined( __clang__) && !defined(__INTEL_COMPILER)
-// Intrinsic not defined in gcc
+// Intrinsic not defined in gcc < 10
+#if (__GNUC__) && (GCC_VERSION < 100000)
 static INLINE
 void _mm256_storeu2_m128i(__m128i *hi, __m128i *lo, __m256i a)
 {
     _mm_storeu_si128((__m128i*)lo, _mm256_castsi256_si128(a));
     _mm_storeu_si128((__m128i*)hi, _mm256_extractf128_si256(a, 0x1));
 }
-
+#endif
 // gcc prior to 4.9 doesn't have _mm*_undefined_*
 #if (__GNUC__) && (GCC_VERSION < 409000)
 #define _mm_undefined_si128 _mm_setzero_si128
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 3 failed."
        return 1
    fi

    #
    # Patch to increase the maximum image size in the llvmpipe
    # driver to 32K x 32K. There are 2 changes. The first is to
    # the number of 2D levels to 16 (2^(16-1)) = 32K. The second is
    # to the maximum texture size - 32768 x 32768 is the maximum
    # number of pixels, the 4 is 4 bytes per pixel, and the 2 is from
    # the fact that a texture can actually store a multi-resolution
    # representation of the image. For example if the image size
    # is 256x256, it has storage for textures of size 256x256,
    # 128x128, 64x64, 32x32, 16x16, 8x8, 4x4, 2x2 and 1x1.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/llvmpipe/lp_limits.h.orig src/gallium/drivers/llvmpipe/lp_limits.h
--- src/gallium/drivers/llvmpipe/lp_limits.h.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/gallium/drivers/llvmpipe/lp_limits.h	2024-11-13 13:47:04.388202316 -0800
@@ -43,8 +43,8 @@
 /**
  * Max texture sizes
  */
-#define LP_MAX_TEXTURE_SIZE (1 * 1024 * 1024 * 1024ULL)  /* 1GB for now */
-#define LP_MAX_TEXTURE_2D_LEVELS 14  /* 8K x 8K for now */
+#define LP_MAX_TEXTURE_SIZE (2 * 4 * 32768 * 32768ULL)  /* 8GB for now */
+#define LP_MAX_TEXTURE_2D_LEVELS 16  /* 32K x 32K for now */
 #define LP_MAX_TEXTURE_3D_LEVELS 12  /* 2K x 2K x 2K for now */
 #define LP_MAX_TEXTURE_CUBE_LEVELS 14  /* 8K x 8K for now */
 #define LP_MAX_TEXTURE_ARRAY_LAYERS 512 /* 8K x 512 / 8K x 8K x 512 */
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 4 failed."
        return 1
    fi

    #
    # Patch to increase the maximum scene temporary storage in the llvmpipe
    # driver. This is required for large image sizes.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/llvmpipe/lp_scene.h.orig src/gallium/drivers/llvmpipe/lp_scene.h
--- src/gallium/drivers/llvmpipe/lp_scene.h.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/gallium/drivers/llvmpipe/lp_scene.h	2024-11-13 13:57:33.700075750 -0800
@@ -60,12 +60,12 @@

 /* Scene temporary storage is clamped to this size:
  */
-#define LP_SCENE_MAX_SIZE (9*1024*1024)
+#define LP_SCENE_MAX_SIZE (256*1024*1024)

 /* The maximum amount of texture storage referenced by a scene is
  * clamped to this size:
  */
-#define LP_SCENE_MAX_RESOURCE_SIZE (64*1024*1024)
+#define LP_SCENE_MAX_RESOURCE_SIZE (256*1024*1024)


 /* switch to a non-pointer value for this:
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 5 failed."
        return 1
    fi

    #
    # Patch to increase the maximum image size in mesa to 32K x 32K.
    #
    patch -p0 << \EOF
diff -u src/mesa/main/config.h.orig src/mesa/main/config.h
--- src/mesa/main/config.h.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/mesa/main/config.h	2024-11-13 14:00:35.358860569 -0800
@@ -91,19 +91,19 @@
 #define LINE_WIDTH_GRANULARITY 0.1

 /** Max memory to allow for a single texture image (in megabytes) */
-#define MAX_TEXTURE_MBYTES 1024
+#define MAX_TEXTURE_MBYTES 8196

 /** Number of 1D/2D texture mipmap levels */
-#define MAX_TEXTURE_LEVELS 15
+#define MAX_TEXTURE_LEVELS 16

 /** Number of 3D texture mipmap levels */
-#define MAX_3D_TEXTURE_LEVELS 15
+#define MAX_3D_TEXTURE_LEVELS 16

 /** Number of cube texture mipmap levels - GL_ARB_texture_cube_map */
-#define MAX_CUBE_TEXTURE_LEVELS 15
+#define MAX_CUBE_TEXTURE_LEVELS 16

 /** Maximum rectangular texture size - GL_NV_texture_rectangle */
-#define MAX_TEXTURE_RECT_SIZE 16384
+#define MAX_TEXTURE_RECT_SIZE 32768

 /**
  * Maximum number of layers in a 1D or 2D array texture - GL_MESA_texture_array
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 6 failed."
        return 1
    fi

    #
    # Patch to fix an arithmetic overflow error calculating the size
    # of a texture.
    #
    patch -p0 << \EOF
diff -u src/gallium/drivers/llvmpipe/lp_texture.c.orig src/gallium/drivers/llvmpipe/lp_texture.c
--- src/gallium/drivers/llvmpipe/lp_texture.c.orig	2018-04-18 01:44:00.000000000 -0700
+++ src/gallium/drivers/llvmpipe/lp_texture.c	2024-11-13 14:17:18.979693408 -0800
@@ -155,7 +155,7 @@

       lpr->mip_offsets[level] = total_size;

-      total_size += align((unsigned)mipsize, mip_align);
+      total_size += align64(mipsize, mip_align);
       if (total_size > LP_MAX_TEXTURE_SIZE) {
          goto fail;
       }
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 7 failed."
        return 1
    fi

    # Patch to address VTK texture buffer error.
    # Taken from https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/9750
    #
    patch -p0 << \EOF
diff -c src/gallium/drivers/llvmpipe/lp_screen.c.orig src/gallium/drivers/llvmpipe/lp_screen.c
*** src/gallium/drivers/llvmpipe/lp_screen.c.orig        Fri Dec 15 14:33:53 PST 2023
--- src/gallium/drivers/llvmpipe/lp_screen.c     Fri Dec 15 14:33:53 PST 2023
***************
*** 236,242 ****
     case PIPE_CAP_TEXTURE_BUFFER_OBJECTS:
        return 1;
     case PIPE_CAP_MAX_TEXTURE_BUFFER_SIZE:
!       return 65536;
     case PIPE_CAP_TEXTURE_BUFFER_OFFSET_ALIGNMENT:
        return 1;
     case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
--- 236,242 ----
     case PIPE_CAP_TEXTURE_BUFFER_OBJECTS:
        return 1;
     case PIPE_CAP_MAX_TEXTURE_BUFFER_SIZE:
!       return 134217728;
     case PIPE_CAP_TEXTURE_BUFFER_OFFSET_ALIGNMENT:
        return 1;
     case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
EOF
    if [[ $? != 0 ]] ; then
        warn "OSMesa patch 6 failed."
        return 1
    fi

    return 0;
}

function build_osmesa
{
    #
    # prepare build dir
    #
    prepare_build_dir $OSMESA_BUILD_DIR $OSMESA_FILE
    untarred_osmesa=$?
    if [[ $untarred_osmesa == -1 ]] ; then
        warn "Unable to prepare Mesa build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    cd $OSMESA_BUILD_DIR || error "Couldn't cd to osmesa build dir."

    info "Patching OSMesa"
    apply_osmesa_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_osmesa == 1 ]] ; then
            warn "Giving up on OSMesa build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Handle case where python doesn't exist.
    # The magic to determine if python exist comes from
    # https://stackoverflow.com/questions/592620/how-can-i-check-if-a-program-exists-from-a-bash-script
    #
    if ! command -v python > /dev/null 2>&1 ; then
        sed -i "s/python2.7/python3 python2.7/" configure.ac
    fi

    #
    # Build OSMESA.
    #
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        OSMESA_STATIC_DYNAMIC="--disable-shared --disable-shared-glapi --enable-static --enable-static-glapi"
    fi
    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        OSMESA_DEBUG_BUILD="--enable-debug"
    fi
    if [[ "$(uname -m)" == "x86_64" ]] ; then
        OSMESA_GALLIUM_DRIVERS="swrast,swr"
    else
        OSMESA_GALLIUM_DRIVERS="swrast"
    fi

    info "Configuring OSMesa . . ."
    # add -fcommon if gcc >=10 to work around changes in compiler behavior
    # see: https://wiki.gentoo.org/wiki/Project:Toolchain/Gcc_10_porting_notes/fno_common
    # otherwise we would need to patch mesa to fix build problems

    osmesa_c_opt_flags=""
    if [[ "$CXX_COMPILER" == "g++" ]] ; then
        VERSION=$(g++ -v 2>&1 | grep "gcc version" | cut -d' ' -f3 | cut -d'.' -f1-1)
        if [[ ${VERSION} -ge 10 ]] ; then
            osmesa_c_opt_flags="-fcommon"
        fi
    fi

    set -x
    env CXXFLAGS="${CXXFLAGS} ${CXX_OPT_FLAGS}" \
        CXX=${CXX_COMPILER} \
        CFLAGS="${CFLAGS} ${C_OPT_FLAGS} ${osmesa_c_opt_flags}" \
        CC=${C_COMPILER} \
        ./autogen.sh \
        --prefix=${VISITDIR}/osmesa/${OSMESA_VERSION}/${VISITARCH} \
        --disable-gles1 \
        --disable-gles2 \
        --disable-dri \
        --disable-dri3 \
        --disable-glx \
        --disable-glx-tls \
        --disable-egl \
        --disable-gbm \
        --disable-xvmc \
        --disable-vdpau \
        --disable-va \
        --with-platforms= \
        --enable-llvm \
        --with-gallium-drivers=${OSMESA_GALLIUM_DRIVERS} \
        --enable-gallium-osmesa $OSMESA_STATIC_DYNAMIC $OSMESA_DEBUG_BUILD \
        --disable-llvm-shared-libs \
        --with-llvm-prefix=${VISIT_LLVM_DIR}
    set +x

    if [[ $? != 0 ]] ; then
        warn "OSMesa configure failed.  Giving up"
        return 1
    fi

    info "Building OSMesa . . ."
    ${MAKE} ${MAKE_OPT_FLAGS}
    if [[ $? != 0 ]] ; then
        warn "OSMesa build failed.  Giving up"
        return 1
    fi

    info "Installing OSMesa ..."
    ${MAKE} ${MAKE_OPT_FLAGS} install
    if [[ $? != 0 ]] ; then
        warn "OSMesa install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/osmesa"
        chgrp -R ${GROUP} "$VISITDIR/osmesa"
    fi
    cd "$START_DIR"
    info "Done with OSMesa"
    return 0
}

function bv_osmesa_is_enabled
{
    if [[ $DO_OSMESA == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_osmesa_is_installed
{
    check_if_installed "osmesa" $OSMESA_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_osmesa_build
{
    #
    # Build OSMesa
    #
    cd "$START_DIR"
    if [[ "$DO_OSMESA" == "yes" ]] ; then
        check_if_installed "osmesa" $OSMESA_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping OSMesa build.  OSMesa is already installed."
            return 0
        fi
        check_if_installed "mesagl" $MESAGL_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping OSMesa build.  MesaGL is already installed."
        else
            info "Building OSMesa (~20 minutes)"
            build_osmesa
            if [[ $? != 0 ]] ; then
                error "Unable to build or install OSMesa.  Bailing out."
            fi
            info "Done building OSMesa"
        fi
    fi
}
function bv_ospray_initialize
{
    export DO_OSPRAY="no"
    export USE_SYSTEM_OSPRAY="no"
    export OSPRAY_CONFIG_DIR=""
    add_extra_commandline_args "ospray" "system-ospray" 0 "Using system OSPRay (exp)"
    add_extra_commandline_args "ospray" "alt-ospray-dir" 1 "Use alternate OSPRay (exp)"
}

function bv_ospray_enable
{
    DO_OSPRAY="yes"
}

function bv_ospray_disable
{
    DO_OSPRAY="no"
}

function bv_ospray_system_ospray
{
    TEST=`which ospray-config`
    [ $? != 0 ] && error "System ospray-config not found, cannot configure ospray"
    bv_ospray_enable
    USE_SYSTEM_OSPRAY="yes"
    OSPRAY_INSTALL_DIR="$1"
    info "Using System OSPRAY: $OSPRAY_INSTALL_DIR"
}

function bv_ospray_alt_ospray_dir
{
    bv_ospray_enable
    USE_SYSTEM_OSPRAY="yes"
    OSPRAY_INSTALL_DIR="$1"
    info "Using Alternate OSPRAY: $OSPRAY_INSTALL_DIR"
}

function bv_ospray_check_openmp
{
    _OPENMP=$(echo | cpp -fopenmp -dM | grep -i open)
    if [[ "$_OPENMP" == "#define _OPENMP"* ]]; then
        return 0
    fi
    return -1
}

function bv_ospray_depends_on
{
    depends_on="cmake"

    echo ${depends_on}
}

function bv_ospray_info
{
    if [[ "$OPSYS" == "Darwin" ]]; then
        export OSPRAY_VERSION=${OSPRAY_VERSION:-"3.2.0"}
        if [[ "$(uname -m)" == "x86_64" ]]; then
            export OSPRAY_FILE=${OSPRAY_FILE:-"ospray-${OSPRAY_VERSION}.x86_64.macosx.zip"}
            export OSPRAY_SHA256_CHECKSUM="073587a9fe4f985086e8d1e1c4749860ae81259e4806fe9475792e7864fe0e9c"
        elif [[ "$(uname -m)" == "arm64" ]]; then
            export OSPRAY_FILE=${OSPRAY_FILE:-"ospray-${OSPRAY_VERSION}.arm64.macosx.zip"}
            export OSPRAY_SHA256_CHECKSUM="adcaf17e4ed4e98d707a49b07e6ad833029ccff24f45ce3ae33c73254f1ca6a7"
        fi
        # This isn't really a "source" dir because its pre-built binaries we're dealing with
        export OSPRAY_SRC_DIR=${OSPRAY_SRC_DIR:-"${OSPRAY_FILE%.zip*}"}
        export OSPRAY_BUILD_DIR=${OSPRAY_BUILD_DIR:-"${OSPRAY_SRC_DIR}-build"}
    else
        export OSPRAY_VERSION=${OSPRAY_VERSION:-"3.0.0"}
        export OSPRAY_FILE=${OSPRAY_FILE:-"ospray-${OSPRAY_VERSION}.tar.gz"}
        export OSPRAY_SRC_DIR=${OSPRAY_SRC_DIR:-"${OSPRAY_FILE%.tar*}"}
        export OSPRAY_BUILD_DIR=${OSPRAY_BUILD_DIR:-"${OSPRAY_SRC_DIR}-build"}
        export OSPRAY_SHA256_CHECKSUM="d8d8e632d77171c810c0f38f8d5c8387470ca19b75f5b80ad4d3d12007280288"
        export OSPRAY_LIBS_FILE=${OSPRAY_LIBS_FILE:-"ospray-libs-${OSPRAY_VERSION}.tar.gz"}
        export OSPRAY_LIBS_DIR=${OSPRAY_LIBS_DIR:-"${OSPRAY_LIBS_FILE%.tar*}"}
        export OSPRAY_LIBS_SHA256_CHECKSUM="8ab33df7ea88d7eb3b9170fc3b6342e77cd105d9549db8bce31cddd5a0336f2f"
    fi
}

function bv_ospray_print
{
    print "%s%s\n" "OSPRAY_FILE=" "${OSPRAY_FILE}"
    print "%s%s\n" "OSPRAY_VERSION=" "${OSPRAY_VERSION}"
    print "%s%s\n" "OSPRAY_SRC_DIR=" "${OSPRAY_SRC_DIR}"
    print "%s%s\n" "OSPRAY_BUILD_DIR=" "${OSPRAY_BUILD_DIR}"
}

function bv_ospray_print_usage
{
    printf "%-20s %s\n" "--ospray" "Build OSPRAY"
    printf "%-20s %s [%s]\n" "--system-ospray" "Use the system installed OSPRAY"
    printf "%-20s %s [%s]\n" "--alt-ospray-dir" "Use OSPRAY from an alternative directory"

}

function bv_ospray_host_profile
{
    if [[ "$DO_OSPRAY" == "yes" ]]; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## OSPRay" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        if [[ "$USE_SYSTEM_OSPRAY" == "no" ]]; then
            echo "SETUP_APP_VERSION(OSPRAY ${OSPRAY_VERSION})" >> $HOSTCONF
            if [[ "$OPSYS" == "Darwin" ]]; then
                echo "VISIT_OPTION_DEFAULT(VISIT_OSPRAY_DIR \${VISITHOME}/ospray/\${OSPRAY_VERSION}/\${VISITARCH})" >> $HOSTCONF
            else
                echo "VISIT_OPTION_DEFAULT(VISIT_OSPRAY_DIR \${VISITHOME}/ospray/\${OSPRAY_VERSION}/\${VISITARCH}/ospray)" >> $HOSTCONF
            fi
        else
            local _tmp_=$(basename ${OSPRAY_CONFIG_DIR})
            echo "SETUP_APP_VERSION(OSPRAY ${_tmp_:7})" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_OSPRAY_DIR ${OSPRAY_INSTALL_DIR})" >> $HOSTCONF
        fi
    fi
}

function bv_ospray_is_enabled
{
    if [[ $DO_OSPRAY == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_ospray_ensure
{
    if [[ "$DO_OSPRAY" == "yes" && "$USE_SYSTEM_OSPRAY" == "no" ]]; then
        if [[ "$OPSYS" != "Darwin" ]]; then
           check_if_installed "ospray" $OSPRAY_VERSION
           if [[ $? == 1 && ! -e ${OSPRAY_LIBS_FILE} ]] ; then
               download_file ${OSPRAY_LIBS_FILE}
           fi
        fi

        ensure_built_or_ready "ospray" $OSPRAY_VERSION $OSPRAY_BUILD_DIR $OSPRAY_FILE $OSPRAY_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_OSPRAY="no"
            error "Unable to build ospray. ${OSPRAY_FILE} not found."
        fi
    fi
}

function bv_ospray_initialize_vars
{
    if [[ "$USE_SYSTEM_OSPRAY" == "no" ]]; then
        OSPRAY_INSTALL_DIR="${VISITDIR}/ospray/${OSPRAY_VERSION}/${VISITARCH}"
    fi
}

function bv_ospray_is_installed
{
    if [[ "$USE_SYSTEM_OSPRAY" == "yes" ]]; then   
        return 1
    fi

    check_if_installed "ospray" $OSPRAY_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function build_ospray_in_source
{
    # set compiler if the user hasn't explicitly set CC and CXX
    if [ -z $CC ]; then
        echo "***NOTE: using compiler $C_COMPILER/$CXX_COMPILER!"
        export CC=$C_COMPILER
        export CXX=$CXX_COMPILER
    fi

    #### Build OSPRay ####
    mkdir -p build
    cd build

    # Clean out build directory to be sure we are doing a fresh build
    rm -rf *

    # set release and RPM settings
    info "Configure OSPRay . . . "
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}

    CMAKE_VARS=""
    CMAKE_VARS=${CMAKE_VARS}" -D CMAKE_INSTALL_PREFIX=${OSPRAY_INSTALL_DIR} "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_BUILD_ISA=ALL "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_MODULE_VISIT=ON "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_MODULE_MPI=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_MODULE_MPI_APPS=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_APPS_EXAMPLEVIEWER=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_APPS_BENCHMARK=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_SG_CHOMBO=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_SG_OPENIMAGEIO=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_SG_VTK=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_ZIP_MODE=OFF "
    CMAKE_VARS=${CMAKE_VARS}" -D embree_DIR=${EMBREE_INSTALL_DIR} "
    CMAKE_VARS=${CMAKE_VARS}" -D ISPC_EXECUTABLE=${ISPC_INSTALL_DIR}/ispc "
    if [[ "${TBB_INSTALL_DIR}" == "" ]]; then
        bv_ospray_check_openmp
        if [[ $? == 0 ]]; then
            CMAKE_VARS=${CMAKE_VARS}" -D OSPRAY_TASKING_SYSTEM=OpenMP "
        else
            error "OSPRay cannot find neither TBB nor OpenMP."
        fi
    else
        CMAKE_VARS=${CMAKE_VARS}" -D TBB_ROOT=${TBB_INSTALL_DIR} "
    fi
    ${CMAKE_INSTALL}/cmake ${CMAKE_VARS} \
        .. || error "OSPRay did not configure correctly.  Giving up."

    #
    # Now build OSPRay
    #
    info "Building OSPRay (~10 minute)"
    env DYLD_LIBRARY_PATH=`pwd`/bin ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS || \
        error "OSPRay did not build correctly.  Giving up."

    info "Installing OSPRay . . . "
    ${CMAKE_COMMAND} --install . || error "OSPRay did not install correctly."
}

function build_ospray
{
    #
    # Uncompress the source file
    #
    prepare_build_dir $OSPRAY_SRC_DIR $OSPRAY_FILE
    untarred_ospray=$?
    if [[ $untarred_ospray == -1 ]] ; then
        warn "Unable to uncompress OSPRay source file. Giving Up!"
        return 1
    fi

    if [[ "$OPSYS" == "Darwin" ]]; then
        # The above "untar" operation produced the pre-built binaries we need.
        # Just install them now. Removing com.apple.quarantine attribute may
        # trigger an email inquiry from LLNL cyber-security team. Just let them
        # know its part of Intel software we use in our release.
        pushd $OSPRAY_SRC_DIR 1>/dev/null 2>&1
        find . -name '*.dylib' -exec xattr -d com.apple.quarantine {} \;
        mkdir -p ${OSPRAY_INSTALL_DIR}
        cp -R include lib ${OSPRAY_INSTALL_DIR}/.
        info "Installed OSPRay from pre-built binaries. . . "
        popd 1>/dev/null 2>&1
        return 0
    fi

    #
    # Make a build directory for an out-of-source build.
    #
    cd "$START_DIR"
    if [[ ! -d $OSPRAY_BUILD_DIR ]] ; then
        echo "Making build directory $OSPRAY_BUILD_DIR"
        mkdir $OSPRAY_BUILD_DIR
        if [[ -f $OSPRAY_LIBS_FILE ]] ; then
            tar zxf $OSPRAY_LIBS_FILE
            mkdir -p $OSPRAY_BUILD_DIR/ispc/src
            cp $OSPRAY_LIBS_DIR/ispc-v1.21.1-linux-oneapi.tar.gz $OSPRAY_BUILD_DIR/ispc/src
            mkdir $OSPRAY_BUILD_DIR/tbb
            cp $OSPRAY_LIBS_DIR/oneapi-tbb-2021.10.0-lin.tgz $OSPRAY_BUILD_DIR/tbb
            mkdir $OSPRAY_BUILD_DIR/rkcommon
            cp $OSPRAY_LIBS_DIR/v1.12.0.zip $OSPRAY_BUILD_DIR/rkcommon
            mkdir $OSPRAY_BUILD_DIR/embree
            cp $OSPRAY_LIBS_DIR/embree-4.3.0.x86_64.linux.tar.gz $OSPRAY_BUILD_DIR/embree
            mkdir $OSPRAY_BUILD_DIR/glm
            cp $OSPRAY_LIBS_DIR/glm-0.9.9.8.zip $OSPRAY_BUILD_DIR/glm
            mkdir $OSPRAY_BUILD_DIR/openvkl
            cp $OSPRAY_LIBS_DIR/v2.0.0.zip $OSPRAY_BUILD_DIR/openvkl
        fi
    else
        #
        # Remove the CMakeCache.txt files ... existing files sometimes
        # prevent fields from getting overwritten properly.
        #
        rm -Rf ${OSPRAY_BUILD_DIR}/CMakeCache.txt ${OSPRAY_BUILD_DIR}/*/CMakeCache.txt
    fi
    cd ${OSPRAY_BUILD_DIR}

    #
    # Configure OSPRAY
    #
    info "Configuring OSPRAY . . ."

    # set compiler if the user hasn't explicitly set CC and CXX
    if [ -z $CC ]; then
        echo "***NOTE: using compiler $C_COMPILER/$CXX_COMPILER!"
        export CC=$C_COMPILER
        export CXX=$CXX_COMPILER
    fi

    CMAKE_VARS=""
    CMAKE_VARS="${CMAKE_VARS} -DCMAKE_INSTALL_PREFIX:PATH=${OSPRAY_INSTALL_DIR} -DBUILD_OIDN:BOOL=OFF -DBUILD_OSPRAY_APPS:BOOL=OFF -DBUILD_GLFW:BOOL=OFF -DBUILD_BENCHMARK:BOOL=OFF"

    #
    # Several platforms have had problems with the cmake configure
    # command issued simply via "issue_command". This was first
    # discovered on BGQ and then showed up in random cases for both
    # OSX and Linux machines.  Brad resolved this on BGQ with a simple
    # work around - we write a simple script that we invoke with bash
    # which calls cmake with all of the properly arguments. We are now
    # using this strategy for all platforms.
    #
    CMAKE_BIN="${CMAKE_INSTALL}/cmake"

    if test -e bv_run_cmake.sh ; then
         rm -f bv_run_cmake.sh
    fi

    echo "\"${CMAKE_BIN}\"" ${CMAKE_VARS} ../${OSPRAY_SRC_DIR}/scripts/superbuild > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh

    if [[ $? != 0 ]] ; then
        warn "OSPRAY configure failed. Giving up"
        return 1
    fi

    #
    # Now build OSPRAY.
    #
    info "Building OSPRAY . . . (~5 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS

    #
    # On Darwin, the build can fail in a cmake -E copy_directory due to
    # bad symlinks created fron unzipping a data file containing binary
    # tbb libs. So, we try to fix those and re-run the build a second time.
    #
    if [[ $? != 0 ]]; then
        if [[ "$OPSYS" == "Darwin" ]]; then
            pushd embree/src/lib 1>/dev/null 2>&1
            rm -f libtbb.a libtbb.dylib libtbb.12.dylib libtbb.12.5.dylib
            ln -sf ../../../tbb/src/lib/libtbb.12.10.dylib .
            ln -sf ../../../tbb/src/lib/libtbb.12.dylib .
            ln -sf ../../../tbb/src/lib/libtbb.dylib .
            popd 1>/dev/null 2>&1
            ${CMAKE_COMMAND} --build .
            if [[ $? != 0 ]] ; then
                warn "OSPRAY build failed. Giving up"
                return 1
            fi
        else
            warn "OSPRAY build failed. Giving up"
            return 1
        fi
    fi

    #
    # Install into the VisIt third party location.
    #

    # No need to install as the cmake build does that.

    if [[ "$DO_GROUP" == "yes" ]]; then
        chmod -R ug+w,a+rX "$VISITDIR/ospray"
        chgrp -R ${GROUP} "$VISITDIR/ospray"
    fi

    cd "$START_DIR"
    info "Done with OSPRay"
    return 0
}

function bv_ospray_build
{
    cd "$START_DIR"
    if [[ "$DO_OSPRAY" == "yes" && "$USE_SYSTEM_OSPRAY" == "no" ]]; then
        check_if_installed "ospray" $OSPRAY_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping OSPRay build. OSPRay is already installed."
        else
            info "Building OSPRAY (~10 minutes)"
            build_ospray
            if [[ $? != 0 ]]; then
                error "Unable to build or install OSPRay. Bailing out."
            fi
            info "Done building OSPRAY"
        fi
    fi
}

function bv_pidx_initialize
{
    export DO_PIDX="no"
    export USE_SYSTEM_PIDX="no"
    add_extra_commandline_args "pidx" "alt-pidx-dir" 1 "Use alternative directory for pidx"
}

function bv_pidx_enable
{
    DO_PIDX="yes"
}

function bv_pidx_disable
{
    DO_PIDX="no"
}

function bv_pidx_alt_pidx_dir
{
    bv_pidx_enable
    USE_SYSTEM_PIDX="yes"
    PIDX_INSTALL_DIR="$1"
}

function bv_pidx_depends_on
{
    depends_on="cmake"

    if [[ "$USE_SYSTEM_PIDX" == "yes" ]]; then
        echo ""
    else
        if [[ "$DO_MPICH" == "yes" ]] ; then
            depends_on="$depends_on mpich"
        fi

        echo $depends_on
    fi
}

function bv_pidx_initialize_vars
{
    if [[ "$USE_SYSTEM_PIDX" == "no" ]]; then
        PIDX_INSTALL_DIR="${VISITDIR}/pidx/$PIDX_VERSION/${VISITARCH}"
    fi
}

function bv_pidx_info
{
    export PIDX_VERSION=${PIDX_VERSION:-"0.9.3"}
    export PIDX_FILE=${PIDX_FILE:-"PIDX-${PIDX_VERSION}.tar.gz"}
    export PIDX_COMPATIBILITY_VERSION=${PIDX_COMPATIBILITY_VERSION:-"1.8"}
    export PIDX_BUILD_DIR=${PIDX_BUILD_DIR:-"PIDX-${PIDX_VERSION}"}
    export PIDX_SHA256_CHECKSUM="e6c91546821134f87b80ab1d3ed6aa0930c4507d84ad1f19ec51a7ae10152888"
}

function bv_pidx_print
{
    printf "%s%s\n" "PIDX_FILE=" "${PIDX_FILE}"
    printf "%s%s\n" "PIDX_VERSION=" "${PIDX_VERSION}"
    printf "%s%s\n" "PIDX_COMPATIBILITY_VERSION=" "${PIDX_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "PIDX_BUILD_DIR=" "${PIDX_BUILD_DIR}"
}

function bv_pidx_print_usage
{
    printf "%-20s %s [%s]\n" "--pidx" "Build pidx" "${DO_PIDX}"
    printf "%-20s %s [%s]\n" "--alt-pidx-dir" "Use pidx from an alternative directory"
}

function bv_pidx_host_profile
{
    if [[ "$DO_PIDX" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## PIDX" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        echo "SETUP_APP_VERSION(PIDX $PIDX_VERSION)" >> $HOSTCONF 

        if [[ "$USE_SYSTEM_PIDX" == "yes" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_PIDX_DIR $PIDX_INSTALL_DIR)" \
                >> $HOSTCONF 
        else
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_PIDX_DIR \${VISITHOME}/pidx/\${PIDX_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF 
        fi
    fi
}

function bv_pidx_ensure
{
    if [[ "$DO_PIDX" == "yes" && "$USE_SYSTEM_PIDX" == "no" ]] ; then
        ensure_built_or_ready "pidx" $PIDX_VERSION $PIDX_BUILD_DIR $PIDX_FILE $PIDX_URL 
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_PIDX="no"
            error "Unable to build pidx.  ${PIDX_FILE} not found."
        fi
    fi
}

function apply_pidx_variable_patch
{
    info "Patching PIDX 0.9.3 variable. "
    patch -p0 << \EOF
diff -u pidx/PIDX_variable.c.orig pidx/PIDX_variable.c
--- pidx/PIDX_variable.c.orig	2025-07-07 15:21:43.184915000 -0700
+++ pidx/PIDX_variable.c	2025-07-07 15:22:13.144941000 -0700
@@ -216,7 +216,7 @@
   memcpy(variable->sim_patch[variable->sim_patch_count]->physical_offset, offset, PIDX_MAX_DIMENSIONS * sizeof(double));
   memcpy(variable->sim_patch[variable->sim_patch_count]->physical_size, dims, PIDX_MAX_DIMENSIONS * sizeof(double));
 
-  variable->sim_patch[variable->sim_patch_count]->read_particle_buffer = write_to_this_buffer;
+  variable->sim_patch[variable->sim_patch_count]->read_particle_buffer = (unsigned char**)(write_to_this_buffer);
   variable->sim_patch[variable->sim_patch_count]->read_particle_buffer_capacity = 0;
   *number_of_particles = 0;
   variable->sim_patch[variable->sim_patch_count]->read_particle_count = number_of_particles;
EOF
    if [[ $? != 0 ]] ; then
        warn "PIDX variable patch failed."
        return 1
    fi

    return 0;
}

function apply_pidx_patch
{
    if [[ "${PIDX_VERSION}" == 0.9.3 ]] ; then
        apply_pidx_variable_patch
        if [[ $? != 0 ]]; then
            return 1
        fi
    fi

    return 0
}

# *************************************************************************** #
#              Function 8.1, build_pidx                                   #
# *************************************************************************** #
function build_pidx
{
    #
    # CMake is the build system for PIDX.
    #
    CMAKE_INSTALL=${CMAKE_INSTALL:-"$VISITDIR/cmake/${CMAKE_VERSION}/$VISITARCH/bin"}
    if [[ -e ${CMAKE_INSTALL}/cmake ]] ; then
        info "pidx: CMake found"
    else
        warn "Unable to find cmake, cannot build pidx. Giving up."
        return 1
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $PIDX_BUILD_DIR $PIDX_FILE
    untarred_pidx=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_pidx == -1 ]] ; then
        warn "Unable to prepare pidx build directory. Giving Up"
        return 1
    fi

    #
    cd $PIDX_BUILD_DIR || error "Can't cd to pidx build dir." $PIDX_BUILD_DIR 

    #
    # Apply patches
    #
    info "Patching pidx . . ."
    apply_pidx_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_pidx == 1 ]] ; then
            warn "Giving up on pidx build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi
 
    #
    # Configure pidx
    #
    info "Configuring pidx . . ."

    ntopts=""
    pidx_build_mode="${VISIT_BUILD_MODE}"
    pidx_inst_path="${PIDX_INSTALL_DIR}"

    ntopts="${ntopts} -DCMAKE_BUILD_TYPE:STRING=${pidx_build_mode}"
    ntopts="${ntopts} -DCMAKE_INSTALL_PREFIX:PATH=${pidx_inst_path}"

    # Currently does not work but should be used.
#    ntopts="${ntopts} -DBUILD_SHARED_LIBS:BOOL=ON"

    # Because above the build type is specificed the compiler flags are set
    # So do not set any of these four flags. Otherse a semi-colon gets
    # inserted into the the makefile comands.
    ntopts="${ntopts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    ntopts="${ntopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    ntopts="${ntopts} -DCMAKE_C_FLAGS:STRING=\"\""
    ntopts="${ntopts} -DCMAKE_CXX_FLAGS:STRING=\"\""
    
#    ntopts="${ntopts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS}\""
#    ntopts="${ntopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS}\""
    
#    ntopts="${ntopts} -DCMAKE_EXE_LINKER_FLAGS:STRING=${lf}"
#    ntopts="${ntopts} -DCMAKE_MODULE_LINKER_FLAGS:STRING=${lf}"
#    ntopts="${ntopts} -DCMAKE_SHARED_LINKER_FLAGS:STRING=${lf}"

    # pidx specific options.

    
#    if test "${OPSYS}" = "Darwin" ; then
#        ntopts="${ntopts} -DCMAKE_INSTALL_NAME_DIR:PATH=${pidx_inst_path}/lib"
#    fi

    if [[ "${DO_MPICH}" == "yes" ]]; then
        info "mpich requested.  Configuring PIDX with mpich support."
        ntopts="${ntopts} -DMPI_C_COMPILER:PATH=${VISITDIR}/mpich/${MPICH_VERSION}/${VISITARCH}/bin/mpicc"
        ntopts="${ntopts} -DMPI_CXX_COMPILER:PATH=${VISITDIR}/mpich/${MPICH_VERSION}/${VISITARCH}/bin/mpicxx"

#        if [[ "$OPSYS" == "Darwin" ]]; then
#            export DYLD_LIBRARY_PATH="$VISITDIR/mpich/$MPICH_VERSION/$VISITARCH/lib":$DYLD_LIBRARY_PATH
#        else
#            export LD_LIBRARY_PATH="$VISITDIR/mpich/$MPICH_VERSION/$VISITARCH/lib":$LD_LIBRARY_PATH
#        fi
    elif [[ "$parallel" == "yes" ]]; then
        if [[ "$PAR_COMPILER" != "" ]]; then
            ntopts="${ntopts} -DMPI_C_COMPILER:STRING=${PAR_COMPILER}"
        fi
        if [[ "$PAR_COMPILER_CXX" != "" ]]; then
            ntopts="${ntopts} -DMPI_CXX_COMPILER:STRING=${PAR_COMPILER_CXX}"
        fi
        if [[ "$PAR_INCLUDE" != "" ]] ; then
            ntopts="${ntopts} -DMPI_C_INCLUDE_PATH:STRING=${PAR_INCLUDE_PATH}"
            ntopts="${ntopts} -DMPI_CXX_INCLUDE_PATH:STRING=${PAR_INCLUDE_PATH}"
        fi
        if [[ "$PAR_LIBS" != "" ]] ; then
            ntopts="${ntopts} -DMPI_C_LINK_FLAGS:STRING=${PAR_LINKER_FLAGS}"
            ntopts="${ntopts} -DMPI_C_LIBRARIES:STRING=${PAR_LIBRARY_LINKER_FLAGS}"
            ntopts="${ntopts} -DMPI_CXX_LINK_FLAGS:STRING=${PAR_LINKER_FLAGS}"
            ntopts="${ntopts} -DMPI_CXX_LIBRARIES:STRING=${PAR_LIBRARY_LINKER_FLAGS}"
        fi
    fi

    cd "$START_DIR"

    # Make a build directory for an out-of-source build.. Change the
    # VISIT_BUILD_DIR variable to represent the out-of-source build directory.
    PIDX_SRC_DIR=$PIDX_BUILD_DIR
    PIDX_BUILD_DIR="${PIDX_SRC_DIR}-build"
    if [[ ! -d $PIDX_BUILD_DIR ]] ; then
        echo "Making build directory $PIDX_BUILD_DIR"
        mkdir $PIDX_BUILD_DIR
    fi

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"

    cd ${PIDX_BUILD_DIR}

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi

    #
    # Remove the CMakeCache.txt files ... existing files sometimes prevent
    # fields from getting overwritten properly.
    #
    rm -Rf ${PIDX_BUILD_DIR}/CMakeCache.txt ${PIDX_BUILD_DIR}/*/CMakeCache.txt

    echo "\"${CMAKE_BIN}\"" ${ntopts} ../${PIDX_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "pidx configuration failed."

    #
    # Build PIDX
    #
    info "Making pidx . . ."
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "pidx build failed.  Giving up"
        return 1
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing pidx . . ."
    ${CMAKE_COMMAND} --install .
    if [[ $? != 0 ]] ; then
        warn "pidx install failed.  Giving up"
        return 1
    fi

#    mv ${pidx_inst_path}/lib64/* ${pidx_inst_path}/lib

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/pidx"
        chgrp -R ${GROUP} "$VISITDIR/pidx"
    fi
    cd "$START_DIR"
    info "Done with pidx"
    return 0
}

function bv_pidx_is_enabled
{
    if [[ $DO_PIDX == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_pidx_is_installed
{

    if [[ "$USE_SYSTEM_PIDX" == "yes" ]]; then
        return 1
    fi

    check_if_installed "pidx" $PIDX_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_pidx_build
{
    cd "$START_DIR"

    if [[ "$DO_PIDX" == "yes" && "$USE_SYSTEM_PIDX" == "no" ]] ; then
        check_if_installed "pidx" $PIDX_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping pidx build.  pidx is already installed."
        else
            info "Building pidx (~2 minutes)"
            build_pidx
            if [[ $? != 0 ]] ; then
                error "Unable to build or install pidx.  Bailing out."
            fi
            info "Done building pidx"
        fi
    fi
}
# *************************************************************************** #
# Function: check_if_py_module_installed                                      #
#                                                                             #
# Purpose: Checks if givne .                       #
#                                                                             #
# Programmer: Cyrus Harrison                                                  #
# Date: Wed Apr 29 15:29:04 PDT 2020                                          #
#                                                                             #
# *************************************************************************** #
function check_if_py_module_installed
{
    MOD_NAME=$1

    PYHOME=${VISIT_PYTHON_DIR}
    PYTHON_COMMAND="${VISIT_PYTHON_DIR}/bin/python3"

    echo "import ${MOD_NAME}; print(${MOD_NAME})" | ${PYTHON_COMMAND}

    if [[ $? != 0 ]] ; then
        return 1
    fi

    return 0
}

function download_py_module
{
    MOD_FILE=$1
    MOD_URL=$2
 
    if ! test -f ${MOD_FILE} ; then
        download_file ${MOD_FILE} "${MOD_URL}"
        if [[ $? != 0 ]] ; then
            warn "Could not download ${MOD_FILE}"
            return 1
        fi
    fi

    return 0
}

function extract_py_module
{
    MOD_DIR=$1
    MOD_FILE=$2
    MOD_NAME=$3

    if ! test -d ${MOD_DIR} ; then
        info "Extracting python ${MOD_NAME} module (file ${MOD_FILE} to dir ${MOD_DIR} ) ..."
        uncompress_untar ${MOD_FILE}
        if test $? -ne 0 ; then
            warn "Could not extract ${MOD_FILE}"
            return 1
        fi
    fi

    return 0
}

function install_py_module
{
    MOD_DIR=$1
    MOD_NAME=$2

    pushd ${MOD_DIR} > /dev/null
    info "Installing ${MOD_NAME} ..."

    echo ${PYTHON_COMMAND} -m pip --no-cache-dir --disable-pip-version-check install --no-index --no-deps --no-build-isolation --no-binary :all: .
    ${PYTHON_COMMAND} -m pip --no-cache-dir --disable-pip-version-check install --no-index --no-deps --no-build-isolation --no-binary :all: .

    if test $? -ne 0 ; then
        popd > /dev/null
        warn "Could not install ${MOD_NAME}"
        return 1
    fi
    popd > /dev/null

    return 0
}

function fix_py_permissions
{
    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/python"
        chgrp -R ${GROUP} "$VISITDIR/python"
    fi
    return 0
}


function bv_python_initialize
{
    export DO_PYTHON="yes"
    export USE_SYSTEM_PYTHON="no"
    export PY_BUILD_MPI4PY="no"
    export PY_BUILD_SPHINX="yes"
    export VISIT_PYTHON_DIR=${VISIT_PYTHON_DIR:-""}
    add_extra_commandline_args "python" "system-python" 0 "Using system python"
    add_extra_commandline_args "python" "alt-python-dir" 1 "Using alternate python directory"
    add_extra_commandline_args "python" "mpi4py" 0 "Build mpi4py"
    add_extra_commandline_args "python" "no-sphinx" 0 "Disable building sphinx"
}

function bv_python_enable
{
    DO_PYTHON="yes"
}

function bv_python_disable
{
    DO_PYTHON="no"
}


function python_set_vars_helper
{
    VISIT_PYTHON_DIR=`"$PYTHON_CONFIG_COMMAND" --prefix`
    PYTHON_BUILD_DIR=`"$PYTHON_CONFIG_COMMAND" --prefix`
    PYTHON_VER=`"$PYTHON_COMMAND" --version 2>&1`
    PYTHON_VERSION=${PYTHON_VER#"Python "}
    PYTHON_COMPATIBILITY_VERSION=${PYTHON_VERSION%.*}
    ########################
    PYTHON_INCLUDE_PATH=`"$PYTHON_CONFIG_COMMAND" --includes`
    #remove -I from first include
    PYTHON_INCLUDE_PATH="${PYTHON_INCLUDE_PATH:2}"
    #remove any extra includes
    PYTHON_INCLUDE_PATH="${PYTHON_INCLUDE_PATH%%-I*}"
    PYTHON_INCLUDE_DIR="$PYTHON_INCLUDE_PATH"
    PYTHON_VERSION_MINOR=`echo $PYTHON_VERSION | cut -d. -f2`
    if [[ $PYTHON_VERSION_MINOR -ge 8 ]] ; then
        PYTHON_LIBRARY=`"$PYTHON_CONFIG_COMMAND" --libs --embed`
    else
        PYTHON_LIBRARY=`"$PYTHON_CONFIG_COMMAND" --libs`
    fi
    #remove all other libraries except for python..
    PYTHON_LIBRARY=`echo $PYTHON_LIBRARY | sed "s/.*\(python[^ ]*\).*/\1/g"`

    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        PYTHON_LIBRARY="lib${PYTHON_LIBRARY}.a"
    else
          if [[ "$OPSYS" == "Darwin" ]]; then
              PYTHON_LIBRARY="lib${PYTHON_LIBRARY}.dylib"
          else
              PYTHON_LIBRARY="lib${PYTHON_LIBRARY}.so"
          fi
    fi
    #
    # use python's distutils info to get the proper library directory.
    #
    PYTHON_LIBRARY_DIR=`"$PYTHON_COMMAND" -c "import sys;from distutils.sysconfig import get_config_var; sys.stdout.write(get_config_var('LIBDIR'))"`
    if [ ! -e "${PYTHON_LIBRARY_DIR}/${PYTHON_LIBRARY}" ]
    then
        # some systems eg fedora use lib64...
        PYTHON_LIBRARY_DIR="${VISIT_PYTHON_DIR}/lib64"
        if [ ! -e "${PYTHON_LIBRARY_DIR}/${PYTHON_LIBRARY}" ]
        then
            # some systems eg debian use x86_64-linux-gnu...
            PYTHON_LIBRARY_DIR="${VISIT_PYTHON_DIR}/lib/x86_64-linux-gnu"
            if [ ! -e "${PYTHON_LIBRARY_DIR}/${PYTHON_LIBRARY}" ]
            then
                error "python library was not found, cannot configure python"
            fi
        fi
    fi
    PYTHON_LIBRARY="${PYTHON_LIBRARY_DIR}/${PYTHON_LIBRARY}"
    echo $PYTHON_BUILD_DIR $PYTHON_VERSION $VISIT_PYTHON_DIR

}

function bv_python_system_python
{
    echo "Using system python"

    # this method uses 'which' to find the full path to system python and it's config command
    TEST=`which python3-config`
    if [ $? == 0 ]
    then 
        PYTHON_COMMAND=`which python3`
        PYTHON_CONFIG_COMMAND=$TEST
    else
        TEST=`which python-config`
        [ $? != 0 ] && error "Neither system python3-config nor python-config found, cannot configure python"
        PYTHON_COMMAND=`which python`
        PYTHON_CONFIG_COMMAND=$TEST
    fi

    USE_SYSTEM_PYTHON="yes"
    bv_python_enable
    PYTHON_FILE=""
    python_set_vars_helper #set vars..
}

function bv_python_mpi4py
{
    echo "configuring for building mpi4py"
    export PY_BUILD_MPI4PY="yes"
}

function bv_python_no_sphinx
{
    echo "Disabling building sphinx"
    export PY_BUILD_SPHINX="no"
}

function bv_python_alt_python_dir
{
    echo "Using alternate python directory"

    if [ -e "$1/bin/python3-config" ]
    then
        PYTHON_COMMAND="$1/bin/python3"
        PYTHON_CONFIG_COMMAND="$1/bin/python3-config"
    elif [ -e "$1/bin/python-config" ]
    then
        PYTHON_COMMAND="$1/bin/python"
        PYTHON_CONFIG_COMMAND="$1/bin/python-config"
    else
        error "Python (python3-config or python-config) not found in $1"
    fi

    bv_python_enable
    USE_SYSTEM_PYTHON="yes"
    PYTHON_ALT_DIR="$1"
    PYTHON_FILE=""
    python_set_vars_helper #set vars..
}


function bv_python_depends_on
{
     pydep=""
     if [[ $USE_SYSTEM_PYTHON == "no" ]] ; then
        pydep="zlib"
     fi
     echo $pydep
}

function bv_python_info
{
    info "bv_python_info"

    # python 3.9
    export PYTHON_FILE_SUFFIX="tgz"
    export PYTHON_VERSION="3.9.18"
    export PYTHON_COMPATIBILITY_VERSION="3.9"
    export PYTHON_FILE="Python-$PYTHON_VERSION.$PYTHON_FILE_SUFFIX"
    export PYTHON_BUILD_DIR="Python-$PYTHON_VERSION"
    export PYTHON_SHA256_CHECKSUM="504ce8cfd59addc04c22f590377c6be454ae7406cb1ebf6f5a350149225a9354"

    export PY_SETUPTOOLS_FILE="setuptools-68.0.0.tar.gz"
    export PY_SETUPTOOLS_BUILD_DIR="setuptools-68.0.0"
    export PY_SETUPTOOLS_SHA256_CHECKSUM=""

    export PY_PILLOW_FILE="Pillow-10.0.0.tar.gz"
    export PY_PILLOW_BUILD_DIR="Pillow-10.0.0"
    export PY_PILLOW_SHA256_CHECKSUM=""

    export PY_REQUESTS_FILE="requests-2.31.0.tar.gz"
    export PY_REQUESTS_BUILD_DIR="requests-2.31.0"
    export PY_REQUESTS_SHA256_CHECKSUM=""

    export PY_CYTHON_FILE="Cython-3.0.0.tar.gz"
    export PY_CYTHON_BUILD_DIR="Cython-3.0.0"
    export PY_CYTHON_SHA256_CHECKSUM=""

    export PY_NUMPY_FILE="numpy-1.25.1.tar.gz"
    export PY_NUMPY_BUILD_DIR="numpy-1.25.1"
    export PY_NUMPY_SHA256_CHECKSUM=""

    export PY_MPI4PY_FILE="mpi4py-3.1.4.tar.gz"
    export PY_MPI4PY_BUILD_DIR="mpi4py-3.1.4"
    export PY_MPI4PY_SHA256_CHECKSUM=""

    export PY_PACKAGING_FILE="packaging-23.1.tar.gz"
    export PY_PACKAGING_BUILD_DIR="packaging-23.1"
    export PY_PACKAGING_SHA256_CHECKSUM=""

    export PY_IMAGESIZE_FILE="imagesize-1.4.1.tar.gz"
    export PY_IMAGESIZE_BUILD_DIR="imagesize-1.4.1"
    export PY_IMAGESIZE_SHA256_CHECKSUM=""

    export PY_ALABASTER_FILE="alabaster-0.7.13.tar.gz"
    export PY_ALABASTER_BUILD_DIR="alabaster-0.7.13"
    export PY_ALABASTER_SHA256_CHECKSUM=""

    export PY_BABEL_FILE="Babel-2.12.1.tar.gz"
    export PY_BABEL_BUILD_DIR="Babel-2.12.1"
    export PY_BABEL_SHA256_CHECKSUM=""

    export PY_SNOWBALLSTEMMER_FILE="snowballstemmer-2.2.0.tar.gz"
    export PY_SNOWBALLSTEMMER_BUILD_DIR="snowballstemmer-2.2.0"
    export PY_SNOWBALLSTEMMER_SHA256_CHECKSUM=""

    export PY_DOCUTILS_FILE="docutils-0.18.1.tar.gz"
    export PY_DOCUTILS_BUILD_DIR="docutils-0.18.1"
    export PY_DOCUTILS_SHA256_CHECKSUM=""

    export PY_PYGMENTS_FILE="Pygments-2.15.1.tar.gz"
    export PY_PYGMENTS_BUILD_DIR="Pygments-2.15.1"
    export PY_PYGMENTS_SHA256_CHECKSUM=""

    export PY_JINJA2_FILE="Jinja2-3.1.2.tar.gz"
    export PY_JINJA2_BUILD_DIR="Jinja2-3.1.2"
    export PY_JINJA2_SHA256_CHECKSUM=""

    export PY_SPHINXCONTRIB_QTHELP_FILE="sphinxcontrib-qthelp-1.0.3.tar.gz"
    export PY_SPHINXCONTRIB_QTHELP_BUILD_DIR="sphinxcontrib-qthelp-1.0.3"
    export PY_SPHINXCONTRIB_QTHELP_SHA256_CHECKSUM=""

    export PY_SPHINXCONTRIB_SERIALIZINGHTML_FILE="sphinxcontrib-serializinghtml-1.1.5.tar.gz"
    export PY_SPHINXCONTRIB_SERIALIZINGHTML_BUILD_DIR="sphinxcontrib-serializinghtml-1.1.5"
    export PY_SPHINXCONTRIB_SERIALIZINGHTML_SHA256_CHECKSUM=""

    export PY_SPHINXCONTRIB_HTMLHELP_FILE="sphinxcontrib-htmlhelp-2.0.1.tar.gz"
    export PY_SPHINXCONTRIB_HTMLHELP_BUILD_DIR="sphinxcontrib-htmlhelp-2.0.1"
    export PY_SPHINXCONTRIB_HTMLHELP_SHA256_CHECKSUM=""

    export PY_SPHINXCONTRIB_JSMATH_FILE="sphinxcontrib-jsmath-1.0.1.tar.gz"
    export PY_SPHINXCONTRIB_JSMATH_BUILD_DIR="sphinxcontrib-jsmath-1.0.1"
    export PY_SPHINXCONTRIB_JSMATH_SHA256_CHECKSUM="a9925e4a4587247ed2191a22df5f6970656cb8ca2bd6284309578f2153e0c4b8"

    export PY_SPHINXCONTRIB_DEVHELP_FILE="sphinxcontrib-devhelp-1.0.2.tar.gz"
    export PY_SPHINXCONTRIB_DEVHELP_BUILD_DIR="sphinxcontrib-devhelp-1.0.2"
    export PY_SPHINXCONTRIB_DEVHELP_SHA256_CHECKSUM=""

    export PY_SPHINXCONTRIB_APPLEHELP_FILE="sphinxcontrib-applehelp-1.0.4.tar.gz"
    export PY_SPHINXCONTRIB_APPLEHELP_BUILD_DIR="sphinxcontrib-applehelp-1.0.4"
    export PY_SPHINXCONTRIB_APPLEHELP_SHA256_CHECKSUM=""

    export PY_URLLIB3_FILE="urllib3-2.0.3.tar.gz"
    export PY_URLLIB3_BUILD_DIR="urllib3-2.0.3"
    export PY_URLLIB3_SHA256_CHECKSUM=""

    export PY_IDNA_FILE="idna-3.4.tar.gz"
    export PY_IDNA_BUILD_DIR="idna-3.4"
    export PY_IDNA_SHA256_CHECKSUM=""
 
    export PY_CHARSET_NORMALIZER_FILE="charset-normalizer-3.2.0.tar.gz"
    export PY_CHARSET_NORMALIZER_BUILD_DIR="charset-normalizer-3.2.0"
    export PY_CHARSET_NORMALIZER_SHA256_CHECKSUM=""

    export PY_CERTIFI_FILE="python-certifi-2025.07.09.tar.gz"
    export PY_CERTIFI_BUILD_DIR="python-certifi-2025.07.09"
    export PY_CERTIFI_SHA256_CHECKSUM=""

    export PY_FLITCORE_FILE="flit_core-3.9.0.tar.gz"
    export PY_FLITCORE_BUILD_DIR="flit_core-3.9.0"
    export PY_FLITCORE_SHA256_CHECKSUM=""

    export PY_TOML_FILE="toml-0.10.2.tar.gz"
    export PY_TOML_BUILD_DIR="toml-0.10.2"
    export PY_TOML_SHA256_CHECKSUM=""

    # and yes, this is a different one from toml!
    export PY_TOMLI_FILE="tomli-2.0.1.tar.gz"
    export PY_TOMLI_BUILD_DIR="tomli-2.0.1"
    export PY_TOMLI_SHA256_CHECKSUM=""

    export PY_PATHSPEC_FILE="pathspec-0.11.2.tar.gz"
    export PY_PATHSPEC_BUILD_DIR="pathspec-0.11.2"
    export PY_PATHSPEC_SHA256_CHECKSUM=""

    export PY_WHEEL_FILE="wheel-0.41.1.tar.gz"
    export PY_WHEEL_BUILD_DIR="wheel-0.41.1"
    export PY_WHEEL_SHA256_CHECKSUM=""

    export PY_CALVER_FILE="calver-2022.6.26.tar.gz"
    export PY_CALVER_BUILD_DIR="calver-2022.6.26"
    export PY_CALVER_SHA256_CHECKSUM=""

    export PY_TROVECLASSIFIERS_FILE="trove-classifiers-2023.8.7.tar.gz"
    export PY_TROVECLASSIFIERS_BUILD_DIR="trove-classifiers-2023.8.7"
    export PY_TROVECLASSIFIERS_SHA256_CHECKSUM=""

    export PY_EDITABLES_FILE="editables-0.5.tar.gz"
    export PY_EDITABLES_BUILD_DIR="editables-0.5"
    export PY_EDITABLES_SHA256_CHECKSUM=""

    export PY_PLUGGY_FILE="pluggy-1.2.0.tar.gz"
    export PY_PLUGGY_BUILD_DIR="pluggy-1.2.0"
    export PY_PLUGGY_SHA256_CHECKSUM=""

    export PY_HATCHLING_FILE="hatchling-1.18.0.tar.gz"
    export PY_HATCHLING_BUILD_DIR="hatchling-1.18.0"
    export PY_HATCHLING_SHA256_CHECKSUM=""

    export PY_MARKUPSAFE_FILE="MarkupSafe-2.1.3.tar.gz"
    export PY_MARKUPSAFE_BUILD_DIR="MarkupSafe-2.1.3"
    export PY_MARKUPSAFE_SHA256_CHECKSUM=""

    export PY_ZIPP_FILE="zipp-3.16.2.tar.gz"
    export PY_ZIPP_BUILD_DIR="zipp-3.16.2"
    export PY_ZIPP_SHA256_CHECKSUM=""

    export PY_IMPORTLIB_METADATA_URL=""
    export PY_IMPORTLIB_METADATA_FILE="importlib_metadata-6.8.0.tar.gz"
    export PY_IMPORTLIB_METADATA_BUILD_DIR="importlib_metadata-6.8.0"
    export PY_IMPORTLIB_METADATA_SHA256_CHECKSUM=""

    export PY_SPHINX_FILE="Sphinx-7.0.1.tar.gz"
    export PY_SPHINX_BUILD_DIR="Sphinx-7.0.1"
    export PY_SPHINX_SHA256_CHECKSUM=""

    export PY_SPHINX_RTD_THEME_FILE="sphinx_rtd_theme-1.2.2.tar.gz"
    export PY_SPHINX_RTD_THEME_BUILD_DIR="sphinx_rtd_theme-1.2.2"
    export PY_SPHINX_RTD_THEME_SHA256_CHECKSUM=""

    # needed by sphinx_rtd_theme
    export PY_SPHINXCONTRIB_JQUERY_FILE="sphinxcontrib-jquery-4.1.tar.gz"
    export PY_SPHINXCONTRIB_JQUERY_BUILD_DIR="sphinxcontrib-jquery-4.1"
    export PY_SPHINXCONTRIB_JQUERY_SHA256_CHECKSUM=""

    export PY_SPHINX_TABS_FILE="sphinx-tabs-3.4.1.tar.gz"
    export PY_SPHINX_TABS_BUILD_DIR="sphinx-tabs-3.4.1"
    export PY_SPHINX_TABS_SHA256_CHECKSUM=""
}

function bv_python_print
{
    printf "%s%s\n" "PYTHON_FILE=" "${PYTHON_FILE}"
    printf "%s%s\n" "PYTHON_VERSION=" "${PYTHON_VERSION}"
    printf "%s%s\n" "PYTHON_COMPATIBILITY_VERSION=" "${PYTHON_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "PYTHON_BUILD_DIR=" "${PYTHON_BUILD_DIR}"
}

function bv_python_print_usage
{
    printf "%-20s %s\n" "--python" "Build Python"
    printf "%-20s %s [%s]\n" "--system-python" "Use the system installed Python"
    printf "%-20s %s [%s]\n" "--alt-python-dir" "Use Python from an alternative directory"
    printf "%-20s %s [%s]\n" "--mpi4py" "Build mpi4py with Python"
    printf "%-20s %s [%s]\n" "--no-sphinx" "Disable building sphinx"
  }

function bv_python_host_profile
{
    if [[ "$DO_PYTHON" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Python" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        if [[ "$USE_SYSTEM_PYTHON" == "yes" ]]; then
            echo "VISIT_OPTION_DEFAULT(VISIT_PYTHON_DIR $VISIT_PYTHON_DIR)" >> $HOSTCONF
            #incase the PYTHON_DIR does not find the include and library set it manually...
            echo "VISIT_OPTION_DEFAULT(PYTHON_INCLUDE_PATH $PYTHON_INCLUDE_PATH)" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(PYTHON_LIBRARY ${PYTHON_LIBRARY})" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(PYTHON_LIBRARY_DIR $PYTHON_LIBRARY_DIR)" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(PYTHON_VERSION $PYTHON_COMPATIBILITY_VERSION)" >> $HOSTCONF
            echo "SET(VISIT_PYTHON_SKIP_INSTALL ON)" >> $HOSTCONF
        else
            echo "VISIT_OPTION_DEFAULT(VISIT_PYTHON_DIR \${VISITHOME}/python/$PYTHON_VERSION/\${VISITARCH})" \
                 >> $HOSTCONF
        fi
    fi
}

function bv_python_initialize_vars
{
    if [[ "$USE_SYSTEM_PYTHON" == "no" ]]; then
        #assign any default values that other libraries should be aware of
        #when they build..
        #this is for when python is being built and system python was not selected..
        export VISIT_PYTHON_DIR=${VISIT_PYTHON_DIR:-"$VISITDIR/python/${PYTHON_VERSION}/${VISITARCH}"}

        export PYHOME=${VISIT_PYTHON_DIR}
        export PYTHON_COMMAND="${VISIT_PYTHON_DIR}/bin/python3"
        # CYRUS NOTE: PYTHON_LIBRARY_DIR looks wrong?
        # export PYTHON_LIBRARY_DIR="${VISIT_PYTHON_DIR}/bin/python"
        export PYTHON_INCLUDE_DIR="${VISIT_PYTHON_DIR}/include/python${PYTHON_COMPATIBILITY_VERSION}"
        export PYTHON_LIBRARY="${VISIT_PYTHON_DIR}/lib/libpython${PYTHON_COMPATIBILITY_VERSION}.${SO_EXT}"
    else
        export PYTHON_COMMAND="${PYTHON_COMMAND}"
    fi
}

function bv_python_ensure
{
    if [[ "$USE_SYSTEM_PYTHON" == "no" ]]; then
        if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
            if [[ "$DO_PYTHON" == "yes" || "$DO_VTK" == "yes" ]] ; then

                if [[ "$DOWNLOAD_ONLY" == "yes" ]] ; then
                    # ensure all packages are downloaded
                    # wheel and its dependencies
                    download_py_module ${PY_FLITCORE_FILE} ${PY_FLITCORE_URL}
                    download_py_module ${PY_WHEEL_FILE} ${PY_WHEEL_URL}
                    # setuptools
                    download_py_module ${PY_SETUPTOOLS_FILE} ${PY_SETUPTOOLS_URL}

                    if [[ "$DO_STATIC_BUILD" == "no" ]]; then
                        # numpy
                        download_py_module ${PY_CYTHON_FILE} ${PY_CYTHON_URL}
                        download_py_module ${PY_NUMPY_FILE} ${PY_NUMPY_URL}
                        # Pillow
                        download_py_module ${PY_PILLOW_FILE} ${PY_PILLOW_URL}
                        # mpi4py
                        if [[ "$PY_BUILD_MPI4PY" == "yes" ]]; then
                            download_py_module ${PY_MPI4PY_FILE} ${PY_MPI4PY_URL}
                        fi
                        if [[ "$PY_BUILD_SPHINX" == "yes" ]]; then
                            # Requests and dependencies
                            download_py_module ${PY_CERTIFI_FILE} ${PY_CERTIFI_URL}
                            download_py_module ${PY_TOML_FILE} ${PY_TOML_URL}
                            download_py_module ${PY_TOMLI_FILE} ${PY_TOMLI_URL}
                            download_py_module ${PY_PATHSPEC_FILE} ${PY_PATHSPEC_URL}
                            download_py_module ${PY_CALVER_FILE} ${PY_TCALVER_URL}
                            download_py_module ${PY_TROVECLASSIFIERS_FILE} ${PY_TROVECLASSIFIERS_URL}
                            download_py_module ${PY_PACKAGING_FILE} ${PY_PACKAGING_URL}
                            download_py_module ${PY_EDITABLES_FILE} ${PY_EDITABLES_URL}
                            download_py_module ${PY_PLUGGY_FILE} ${PY_PLUGGY_URL}
                            download_py_module ${PY_HATCHLING_FILE} ${PY_HATCHLING_URL}
                            download_py_module ${PY_URLLIB3_FILE} ${PY_URLLIB3_URL}
                            download_py_module ${PY_IDNA_FILE} ${PY_IDNA_URL}
                            download_py_module ${PY_CHARSET_NORMALIZER_FILE} ${PY_CHARSET_NORMALIZER_URL}
                            download_py_module ${PY_REQUESTS_FILE} ${PY_REQUESTS_URL}
                            # sphinx
                            download_py_module ${PY_PACKAGING_FILE} ${PY_PACKAGING_URL}
                            download_py_module ${PY_IMAGESIZE_FILE} ${PY_IMAGESIZE_URL}
                            download_py_module ${PY_ALABASTER_FILE} ${PY_ALABASTER_URL}
                            download_py_module ${PY_BABEL_FILE} ${PY_BABEL_URL}
                            download_py_module ${PY_SNOWBALLSTEMMER_FILE} ${PY_SNOWBALLSTEMMER_URL}
                            download_py_module ${PY_DOCUTILS_FILE} ${PY_DOCUTILS_URL}
                            download_py_module ${PY_PYGMENTS_FILE} ${PY_PYGMENTS_URL}
                            download_py_module ${PY_JINJA2_FILE} ${PY_JINJA2_URL}
                            download_py_module ${PY_SPHINXCONTRIB_QTHELP_FILE} ${PY_SPHINXCONTRIB_QTHELP_URL}
                            download_py_module ${PY_SPHINXCONTRIB_SERIALIZINGHTML_FILE} ${PY_SPHINXCONTRIB_SERIALIZINGHTML_URL}
                            download_py_module ${PY_SPHINXCONTRIB_HTMLHELP_FILE} ${PY_SPHINXCONTRIB_HTMLHELP_URL}
                            download_py_module ${PY_SPHINXCONTRIB_JSMATH_FILE} ${PY_SPHINXCONTRIB_JSMATH_URL}
                            download_py_module ${PY_SPHINXCONTRIB_DEVHELP_FILE} ${PY_SPHINXCONTRIB_DEVHELP_URL}
                            download_py_module ${PY_SPHINXCONTRIB_APPLEHELP_FILE} ${PY_SPHINXCONTRIB_APPLEHELP_ULR}
                            download_py_module ${PY_MARKUPSAFE_FILE} ${PY_MARKUPSAFE_URL}
                            download_py_module ${PY_ZIPP_FILE} ${PY_ZIPP_URL}

                            download_py_module ${PY_IMPORTLIB_METADATA_FILE} ${PY_IMPORTLIB_METADATA_URL}
                            download_py_module ${PY_SPHINX_FILE} ${PY_SPHINX_URL}
                            # sphinx rtd
                            download_py_module ${PY_SPHINXCONTRIB_JQUERY_FILE} ${PY_SPHINXCONTRIB_JQUERY_URL}
                            download_py_module ${PY_SPHINX_RTD_THEME_FILE} ${PY_SPHINX_RTD_THEME_URL}
                            # sphinx tabs
                            download_py_module ${PY_SPHINX_TABS_FILE} ${PY_SPHINX_TABS_URL}
                        fi
                    fi
                fi

                ensure_built_or_ready "python" $PYTHON_VERSION $PYTHON_BUILD_DIR $PYTHON_FILE
                if [[ $? != 0 ]] ; then
                    return 1

                fi

            fi
        fi
    fi
}


function apply_python_patch
{
    # no patches for 3.9
    return 0
}


# *************************************************************************** #
#                         Function 7, build_python                            #
# *************************************************************************** #

function build_python
{
    prepare_build_dir $PYTHON_BUILD_DIR $PYTHON_FILE
    untarred_python=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_python == -1 ]] ; then
        warn "Unable to prepare Python build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    cd $PYTHON_BUILD_DIR || error "Can't cd to Python build dir."
    apply_python_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_python == 1 ]] ; then
            warn "Giving up on Python build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Configure Python
    #
    cCompiler="${C_COMPILER}"
    cFlags="${CFLAGS} ${C_OPT_FLAGS}"
    cxxCompiler="${CXX_COMPILER}"
    cxxFlags="{$CXXFLAGS} ${CXX_OPT_FLAGS}"
    if [[ "$OPSYS" == "Linux" && "$C_COMPILER" == "xlc" ]]; then
        cCompiler="gxlc"
        cxxCompiler="gxlC"
        cFlags=`echo ${CFLAGS} ${C_OPT_FLAGS} | sed "s/-qpic/-fPIC/g"`
        cxxFlags=`echo $CXXFLAGS} ${CXX_OPT_FLAGS} | sed "s/-qpic/-fPIC/g"`
    fi
    PYTHON_OPT="$cFlags"
    PYTHON_LDFLAGS=""
    PYTHON_CPPFLAGS=""
    PYTHON_PREFIX_DIR="$VISITDIR/python/$PYTHON_VERSION/$VISITARCH"
    if [[ "$DO_STATIC_BUILD" == "no" ]]; then
        PYTHON_SHARED="--enable-shared"
        #
        # python's --enable-shared configure flag doesn't link
        # the exes it builds correctly when installed to a non standard
        # prefix. To resolve this we need to add a rpath linker flags.
        #
        mkdir -p ${PYTHON_PREFIX_DIR}/lib/
        if [[ $? != 0 ]] ; then
            warn "Python configure failed.  Giving up"
            return 1
        fi

        if [[ "$OPSYS" != "Darwin" || ${VER%%.*} -ge 9 ]]; then
            PYTHON_LDFLAGS="-Wl,-rpath,${PYTHON_PREFIX_DIR}/lib/ -pthread"
        fi
    fi

    PY_ZLIB_INCLUDE="$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/include"
    PY_ZLIB_LIB="$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/lib"
    PYTHON_LDFLAGS="${PYTHON_LDFLAGS} -L${PY_ZLIB_LIB}"
    PYTHON_CPPFLAGS="${PYTHON_CPPFLAGS} -I${PY_ZLIB_INCLUDE}"

    info "Configuring Python"
    set -x
    ./configure OPT="$PYTHON_OPT" CXX="$cxxCompiler" CC="$cCompiler" \
                LDFLAGS="$PYTHON_LDFLAGS" \
                CPPFLAGS="$PYTHON_CPPFLAGS" \
                ${PYTHON_SHARED} \
                --prefix="$PYTHON_PREFIX_DIR" --disable-ipv6
    set +x

    if [[ $? != 0 ]] ; then
        warn "Python configure failed.  Giving up"
        return 1
    fi

    #
    # Build Python.
    #
    info "Building Python . . . (~3 minutes)"
    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Python build failed.  Giving up"
        return 1
    fi
    info "Installing Python . . ."
    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "Python build (make install) failed.  Giving up"
        return 1
    fi

    cd "$START_DIR"
    info "Done with Python"


    # wheel and its dependencies
    download_py_module ${PY_FLITCORE_FILE} ${PY_FLITCORE_URL}
    if test $? -ne 0 ; then
        return 1
    fi
  
    download_py_module ${PY_WHEEL_FILE} ${PY_WHEEL_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_FLITCORE_BUILD_DIR} ${PY_FLITCORE_FILE}  "flit_core"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_WHEEL_BUILD_DIR} ${PY_WHEEL_FILE} "wheel"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_FLITCORE_BUILD_DIR} "flit_core"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_WHEEL_BUILD_DIR} "wheel"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    # setuptools
    # need the newest version required by a module, not the default
    # version from python
    download_py_module ${PY_SETUPTOOLS_FILE} ${PY_SETUPTOOLS_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SETUPTOOLS_BUILD_DIR} ${PY_SETUPTOOLS_FILE} "setuptools"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SETUPTOOLS_BUILD_DIR} "setuptools"
    if test $? -ne 0 ; then
        return 1
    fi

    fix_py_permissions

    info "Done with python setuptools module."
    return 0

}

# *************************************************************************** #
#                            Function 7.1, build_pillow                       #
# *************************************************************************** #
function build_pillow
{
    download_py_module ${PY_PILLOW_FILE} ${PY_PILLOW_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_PILLOW_BUILD_DIR} ${PY_PILLOW_FILE} "pillow"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    # Pillow depends on Zlib
    PY_ZLIB_INCLUDE="$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/include"
    PY_ZLIB_LIB="$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH/lib"

    PYEXT_CFLAGS="${CFLAGS} ${C_OPT_FLAGS}"
    PYEXT_CFLAGS="${CFLAGS} ${C_OPT_FLAGS} -I${PY_ZLIB_INCLUDE}"
    PYEXT_CXXFLAGS="${CXXFLAGS} ${CXX_OPT_FLAGS} -I${PY_ZLIB_INCLUDE}"
    PYEXT_LDFLAGS="-L${PY_ZLIB_LIB}"

    if [[ "$OPSYS" == "Darwin" ]]; then
        PYEXT_CFLAGS="${PYEXT_CFLAGS} -I/opt/X11/include"
        PYEXT_CXXFLAGS="${PYEXT_CXXFLAGS} -I/opt/X11/include"
    fi

    pushd $PY_PILLOW_BUILD_DIR > /dev/null

    info "Building Pillow ...\n" \
    set -x
    CC=${C_COMPILER} CXX=${CXX_COMPILER} CFLAGS="${PYEXT_CFLAGS}" \
     CXXFLAGS="${PYEXT_CXXFLAGS}" \
     LDFLAGS="${PYEXT_LDFLAGS}" \
     ${PYTHON_COMMAND} ./setup.py build_ext --disable-webp --disable-webpmux --disable-freetype --disable-lcms --disable-tiff --disable-xcb --disable-jpeg2000 --disable-jpeg install --prefix="${PYHOME}" --single-version-externally-managed --record record.txt
    set +x

    if test $? -ne 0 ; then
        popd > /dev/null
        warn "Could not build and install Pillow"
        return 1
    fi
    popd > /dev/null

    # Pillow installs into site-packages dir of Visit's Python.
    # Simply re-execute the python perms command.
    fix_py_permissions

    info "Done with Pillow."
    return 0
}


# *************************************************************************** #
#                            Function 7.3, build_requests                     #
# *************************************************************************** #
function build_requests
{
    download_py_module ${PY_CERTIFI_FILE} ${PY_CERTIFIY_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_TOML_FILE} ${PY_TOML_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_TOMLI_FILE} ${PY_TOMLI_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_PATHSPEC_FILE} ${PY_PATHSPEC_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_CALVER_FILE} ${PY_TCALVER_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_TROVECLASSIFIERS_FILE} ${PY_TROVECLASSIFIERS_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_PACKAGING_FILE} ${PY_PACKAGING_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_EDITABLES_FILE} ${PY_EDITABLES_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_PLUGGY_FILE} ${PY_PLUGGY_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_HATCHLING_FILE} ${PY_HATCHLING_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_URLLIB3_FILE} ${PY_URLLIB3_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_IDNA_FILE} ${PY_IDNA_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_CHARSET_NORMALIZER_FILE} ${PY_CHARSET_NORMALIZER_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_CERTIFI_BUILD_DIR} ${PY_CERTIFI_FILE} "certifi"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_TOML_BUILD_DIR} ${PY_TOML_FILE} "toml"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_TOMLI_BUILD_DIR} ${PY_TOMLI_FILE} "tomli"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_PATHSPEC_BUILD_DIR} ${PY_PATHSPEC_FILE} "pathspec"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_CALVER_BUILD_DIR} ${PY_CALVER_FILE} "calver"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_TROVECLASSIFIERS_BUILD_DIR} ${PY_TROVECLASSIFIERS_FILE} "trove_classifiers"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_PACKAGING_BUILD_DIR} ${PY_PACKAGING_FILE} "packaging"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_EDITABLES_BUILD_DIR} ${PY_EDITABLES_FILE} "editables"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_PLUGGY_BUILD_DIR} ${PY_PLUGGY_FILE} "pluggy"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_HATCHLING_BUILD_DIR} ${PY_HATCHLING_FILE} "hatchling"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_URLLIB3_BUILD_DIR} ${PY_URLLIB3_FILE} "urllib3"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_IDNA_BUILD_DIR} ${PY_IDNA_FILE} "idna"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_CHARSET_NORMALIZER_BUILD_DIR} ${PY_CHARSET_NORMALIZER_FILE} "charset-normalizer"
    if test $? -ne 0 ; then
            return 1
    fi

    install_py_module ${PY_CERTIFI_BUILD_DIR} "certifi"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_TOML_BUILD_DIR} "toml"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_TOMLI_BUILD_DIR} "tomlI"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_PATHSPEC_BUILD_DIR} "pathspec"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_CALVER_BUILD_DIR} "calver"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_TROVECLASSIFIERS_BUILD_DIR} "trove_classifiers"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_PACKAGING_BUILD_DIR} "packaging"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_EDITABLES_BUILD_DIR} "editables"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_PLUGGY_BUILD_DIR} "pluggy"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_HATCHLING_BUILD_DIR} "hatchling"
    if test $? -ne 0 ; then
          return 1
    fi

    install_py_module ${PY_URLLIB3_BUILD_DIR} "urllib3"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_IDNA_BUILD_DIR} "idna"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_CHARSET_NORMALIZER_BUILD_DIR} "charset-normalizer"
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_REQUESTS_FILE} ${PY_REQUESTS_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_REQUESTS_BUILD_DIR} ${PY_REQUESTS_FILE} "requests"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_REQUESTS_BUILD_DIR} "requests"
    if test $? -ne 0 ; then
        return 1
    fi

    # installs into site-packages dir of VisIt's Python.
    # Simply re-execute the python perms command.
    fix_py_permissions

    info "Done with python requests module."
    return 0
}

# *************************************************************************** #
#                                  build_mpi4py                               #
# *************************************************************************** #
function build_mpi4py
{
    download_py_module ${PY_MPI4PY_FILE} ${PY_MPI4PY_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_MPI4PY_BUILD_DIR} ${PY_MPI4PY_FILE} "mpi4py"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_MPI4PY_BUILD_DIR} "mpi4py"
    if test $? -ne 0 ; then
        return 1
    fi

    fix_py_permissions

    return 0
}

# *************************************************************************** #
#                                  build_numpy                                #
# *************************************************************************** #
function build_numpy
{
    download_py_module ${PY_CYTHON_FILE} ${PY_CYTHON_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    download_py_module ${PY_NUMPY_FILE} ${PY_NUMPY_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_CYTHON_BUILD_DIR} ${PY_CYTHON_FILE} "cython"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_NUMPY_BUILD_DIR} ${PY_NUMPY_FILE} "numpy"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    install_py_module ${PY_CYTHON_BUILD_DIR} "cython"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    # Disable blas and lapack on macOS but only if user isn't somehow fiddling with them also.
    # https://numpy.org/doc/1.25/user/building.html#disabling-atlas-and-other-accelerated-libraries
    we_set_numpy_lib_vars=0
    if [ "$OPSYS" == "Darwin" ] && [ -z "$NPY_BLAS_ORDER" ] && [ -z "$NPY_LAPACK_ORDER" ]; then
        we_set_numpy_lib_vars=1
        export NPY_BLAS_ORDER= NPY_LAPACK_ORDER=
    fi
    install_py_module ${PY_NUMPY_BUILD_DIR} "numpy"
    return_status=$?
    if [ $we_set_numpy_lib_vars -eq 1 ]; then
        unset NPY_BLAS_ORDER NPY_LAPACK_ORDER
    fi
    if [ $return_status -ne 0 ] ; then
        return 1
    fi

    fix_py_permissions

    return 0
}

# *************************************************************************** #
#                                  build_sphinx                               #
# *************************************************************************** #
function build_sphinx
{
    info "building sphinx"

    download_py_module ${PY_PACKAGING_FILE} ${PY_PACKAGING_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_IMAGESIZE_FILE} ${PY_IMAGESIZE_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_ALABASTER_FILE} ${PY_ALABASTER_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_BABEL_FILE} ${PY_BABEL_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SNOWBALLSTEMMER_FILE} ${PY_SNOWBALLSTEMMER_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_DOCUTILS_FILE} ${PY_DOCUTILS_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_PYGMENTS_FILE} ${PY_PYGMENTS_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_JINJA2_FILE} ${PY_JINJA2_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINXCONTRIB_QTHELP_FILE} ${PY_SPHINXCONTRIB_QTHELP_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINXCONTRIB_SERIALIZINGHTML_FILE} ${PY_SPHINXCONTRIB_SERIALIZINGHTML_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINXCONTRIB_HTMLHELP_FILE} ${PY_SPHINXCONTRIB_HTMLHELP_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINXCONTRIB_JSMATH_FILE} ${PY_SPHINXCONTRIB_JSMATH_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINXCONTRIB_DEVHELP_FILE} ${PY_SPHINXCONTRIB_DEVHELP_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINXCONTRIB_APPLEHELP_FILE} ${PY_SPHINXCONTRIB_APPLEHELP_ULR}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_MARKUPSAFE_FILE} ${PY_MARKUPSAFE_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_ZIPP_FILE} ${PY_ZIPP_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_IMPORTLIB_METADATA_FILE} ${PY_IMPORTLIB_METADATA_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    download_py_module ${PY_SPHINX_FILE} ${PY_SPHINX_URL}
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_PACKAGING_BUILD_DIR} ${PY_PACKAGING_FILE} "packaging"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_IMAGESIZE_BUILD_DIR} ${PY_IMAGESIZE_FILE} "imagesize"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_ALABASTER_BUILD_DIR} ${PY_ALABASTER_FILE} "alabaster"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_BABEL_BUILD_DIR} ${PY_BABEL_FILE} "babel"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SNOWBALLSTEMMER_BUILD_DIR} ${PY_SNOWBALLSTEMMER_FILE} "snowballstemmer"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_DOCUTILS_BUILD_DIR} ${PY_DOCUTILS_FILE} "docutils"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_PYGMENTS_BUILD_DIR} ${PY_PYGMENTS_FILE} "pygments"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_JINJA2_BUILD_DIR} ${PY_JINJA2_FILE} "jinja2"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_QTHELP_BUILD_DIR} ${PY_SPHINXCONTRIB_QTHELP_FILE} "sphinxcontrib-qthelp"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_SERIALIZINGHTML_BUILD_DIR} ${PY_SPHINXCONTRIB_SERIALIZINGHTML_FILE} "sphinxcontrib-serializinghtml"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_HTMLHELP_BUILD_DIR} ${PY_SPHINXCONTRIB_HTMLHELP_FILE} "sphinxcontrib-htmlhelp"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_JSMATH_BUILD_DIR} ${PY_SPHINXCONTRIB_JSMATH_FILE} "sphinxcontrib-jsmath"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_DEVHELP_BUILD_DIR} ${PY_SPHINXCONTRIB_DEVHELP_FILE} "sphinxcontrib-devhelp"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_APPLEHELP_BUILD_DIR} ${PY_SPHINXCONTRIB_APPLEHELP_FILE} "sphinxcontrib-applehelp"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_MARKUPSAFE_BUILD_DIR} ${PY_MARKUPSAFE_FILE} "markupsafe"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_ZIPP_BUILD_DIR} ${PY_ZIPP_FILE} "zipp"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_IMPORTLIB_METADATA_BUILD_DIR} ${PY_IMPORTLIB_METADATA_FILE} "importlib-metadata"
    if test $? -ne 0 ; then
        return 1
    fi

    extract_py_module ${PY_SPHINX_BUILD_DIR} ${PY_SPHINX_FILE} "sphinx"
    if test $? -ne 0 ; then
        return 1
    fi

    # patch
    SED_CMD="sed -i "
    if [[ "$OPSYS" == "Darwin" ]]; then
        SED_CMD="sed -i '' " # the intention of this sed command is foiled by shell variable expansion
    fi
    pushd $PY_SPHINX_BUILD_DIR > /dev/null
    ${SED_CMD} "s/docutils>=0.12/docutils<0.16,>=0.12/" ./Sphinx.egg-info/requires.txt
    ${SED_CMD} "s/docutils>=0.12/docutils<0.16,>=0.12/" ./setup.py
    popd > /dev/null

    install_py_module ${PY_PACKAGING_BUILD_DIR} "packaging"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_IMAGESIZE_BUILD_DIR} "imagesize"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_ALABASTER_BUILD_DIR} "alabaster"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_BABEL_BUILD_DIR} "babel"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SNOWBALLSTEMMER_BUILD_DIR} "snowballstemmer"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_DOCUTILS_BUILD_DIR} "docutils"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_PYGMENTS_BUILD_DIR} "pygments"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_MARKUPSAFE_BUILD_DIR} "markupsafe"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_JINJA2_BUILD_DIR} "jinja2"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_QTHELP_BUILD_DIR} "sphinxcontrib-qthelp"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_SERIALIZINGHTML_BUILD_DIR} "sphinxcontrib-serializinghtml"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_HTMLHELP_BUILD_DIR} "sphinxcontrib-htmlhelp"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_JSMATH_BUILD_DIR} "sphinxcontrib-jsmath"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_DEVHELP_BUILD_DIR} "sphinxcontrib-devhelp"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_APPLEHELP_BUILD_DIR} "sphinxcontrib-applehelp"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_ZIPP_BUILD_DIR} "zipp"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_IMPORTLIB_METADATA_BUILD_DIR} "importlib-metadata"
    if test $? -ne 0 ; then
        return 1
    fi

    install_py_module ${PY_SPHINX_BUILD_DIR} "sphinx"
    if test $? -ne 0 ; then
        return 1
    fi

    fix_py_permissions

    # fix shebangs. On Darwin, if python is available in Xcode,
    # Sphinx scripts may get installed with shebangs that are absolute
    # paths to Xcode's python interpreter. We want VisIt's python.
    if [[ "$OPSYS" == "Darwin" ]]; then
        for f in ${VISIT_PYTHON_DIR}/bin/*; do
            if [[ -z "$(file $f | grep -i 'ascii text')" ]]; then
                continue # Process only scripts
            fi
            # -i '' means do in-place...don't create backups
            # 1s means do substitution only on line 1
            # @ choosen as sep char for s sed cmd to not collide w/slashes
            # ! needs to be escaped with a backslash
            # don't use ${SED_CMD}
            sed -i '' -e "1s@^#\!.*\$@#\!${VISIT_PYTHON_DIR}/bin/python3@" $f
        done
    fi

    return 0
}

# *************************************************************************** #
#                              build_sphinx_rtd                               #
# *************************************************************************** #
function build_sphinx_rtd
{
    download_py_module ${PY_SPHINXCONTRIB_JQUERY_FILE} ${PY_SPHINXCONTRIB_JQUERY_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_SPHINXCONTRIB_JQUERY_BUILD_DIR} ${PY_SPHINXCONTRIB_JQUERY_FILE} "sphinxcontrib-jquery"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    install_py_module ${PY_SPHINXCONTRIB_JQUERY_BUILD_DIR} "sphinxcontrib-jquery"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    download_py_module ${PY_SPHINX_RTD_THEME_FILE} ${PY_SPHINX_RTD_THEME_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_SPHINX_RTD_THEME_BUILD_DIR} ${PY_SPHINX_RTD_THEME_FILE} "sphinx_rtd_theme"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    install_py_module ${PY_SPHINX_RTD_THEME_BUILD_DIR} "sphinx_rtd_theme"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    fix_py_permissions

    return 0
}

# *************************************************************************** #
#                              build_sphinx_tabs                              #
# *************************************************************************** #
function build_sphinx_tabs
{
    download_py_module ${PY_SPHINX_TABS_FILE} ${PY_SPHINX_TABS_URL}
    if [[ $? != 0 ]] ; then
        return 1
    fi

    extract_py_module ${PY_SPHINX_TABS_BUILD_DIR} ${PY_SPHINX_TABS_FILE} "sphinx-tabs"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    install_py_module ${PY_SPHINX_TABS_BUILD_DIR} "sphinx-tabs"
    if [[ $? != 0 ]] ; then
        return 1
    fi

    fix_py_permissions

    return 0
}

function bv_python_is_enabled
{
    if [[ $DO_PYTHON == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_python_is_installed
{
    PY_CHECK_ECHO=0
    if [[ $# == 1 ]]; then
        PY_CHECK_ECHO=$1
    fi
    
    info "checking if python is installed"
    # byo python, assume mods are there
    if [[ $USE_SYSTEM_PYTHON == "yes" ]]; then
        return 1
    fi
    
    check_if_installed "python" $PYTHON_VERSION
    if [[ $? != 0 ]] ; then
        if [[ $PY_CHECK_ECHO != 0 ]] ; then
            info "python is not installed"
        fi
        return 0
    fi

    PY_OK=1

    # we also need to check all the python modules ...
    check_if_py_module_installed "PIL"
    if [[ $? != 0 ]] ; then
        if [[ $PY_CHECK_ECHO != 0 ]] ; then
            info "python module Pillow is not installed"
        fi
        PY_OK=0
    fi

    check_if_py_module_installed "numpy"
    if [[ $? != 0 ]] ; then
        if [[ $PY_CHECK_ECHO != 0 ]] ; then
            info "python module numpy is not installed"
        fi
        PY_OK=0
    fi

    if [[ "$PY_BUILD_SPHINX" == "yes" ]]; then

        check_if_py_module_installed "sphinx"
        if [[ $? != 0 ]] ; then
            if [[ $PY_CHECK_ECHO != 0 ]] ; then
                info "python module sphinx is not installed"
            fi
            PY_OK=0
        fi

        check_if_py_module_installed "sphinx_rtd_theme"
        if [[ $? != 0 ]] ; then
            if [[ $PY_CHECK_ECHO != 0 ]] ; then
                info "python module sphinx_rtd_theme is not installed"
            fi
            PY_OK=0
        fi
        check_if_py_module_installed "sphinx_tabs"
        if [[ $? != 0 ]] ; then
            if [[ $PY_CHECK_ECHO != 0 ]] ; then
                info "python module sphinx_tabs is not installed"
            fi
            PY_OK=0
        fi

    fi

    if [[ "$PY_BUILD_MPI4PY" == "yes" ]]; then

        check_if_py_module_installed "mpi4py"
        if [[ $? != 0 ]] ; then
            if [[ $PY_CHECK_ECHO != 0 ]] ; then
                info "python module mpi4py is not installed"
            fi
            PY_OK=0
        fi
    fi

    return $PY_OK
}

function bv_python_build
{
    #
    # Build Python
    #
    cd "$START_DIR"
    if [[ "$DO_PYTHON" == "yes" && "$USE_SYSTEM_PYTHON" == "no" ]] ; then

        bv_python_is_installed 1
        
        if [[ $? == 1 ]] ; then
            info "Skipping Python build.  Python is already installed."
        else

            # check python proper, then mods
            check_if_installed "python" $PYTHON_VERSION
            if [[ $? != 0 ]] ; then
                info "Building Python (~3 minutes)"
                build_python
                if [[ $? != 0 ]] ; then
                    error "Unable to build or install Python.  Bailing out."
                fi
                info "Done building Python"
            fi

            # Do not build those packages for a static build!
            if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
                return 0
            fi

            # setup PYHOME and PYTHON_COMMAND which is used in our build
            # of these python modules
            export PYHOME="${VISITDIR}/python/${PYTHON_VERSION}/${VISITARCH}"
            export PYTHON_COMMAND="${PYHOME}/bin/python3"

            check_if_py_module_installed "numpy"
            if [[ $? != 0 ]] ; then
                info "Building the numpy module"
                build_numpy
                if [[ $? != 0 ]] ; then
                    error "numpy build failed. Bailing out."
                fi
                info "Done building the numpy module."
            fi

            check_if_py_module_installed "PIL"
            # use Pillow for when python 3
            if [[ $? != 0 ]] ; then
                info "Building the Python Pillow Imaging Library"
                build_pillow
                if [[ $? != 0 ]] ; then
                    error "Pillow build failed. Bailing out."
                fi
                info "Done building the Python Pillow Imaging Library"
            fi

            if [[ "$PY_BUILD_MPI4PY" == "yes" ]]; then

                check_if_py_module_installed "mpi4py"
                if [[ $? != 0 ]] ; then
                    info "Building the mpi4py module"
                    build_mpi4py
                    if [[ $? != 0 ]] ; then
                        error "mpi4py build failed. Bailing out."
                    fi
                    info "Done building the mpi4py module"
                fi
            fi

            if [[ "$PY_BUILD_SPHINX" == "yes" ]]; then
                # requests is needed by sphinx.
                check_if_py_module_installed "requests"
                if [[ $? != 0 ]] ; then
                    build_requests
                    if [[ $? != 0 ]] ; then
                        error "requests python module build failed. Bailing out."
                    fi
                    info "Done building the requests python module."
                fi

                check_if_py_module_installed "sphinx"
                if [[ $? != 0 ]] ; then
                    build_sphinx
                    if [[ $? != 0 ]] ; then
                        error "sphinx python module build failed. Bailing out."
                    fi
                    info "Done building the sphinx python module."
                fi

                check_if_py_module_installed "sphinx_rtd_theme"
                if [[ $? != 0 ]] ; then
                    build_sphinx_rtd
                    if [[ $? != 0 ]] ; then
                        error "sphinx rtd python theme build failed. Bailing out."
                    fi
                    info "Done building the sphinx rtd python theme."
                fi

                check_if_py_module_installed "sphinx_tabs"
                if [[ $? != 0 ]] ; then
                    build_sphinx_tabs
                    if [[ $? != 0 ]] ; then
                        error "sphinx tabs python module build failed. Bailing out."
                    fi
                    info "Done building the sphinx tabs."
                fi
            fi
        fi
    fi
}

function bv_qt_initialize
{
    export DO_QT="yes"
}

function bv_qt_enable
{
    DO_QT="yes"
}

function bv_qt_disable
{
    DO_QT="no"
}

function bv_qt_depends_on
{
    QT_DEPENDS=""
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        QT_DEPENDS="mesagl glu"
    fi
    if [[ "$DO_XKBCOMMON" == "yes" ]] ; then
        QT_DEPENDS="$QT_DEPENDS xkbcommon"
    fi
    if [[ "$DO_XCB" == "yes" ]] ; then
        QT_DEPENDS="$QT_DEPENDS xcb"
    fi

    echo $QT_DEPENDS
}

function bv_qt_info
{
    export QT_VERSION=${QT_VERSION:-"6.4.2"}
    export QT_SHORT_VERSION=${QT_SHORT_VERSION:-"6.4"}
    export QT_BASE_FILE=${QT_BASE_FILE:-"qtbase-everywhere-src-${QT_VERSION}.tar.xz"}
    export QT_BASE_SOURCE_DIR=${QT_BASE_SOURCE_DIR:-"qtbase-everywhere-src-${QT_VERSION}"}
    export QT_BASE_SHA256_CHECKSUM="a88bc6cedbb34878a49a622baa79cace78cfbad4f95fdbd3656ddb21c705525d"

    # Other submodules
    export QT_TOOLS_FILE=${QT_TOOLS_FILE:-"qttools-everywhere-src-${QT_VERSION}.tar.xz"}
    export QT_TOOLS_SOURCE_DIR=${QT_TOOLS_SOURCE_DIR:-"qttools-everywhere-src-${QT_VERSION}"}
    export QT_TOOLS_SHA256_CHECKSUM="a31387916184e4a5ef522d3ea841e8e931cc0f88be0824a7a354a572d5826c68"
    export QT_SVG_FILE=${QT_SVG_FILE:-"qtsvg-everywhere-src-${QT_VERSION}.tar.xz"}
    export QT_SVG_SOURCE_DIR=${QT_SVG_SOURCE_DIR:-"qtsvg-everywhere-src-${QT_VERSION}"}
    export QT_SVG_SHA256_CHECKSUM="b746af3cb1793621d8ed7eae38d9ad5a15541dc2742031069f2ae3fe87590314"
}

function bv_qt_print
{
    printf "%s%s\n" "QT_BASE_FILE=" "${QT_BASE_FILE}"
    printf "%s%s\n" "QT_VERSION=" "${QT_VERSION}"
    printf "%s%s\n" "QT_SHORT_VERSION=" "${QT_SHORT_VERSION}"
    printf "%s%s\n" "QT_BASE_SOURCE_DIR=" "${QT_BASE_SOURCE_DIR}"
}

function bv_qt_print_usage
{
    printf "%-20s %s [%s]\n" "--qt"   "Build QT" "$DO_QT"
}

function bv_qt_host_profile
{
    # bv_qt_host_profile has tests for ENGINE_ONLY etc, but if any of those conditions
    # are set, then DO_QT is "no", so no need to test for them here.
    if [[ "$DO_QT" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## QT" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "SETUP_APP_VERSION(QT $QT_VERSION)" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_QT_DIR \${VISITHOME}/qt/$QT_VERSION/\${VISITARCH})" >> $HOSTCONF
     fi
}

function bv_qt_initialize_vars
{
    info "initializing qt vars"
    QT_INSTALL_DIR="${VISITDIR}/qt/${QT_VERSION}/${VISITARCH}"
    QT_BIN_DIR="$QT_INSTALL_DIR/bin"
    QT_INCLUDE_DIR="$QT_INSTALL_DIR/include"
    info "qt_BIN dir ${QT_BIN_DIR}"
}

#prepare the module and check whether it is built or is ready to be built.
function bv_qt_ensure
{
    if [[ "$DO_QT" == "yes" ]]; then
        if [[ "$DOWNLOAD_ONLY" == "yes" ]] ; then
            download_file ${QT_TOOLS_FILE} ${QT_URL}
            download_file ${QT_SVG_FILE} ${QT_URL}
        fi
        ensure_built_or_ready "qt"     $QT_VERSION    $QT_BASE_SOURCE_DIR    $QT_BASE_FILE    $QT_URL
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi
    return 0
}


function apply_qt_base_patch
{
    if [[ ${QT_VERSION} == 6.4.2 ]] ; then
        if [[ "$OPSYS" == "Darwin" ]] ; then

            qt6_macos_13_cpp_stdlib_issue_patch
            if [[ $? != 0 ]] ; then
                return 1
            fi

            qt6_macos_14_xcode_15_patch
            if [[ $? != 0 ]] ; then
                return 1
            fi

            qt6_macos_15_opengl_patch
            if [[ $? != 0 ]] ; then
                return 1
            fi
        fi

        qt6_xkbcommon_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi

        qt6_libpng_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi
}

function qt6_macos_15_opengl_patch
{
    info "Patching qt 6 for macos opengl linking issue"
    patch -p0 << \EOF
    From 0efea8020c1d221635aaa0a71529edb392cfe3cc Mon Sep 17 00:00:00 2001
From: Joerg Bornemann <joerg.bornemann@qt.io>
Date: Mon, 11 Sep 2023 14:48:32 +0200
Subject: [PATCH] CMake: Fix build with CMake 3.28 on macOS

FindWrapOpenGL.cmake assumed that IMPORTED_LOCATION is the absolute path
of the library within the framework. That's not the case with CMake 3.28
anymore. There, IMPORTED_LOCATION is the absolute path of the framework
directory.

The relevant upstream CMake change is
6b01a27f901b5eb392955fea322cde44a1b782a3.

Pick-to: 6.2 6.5 6.6
Change-Id: I6b702a28318e0978c56dec83c398965aa77ef020
Reviewed-by: Alexandru Croitor <alexandru.croitor@qt.io>
---
 qtbase-everywhere-src-6.4.2/cmake/FindWrapOpenGL.cmake | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

diff --git qtbase-everywhere-src-6.4.2/cmake/FindWrapOpenGL.cmake qtbase-everywhere-src-6.4.2/cmake/FindWrapOpenGL.cmake
index 3e6abaf4dda7..7295a159caf6 100644
--- qtbase-everywhere-src-6.4.2/cmake/FindWrapOpenGL.cmake
+++ qtbase-everywhere-src-6.4.2/cmake/FindWrapOpenGL.cmake
@@ -17,14 +17,18 @@ if (OpenGL_FOUND)

     add_library(WrapOpenGL::WrapOpenGL INTERFACE IMPORTED)
     if(APPLE)
+        # CMake 3.27 and older:
         # On Darwin platforms FindOpenGL sets IMPORTED_LOCATION to the absolute path of the library
         # within the framework. This ends up as an absolute path link flag, which we don't want,
         # because that makes our .prl files un-relocatable.
         # Extract the framework path instead, and use that in INTERFACE_LINK_LIBRARIES,
-        # which CMake ends up transforming into a reloctable -framework flag.
+        # which CMake ends up transforming into a relocatable -framework flag.
         # See https://gitlab.kitware.com/cmake/cmake/-/issues/20871 for details.
+        #
+        # CMake 3.28 and above:
+        # IMPORTED_LOCATION is the absolute path the the OpenGL.framework folder.
         get_target_property(__opengl_fw_lib_path OpenGL::GL IMPORTED_LOCATION)
-        if(__opengl_fw_lib_path)
+        if(__opengl_fw_lib_path AND NOT __opengl_fw_lib_path MATCHES "/([^/]+)\\.framework$")
             get_filename_component(__opengl_fw_path "${__opengl_fw_lib_path}" DIRECTORY)
         endif()
EOF

}

function qt6_libpng_patch
{
    info "Patching qt 6 for libpng header issue"
    patch -p0 << \EOF
diff --git qtbase-everywhere-src-6.4.2/src/3rdparty/libpng/pngpriv.h qtbase-everywhere-src-6.4.2/src/3rdparty/libpng//pngpriv.h
index 6c7280cf53..190eb85cbf 100644
--- qtbase-everywhere-src-6.4.2/src/3rdparty/libpng/a/pngpriv.h
+++ qtbase-everywhere-src-6.4.2/src/3rdparty/libpng//pngpriv.h
@@ -556,18 +556,8 @@
     */
 #  include <float.h>

-#  if (defined(__MWERKS__) && defined(macintosh)) || defined(applec) || \
-    defined(THINK_C) || defined(__SC__) || defined(TARGET_OS_MAC)
-   /* We need to check that <math.h> hasn't already been included earlier
-    * as it seems it doesn't agree with <fp.h>, yet we should really use
-    * <fp.h> if possible.
-    */
-#    if !defined(__MATH_H__) && !defined(__MATH_H) && !defined(__cmath__)
-#      include <fp.h>
-#    endif
-#  else
-#    include <math.h>
-#  endif
+#  include <math.h>
+
 #  if defined(_AMIGA) && defined(__SASC) && defined(_M68881)
    /* Amiga SAS/C: We must include builtin FPU functions when compiling using
     * MATH=68881
EOF

}

function qt6_xkbcommon_patch
{
    info "Patching qt 6 for xkbcommon issue"
    patch -p0 << \EOF
-- qtbase-everywhere-src-6.4.2/src/gui/platform/unix/qxkbcommon.cpp.orig	2024-05-21 08:51:16.000000000 -0700
+++ qtbase-everywhere-src-6.4.2/src/gui/platform/unix/qxkbcommon.cpp	2024-05-21 08:50:33.000000000 -0700
@@ -236,16 +236,20 @@
         Xkb2Qt<XKB_KEY_dead_O,                  Qt::Key_Dead_O>,
         Xkb2Qt<XKB_KEY_dead_u,                  Qt::Key_Dead_u>,
         Xkb2Qt<XKB_KEY_dead_U,                  Qt::Key_Dead_U>,
         Xkb2Qt<XKB_KEY_dead_small_schwa,        Qt::Key_Dead_Small_Schwa>,
         Xkb2Qt<XKB_KEY_dead_capital_schwa,      Qt::Key_Dead_Capital_Schwa>,
         Xkb2Qt<XKB_KEY_dead_greek,              Qt::Key_Dead_Greek>,
+/* The following for XKB_KEY_dead keys got removed in libxkbcommon 1.6.0
+   The define check is kind of version check here. */
+#ifdef XKB_KEY_dead_lowline
         Xkb2Qt<XKB_KEY_dead_lowline,            Qt::Key_Dead_Lowline>,
         Xkb2Qt<XKB_KEY_dead_aboveverticalline,  Qt::Key_Dead_Aboveverticalline>,
         Xkb2Qt<XKB_KEY_dead_belowverticalline,  Qt::Key_Dead_Belowverticalline>,
         Xkb2Qt<XKB_KEY_dead_longsolidusoverlay, Qt::Key_Dead_Longsolidusoverlay>,
+#endif

         // Special keys from X.org - This include multimedia keys,
         // wireless/bluetooth/uwb keys, special launcher keys, etc.
         Xkb2Qt<XKB_KEY_XF86Back,                Qt::Key_Back>,
         Xkb2Qt<XKB_KEY_XF86Forward,             Qt::Key_Forward>,
         Xkb2Qt<XKB_KEY_XF86Stop,                Qt::Key_Stop>,
EOF
    if [[ $? != 0 ]] ; then
        warn "Patching qt 6 for xkbcommon issue failed"
        return 1
    fi
}


function qt6_macos_13_cpp_stdlib_issue_patch
{
    info "Patching qt 6 for macOS c++ stdlib issue"

    patch -p0 << \EOF
diff -crB qtbase-everywhere-src-6.4.2/src/corelib/tools/qduplicatetracker_p.h qtbase-everywhere-src-6.4.2-patched/src/corelib/tools/qduplicatetracker_p.h
*** qtbase-everywhere-src-6.4.2/src/corelib/tools/qduplicatetracker_p.h	Tue Nov 15 23:54:24 2022
--- qtbase-everywhere-src-6.4.2-patched/src/corelib/tools/qduplicatetracker_p.h	Wed Oct 25 13:14:40 2023
***************
*** 16,33 ****

  #include <private/qglobal_p.h>

! #if __has_include(<memory_resource>)
! #  include <unordered_set>
! #  include <memory_resource>
! #  include <qhash.h> // for the hashing helpers
! #else
! #  include <qset.h>
! #endif

  QT_BEGIN_NAMESPACE

  template <typename T, size_t Prealloc = 32>
  class QDuplicateTracker {
  #ifdef __cpp_lib_memory_resource
      template <typename HT>
      struct QHasher {
--- 16,38 ----

  #include <private/qglobal_p.h>

! // Only supported on macOS 14 and iOS 17
! // #if __has_include(<memory_resource>)
! // #  include <unordered_set>
! // #  include <memory_resource>
! // #  include <qhash.h> // for the hashing helpers
! // #else
! // #  include <qset.h>
! // #endif

+ #undef __cpp_lib_memory_resource // Only supported on macOS 14 and iOS 17
+ #include <qset.h>
+
  QT_BEGIN_NAMESPACE

  template <typename T, size_t Prealloc = 32>
  class QDuplicateTracker {
+ #undef __cpp_lib_memory_resource // Only supported on macOS 14 and iOS 17
  #ifdef __cpp_lib_memory_resource
      template <typename HT>
      struct QHasher {
***************
*** 70,75 ****
--- 75,81 ----
      Q_DISABLE_COPY_MOVE(QDuplicateTracker);
  public:
      static constexpr inline bool uses_pmr =
+ #undef __cpp_lib_memory_resource // Only supported on macOS 14 and iOS 17
          #ifdef __cpp_lib_memory_resource
              true
          #else
***************
*** 78,83 ****
--- 84,90 ----
              ;
      QDuplicateTracker() = default;
      explicit QDuplicateTracker(qsizetype n)
+ #undef __cpp_lib_memory_resource // Only supported on macOS 14 and iOS 17
  #ifdef __cpp_lib_memory_resource
          : set{size_t(n), &res}
  #else
diff -crB qtbase-everywhere-src-6.4.2/src/gui/image/qxpmhandler.cpp qtbase-everywhere-src-6.4.2-patched/src/gui/image/qxpmhandler.cpp
*** qtbase-everywhere-src-6.4.2/src/gui/image/qxpmhandler.cpp	Tue Nov 15 23:54:24 2022
--- qtbase-everywhere-src-6.4.2-patched/src/gui/image/qxpmhandler.cpp	Wed Oct 25 12:58:52 2023
***************
*** 1078,1083 ****
--- 1078,1084 ----
      else
          image = sourceImage;

+ #undef __cpp_lib_memory_resource
  #ifdef __cpp_lib_memory_resource
      char buffer[1024];
      std::pmr::monotonic_buffer_resource res{&buffer, sizeof buffer};

EOF
    if [[ $? != 0 ]] ; then
        warn "Patching qt 6for macOS c++ stdlib issue failed"
        return 1
    fi
}

function qt6_macos_14_xcode_15_patch
{
    info "Patching qt 6 for macOS xcode 15 with toolchain fix"

    patch -p0 << \EOF
diff --git qtbase-everywhere-src-6.4.2/mkspecs/features/toolchain.prf qtbase-everywhere-src-6.4.2-patched/mkspecs/features/toolchain.prf
index 0040b6c..bfad10d 100644
--- qtbase-everywhere-src-6.4.2/mkspecs/features/toolchain.prf
+++ qtbase-everywhere-src-6.4.2-patched/mkspecs/features/toolchain.prf
@@ -288,9 +288,12 @@
                 }
             }
         }
-        isEmpty(QMAKE_DEFAULT_LIBDIRS)|isEmpty(QMAKE_DEFAULT_INCDIRS): \
+        isEmpty(QMAKE_DEFAULT_INCDIRS): \
             !integrity: \
-                error("failed to parse default search paths from compiler output")
+                error("failed to parse default include paths from compiler output")
+        isEmpty(QMAKE_DEFAULT_LIBDIRS): \
+            !integrity:!darwin: \
+                error("failed to parse default library paths from compiler output")
         QMAKE_DEFAULT_LIBDIRS = $$unique(QMAKE_DEFAULT_LIBDIRS)
     } else: ghs {
         cmd = $$QMAKE_CXX $$QMAKE_CXXFLAGS -$${LITERAL_HASH} -o /tmp/fake_output /tmp/fake_input.cpp
@@ -411,7 +414,7 @@
         QMAKE_DEFAULT_INCDIRS = $$split(INCLUDE, $$QMAKE_DIRLIST_SEP)
     }

-    unix:if(!cross_compile|host_build) {
+    unix:!darwin:if(!cross_compile|host_build) {
         isEmpty(QMAKE_DEFAULT_INCDIRS): QMAKE_DEFAULT_INCDIRS = /usr/include /usr/local/include
         isEmpty(QMAKE_DEFAULT_LIBDIRS): QMAKE_DEFAULT_LIBDIRS = /lib /usr/lib
     }
EOF
    if [[ $? != 0 ]] ; then
        warn "Patching qt 6 for macOS xcode 15 with toolchain fix failed"
        return 1
    fi
}


function build_qt_base
{
    echo "Build Qt 6 base module"
    prepare_build_dir $QT_BASE_SOURCE_DIR $QT_BASE_FILE

    untarred_qt=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_qt == -1 ]] ; then
        warn "Unable to prepare Qt 6 build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching qt . . ."

    apply_qt_base_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_qt == 1 ]] ; then
            warn "Giving up on Qt build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    QT_BASE_BUILD_DIR="${QT_BASE_SOURCE_DIR}-build"
    if ! test -f $QT_BASE_BUILD_DIR ; then
        echo "Making build directory $QT_BASE_BUILD_DIR"
        mkdir $QT_BASE_BUILD_DIR
    fi

    # Qt has a check for symlinks in its build dir,
    # so use 'cd -P' to resolve them if they are present
    cd -P ${QT_BASE_BUILD_DIR}

    #
    # Platform specific configuration
    #

    #
    # Select the proper value for QT_PLATFORM
    #
    # Question: Could qt auto detect this via the CC and CXX env vars?
    #
    # We should try to see if we can avoid setting the platform, set
    # CC and CXX and see if that is enough to trigger qt's detection logic.
    #
    # NOTE, KSB 03-20-2023, setting CC and CXX, on LC toss4, QT chose as
    # QT_QMAKE_TARGET_MKSPEC: linux-g++, not linux-g++-x64
    #


    if [[ "$OPSYS" == "Darwin" ]]; then
        QT_PLATFORM="macx-clang"
    elif [[ "$OPSYS" == "Linux" ]] ; then
        if [[ "$C_COMPILER" == "clang" ]]; then
            QT_PLATFORM="linux-clang"
        elif [[ "$C_COMPILER" == "llvm" ]]; then
            QT_PLATFORM="linux-llvm"
        elif [[ "$(uname -m)" == "ia64" ]]; then
            QT_PLATFORM="linux-g++-64"
        elif [[ "$(uname -m)" == "x86_64" ]] ; then
            if [[ "$C_COMPILER" == "icc" || "$CXX_COMPILER" == "icpc" ]]; then
                QT_PLATFORM="linux-icc-64"
            else
                QT_PLATFORM="linux-g++-64"
            fi
        elif [[ "$(uname -m)" == "ppc64" || "$(uname -m)" == "ppc64le" ]]; then
            QT_PLATFORM="linux-g++-64"
        else
            if [[ "$C_COMPILER" == "icc" || "$CXX_COMPILER" == "icpc" ]]; then
                QT_PLATFORM="linux-icc-32"
            else
                QT_PLATFORM="linux-g++-32"
            fi
        fi
        # For Fedora, disable openssl
        if [[ -n "$(cat /proc/version 2>/dev/null | grep -i fedora)" ]]; then
            EXTRA_QT_FLAGS="$EXTRA_QT_FLAGS -no-openssl"
        fi
    fi

    #
    # Call configure
    #

    if [[ "$DO_XKBCOMMON" == "yes" ]] ; then
        export PKG_CONFIG_PATH=$XKBCOMMON_INSTALL_DIR/lib/pkgconfig:$PKG_CONFIG_PATH
    fi
    if [[ "$DO_XCB" == "yes" ]] ; then
        export PKG_CONFIG_PATH=$XCB_INSTALL_DIR/lib/pkgconfig:$PKG_CONFIG_PATH
    fi

    QT_CFLAGS="${CFLAGS} ${C_OPT_FLAGS}"
    QT_CXXFLAGS="${CXXFLAGS} ${CXX_OPT_FLAGS}"

    qt_flags=""
    qt_flags="${qt_flags} -no-dbus"
    qt_flags="${qt_flags} -no-egl"
    qt_flags="${qt_flags} -no-eglfs"
    qt_flags="${qt_flags} -no-sql-db2"
    qt_flags="${qt_flags} -no-sql-ibase"
    qt_flags="${qt_flags} -no-sql-mysql"
    qt_flags="${qt_flags} -no-sql-oci"
    qt_flags="${qt_flags} -no-sql-odbc"
    qt_flags="${qt_flags} -no-sql-psql"
    qt_flags="${qt_flags} -no-sql-sqlite"
    qt_flags="${qt_flags} -no-libjpeg"
    qt_flags="${qt_flags} -qt-libpng"
    qt_flags="${qt_flags} -qt-zlib"
    qt_flags="${qt_flags} -nomake examples"
    qt_flags="${qt_flags} -nomake tests"
    qt_flags="${qt_flags} -opensource"
    qt_flags="${qt_flags} -confirm-license"
    # should test for static
    qt_flags="${qt_flags} -shared"

    if [[ "$VISIT_BUILD_MODE" == "Release" ]] ; then
        qt_flags="${qt_flags} -release"
    else
        qt_flags="${qt_flags} -debug"
    fi

    qt_cmake_flags=""
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        # '--' separates the qt-configure-style flags from the cmake flags
        qt_cmake_flags=" -- -DOPENGL_INCLUDE_DIR:PATH=${MESAGL_INCLUDE_DIR}"
        qt_cmake_flags="${qt_cmake_flags} -DOPENGL_gl_LIBRARY:STRING=${MESAGL_OPENGL_LIB}"
        qt_cmake_flags="${qt_cmake_flags} -DOPENGL_opengl_LIBRARY:STRING="
        qt_cmake_flags="${qt_cmake_flags} -DOPENGL_glu_LIBRARY:STRING=${MESAGL_GLU_LIB}"
        qt_cmake_flags="${qt_cmake_flags} -DOpenGL_GL_PREFERENCE:STRING=LEGACY"
    fi
    info "Configuring Qt base: . . . "
    set -x
    (echo "o"; echo "yes") | env PATH="${CMAKE_INSTALL}:$PATH" \
                             CFLAGS="${QT_CFLAGS}" CXXFLAGS="${QT_CXXFLAGS}"  \
                             CC="${C_COMPILER}" CXX="${CXX_COMPILER}"  \
                             ../${QT_BASE_SOURCE_DIR}/configure \
                             -prefix ${QT_INSTALL_DIR} ${qt_flags} \
                             ${qt_cmake_flags} | tee qt.config.out
    set +x
    if [[ $? != 0 ]] ; then
        warn "Qt base configure failed. Giving up."
        return 1
    fi

   #
    # Build Qt. Config options above make sure we only build the libs & tools.
    #
    info "Building Qt6 base . . . "
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS

    if [[ $? != 0 ]] ; then
        warn "Qt base build failed.  Giving up"
        return 1
    fi

    info "Installing Qt  base . . . "
    ${CMAKE_COMMAND} --install .

    # Qt screws up permissions in some cases.  Try to fix that.
    chmod -R a+rX ${VISITDIR}/qt/${QT_VERSION}
   if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/qt"
        chgrp -R ${GROUP} "$VISITDIR/qt"
    fi

    cd "$START_DIR"
    info "Done with Qt base "

    return 0
}


function build_qt_tools
{
    cd "$START_DIR"
    echo "Build Qt 6 tools module"

    if ! test -f ${QT_TOOLS_FILE} ; then
        download_file ${QT_TOOLS_FILE} ${QT_URL}
        if [[ $? != 0 ]] ; then
            warn "Could not download ${QT_TOOLS_FILE}"
            return 1
        fi
    fi

    if ! test -d ${QT_TOOLS_SOURCE_DIR} ; then
        info "Extracting qt tools ..."
        uncompress_untar ${QT_TOOLS_FILE}
        if test $? -ne 0 ; then
            warn "Could not extract ${QT_TOOLS_FILE}"
            return 1
        fi
    fi

    # Make a build directory for an out-of-source build.
    QT_TOOLS_BUILD_DIR="${QT_TOOLS_SOURCE_DIR}-build"
    if [[ ! -d $QT_TOOLS_BUILD_DIR ]] ; then
        echo "Making build directory $QT_TOOLS_BUILD_DIR"
        mkdir $QT_TOOLS_BUILD_DIR
    fi

    cd ${QT_TOOLS_BUILD_DIR}

    info "Configuring Qt tools . . . "
    env CC="${C_COMPILER}" CXX="${CXX_COMPILER}"  \
        ${QT_INSTALL_DIR}/bin/qt-configure-module  ../${QT_TOOLS_SOURCE_DIR}

    info "Building Qt6 tools . . . "
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS

    info "Installing Qt tools . . . "
    ${CMAKE_COMMAND} --install .

    return 0;
}

function build_qt_svg
{
    cd "$START_DIR"
    echo "Build Qt 6 svg module"

    if ! test -f ${QT_SVG_FILE} ; then
        download_file ${QT_SVG_FILE} ${QT_URL}
        if [[ $? != 0 ]] ; then
            warn "Could not download ${QT_SVG_FILE}"
            return 1
        fi
    fi

    if ! test -d ${QT_SVG_SOURCE_DIR} ; then
        info "Extracting qt svg ..."
        uncompress_untar ${QT_SVG_FILE}
        if test $? -ne 0 ; then
            warn "Could not extract ${QT_SVG_FILE}"
            return 1
        fi
    fi

    # Make a build directory for an out-of-source build.
    QT_SVG_BUILD_DIR="${QT_SVG_SOURCE_DIR}-build"
    if [[ ! -d $QT_SVG_BUILD_DIR ]] ; then
        echo "Making build directory $QT_SVG_BUILD_DIR"
        mkdir $QT_SVG_BUILD_DIR
    fi

    cd ${QT_SVG_BUILD_DIR}

    info "Configuring Qt svg . . . "
    env CC="${C_COMPILER}" CXX="${CXX_COMPILER}"  \
        ${QT_INSTALL_DIR}/bin/qt-configure-module  ../${QT_SVG_SOURCE_DIR}

    info "Building Qt6 svg . . . "
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS

    info "Installing Qt svg . . . "
    ${CMAKE_COMMAND} --install .

    return 0;
}

function bv_qt_is_enabled
{
    if [[ $DO_QT == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_qt_is_installed
{
    check_if_installed "qt" $QT_VERSION
    if [[ $? != 0 ]] ; then
        return 0
    fi

    # check submodules

    if ! test -f ${QT_INSTALL_DIR}/modules/Tools.json ; then
        return 0
    fi

    if ! test -f ${QT_INSTALL_DIR}/modules/Svg.json ; then
        return 0
    fi
    return 1
}

function bv_qt_build
{
    cd "$START_DIR"
    if [[ "$DO_QT" == "yes" ]] ; then

        # checks if qtbase and all required modules are installed
        bv_qt_is_installed
        if [[ $? == 1 ]] ; then
             info "Skipping Qt build.  Qt is already installed."
        else

            # check qt proper, then submodules
            check_if_installed "qt" $QT_VERSION
            if [[ $? != 0 ]] ; then
                info "Building QT base (~10 minutes)"
                build_qt_base
                if [[ $? != 0 ]] ; then
                    error "Unable to build or install QT.  Bailing out."
                fi
                info "Done building Qt base"
            else
                info "Qt base already exists"
            fi


            # tools submodule
            if test -f ${QT_INSTALL_DIR}/modules/Tools.json ; then
                info "Qt 6 submodule tools already exists"
            else
                info "Building QT tools (~4 minutes)"
                build_qt_tools
            fi

            # svg submodule
            if test -f ${QT_INSTALL_DIR}/modules/Svg.json ; then
                info "Qt 6 submodule svg already exists"
            else
                info "Building QT svg (~2 minutes)"
                build_qt_svg
           fi
        fi
    fi
}
function bv_qwt_initialize
{
    export DO_QWT="no"
    export USE_SYSTEM_QWT="no"
    export USE_ALT_QWT="no"
    add_extra_commandline_args "qwt" "system-qwt" 0 "Use Qwt found on system"
    add_extra_commandline_args "qwt" "alt-qwt-dir" 1 "Use alternative directory for Qwt"
}

function bv_qwt_enable
{
    DO_QWT="yes"
}

function bv_qwt_disable
{
    DO_QWT="no"
}

function bv_qwt_system_qwt
{
    bv_qwt_enable
    echo "using system qwt"
    USE_SYSTEM_QWT="yes"
}

function bv_qwt_alt_qwt_dir
{
    bv_qwt_enable
    USE_ALT_QWT="yes"
    QWT_INSTALL_DIR="$1"
}

function bv_qwt_depends_on
{
    if [[ "$USE_SYSTEM_QWT" == "yes" || "$USE_ALT_QWT" == "yes" ]]; then
        echo ""
    else
        echo "qt"
    fi
}

function bv_qwt_initialize_vars
{
    if [[ "$USE_SYSTEM_QWT" == "no" && "$USE_ALT_QWT" == "no" ]]; then
        QWT_INSTALL_DIR="${VISITDIR}/qwt/${QWT_VERSION}/${VISITARCH}"
    fi
}

function bv_qwt_info
{
    export QWT_FILE=${QWT_FILE:-"qwt-git-d3706f6e7f0351d278be2d989a4caaf92b399bbd.tar.xz"}
    export QWT_VERSION=${QWT_VERSION:-"6.3.0"}
    export QWT_COMPATIBILITY_VERSION=${QWT_COMPATIBILITY_VERSION:-"6.3"}
    export QWT_BUILD_DIR=${QWT_BUILD_DIR:-"qwt-6.3.0"}
    export QWT_SHA256_CHECKSUM="39839f3aa83f41d09109296d41659e04bb234d9e41ab551af9f4e9b4fceed251"
}

function bv_qwt_print
{
    printf "%s%s\n" "QWT_FILE=" "${QWT_FILE}"
    printf "%s%s\n" "QWT_VERSION=" "${QWT_VERSION}"
    printf "%s%s\n" "QWT_COMPATIBILITY_VERSION=" "${QWT_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "QWT_BUILD_DIR=" "${QWT_BUILD_DIR}"
}

function bv_qwt_print_usage
{
    printf "%-20s %s [%s]\n" "--qwt" "Build with Qwt" "$DO_QWT"
    printf "%-20s %s [%s]\n" "--system-qwt" "Use system Qwt" "$USE_SYSTEM_QWT"
    printf "%-20s %s [%s]\n" "--alt-qwt-dir" "Use Qwt from an alternative directory"
}

function bv_qwt_host_profile
{
    if [[ "$DO_QWT" != "yes" ]]; then
        return
    fi

    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        if [[ "$DO_ENGINE_ONLY" != "yes" ]]; then
            if [[ "$DO_SERVER_COMPONENTS_ONLY" != "yes" ]]; then
                echo >> $HOSTCONF
                echo "##" >> $HOSTCONF
                echo "## QWT" >> $HOSTCONF
                echo "##" >> $HOSTCONF
                if [[ "$USE_SYSTEM_QWT" == "yes" ]]; then
                    echo "option(VISIT_USE_SYSTEM_QWT \"Use system version of Qwt\" ON)" >> $HOSTCONF
                elif [[ "$USE_ALT_QWT" == "yes" ]]; then
                    echo "VISIT_OPTION_DEFAULT(VISIT_QWT_DIR $QWT_INSTALL_DIR)" >> $HOSTCONF
                else
                    echo "SETUP_APP_VERSION(QWT $QWT_VERSION)" >> $HOSTCONF
                    echo "VISIT_OPTION_DEFAULT(VISIT_QWT_DIR \${VISITHOME}/qwt/\${QWT_VERSION}/\${VISITARCH})" >> $HOSTCONF
                fi
            fi
        fi
    fi
}

function bv_qwt_ensure
{
    if [[ "$USE_SYSTEM_QWT" == "yes" || "$USE_ALT_QWT" == "yes" ]]; then
        return
    fi

    if [[ "$DO_QWT" == "yes" && "$DO_SERVER_COMPONENTS_ONLY" == "no" ]] ; then
        ensure_built_or_ready "qwt" $QWT_VERSION $QWT_BUILD_DIR $QWT_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_QWT="no"
            error "Unable to build Qwt.  ${QWT_FILE} not found."
        fi
    fi
}

function apply_qwt_612_linux_patch
{
    PATCHFILE="./patchfile.patch"
    rm -rf $PATCHFILE
    touch $PATCHFILE

    echo "--- qwtconfig.pri        2014-12-11 07:13:13.000000000 -0700" >> $PATCHFILE
    echo "+++ qwtconfig.pri.new    2016-05-03 16:14:00.000000000 -0600" >> $PATCHFILE
    echo "@@ -19,7 +19,7 @@" >> $PATCHFILE
    echo " QWT_INSTALL_PREFIX = \$\$[QT_INSTALL_PREFIX]" >> $PATCHFILE
    echo " " >> $PATCHFILE
    echo " unix {" >> $PATCHFILE
    echo "-    QWT_INSTALL_PREFIX    = /usr/local/qwt-\$\$QWT_VERSION" >> $PATCHFILE
    echo "+    QWT_INSTALL_PREFIX    = ${QWT_INSTALL_DIR}" >> $PATCHFILE
    echo "     # QWT_INSTALL_PREFIX = /usr/local/qwt-\$\$QWT_VERSION-qt-\$\$QT_VERSION" >> $PATCHFILE
    echo " }" >> $PATCHFILE

    patch -p0 < $PATCHFILE

    if [[ $? != 0 ]] ; then
        warn "qwt patch failed."
        return 1
    fi

#    rm -rf $PATCHFILE
    
    return 0;
}

function apply_qwt_630_linux_patch
{
    PATCHFILE="./patchfile.patch"
    rm -rf $PATCHFILE
    touch $PATCHFILE

    echo "--- qwtconfig.pri       2023-04-13 07:57:21.545486000 -0700" >> $PATCHFILE
    echo "+++ qwtconfig.pri.new   2023-04-13 07:58:43.382979000 -0700" >> $PATCHFILE
    echo "@@ -19,7 +19,7 @@" >> $PATCHFILE
    echo " QWT_INSTALL_PREFIX = \$\$[QT_INSTALL_PREFIX]" >> $PATCHFILE
    echo " " >> $PATCHFILE
    echo " unix {" >> $PATCHFILE
    echo "-    QWT_INSTALL_PREFIX    = /usr/local/qwt-\$\$QWT_VERSION-dev" >> $PATCHFILE
    echo "+    QWT_INSTALL_PREFIX    = ${QWT_INSTALL_DIR}" >> $PATCHFILE
    echo "     # QWT_INSTALL_PREFIX = /usr/local/qwt-\$\$QWT_VERSION-dev-qt-\$\$QT_VERSION" >> $PATCHFILE
    echo " }" >> $PATCHFILE


    patch -p0 < $PATCHFILE

    if [[ $? != 0 ]] ; then
        warn "qwt 6.3.0 linux patch failed."
        return 1
    fi

    return 0;
}

function apply_qwt_612_static_patch
{
    # must patch a file in order to create static library
    info "Patching qwt for static build"
    patch -p0 << \EOF
*** qwtconfig.pri.orig	2019-02-07 09:54:46.000000000 -0800
--- qwtconfig.pri	2019-02-07 09:54:58.000000000 -0800
***************
*** 72,78 ****
  # it will be a static library.
  ######################################################################
  
! QWT_CONFIG           += QwtDll
  
  ######################################################################
  # QwtPlot enables all classes, that are needed to use the QwtPlot 
--- 72,78 ----
  # it will be a static library.
  ######################################################################
  
! #QWT_CONFIG           += QwtDll
  
  ######################################################################
  # QwtPlot enables all classes, that are needed to use the QwtPlot 
***************
*** 93,99 ****
  # export a plot to a SVG document
  ######################################################################
  
! QWT_CONFIG     += QwtSvg
  
  ######################################################################
  # If you want to use a OpenGL plot canvas
--- 93,99 ----
  # export a plot to a SVG document
  ######################################################################
  
! #QWT_CONFIG     += QwtSvg
  
  ######################################################################
  # If you want to use a OpenGL plot canvas
***************
*** 118,124 ****
  # Otherwise you have to build it from the designer directory.
  ######################################################################
  
! QWT_CONFIG     += QwtDesigner
  
  ######################################################################
  # Compile all Qwt classes into the designer plugin instead
--- 118,124 ----
  # Otherwise you have to build it from the designer directory.
  ######################################################################
  
! #QWT_CONFIG     += QwtDesigner
  
  ######################################################################
  # Compile all Qwt classes into the designer plugin instead


EOF
    if [[ $? != 0 ]] ; then
        warn "qwt static patch failed."
        return 1
    fi

    return 0;

}

function apply_qwt_patch
{
    if [[ "$QWT_VERSION" == "6.1.2" ]]; then
        if [[ "$OPSYS" == "Linux" || "$OPSYS" == "Darwin" ]]; then
            apply_qwt_612_linux_patch
        fi

        if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
            apply_qwt_612_static_patch
        fi
    elif [[ "$QWT_VERSION" == "6.3.0" ]]; then
        if [[ "$OPSYS" == "Linux" || "$OPSYS" == "Darwin" ]]; then
            apply_qwt_630_linux_patch
        fi
    fi
}

# *************************************************************************** #
#                          Function 8.0, build_qwt                           #
# *************************************************************************** #

function build_qwt
{
    #
    # we need or patch to work for any successive configure to build qwt
    # the easiest and most robust way to tackle this is to always delete
    # the source dir if it exists

    if [[ -d ${QWT_BUILD_DIR} ]] ; then
        info "Removing old Qwt build dir ${QWT_BUILD_DIR} . . ."
        rm -rf ${QWT_BUILD_DIR}
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $QWT_BUILD_DIR $QWT_FILE
    untarred_qwt=$?
    if [[ $untarred_qwt == -1 ]] ; then
        warn "Unable to prepare Qwt build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching Qwt . . ."
    cd $QWT_BUILD_DIR || error "Can't cd to Qwt build dir."
    apply_qwt_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_qwt == 1 ]] ; then
            warn "Giving up on Qwt build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    #
    # Build Qwt
    #
    info "Configuring Qwt . . . (~1 minute)"
    ${QT_BIN_DIR}/qmake qwt.pro

    if [[ $? != 0 ]] ; then
        warn "Qwt project build failed.  Giving up"
        return 1
    fi

    info "Building Qwt . . . (~2 minutes)"
    $MAKE
    if [[ $? != 0 ]] ; then
        warn "Qwt build failed.  Giving up"
        return 1
    fi
    #
    # Install into the VisIt third party location.
    #
    info "Installing Qwt . . ."

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "Qwt install failed.  Giving up"
        return 1
    fi

    if [[ "$OPSYS" == "Darwin" ]]; then
        if [[ "$DO_STATIC_BUILD" == "no" ]]; then
            #
            # Make dynamic executable, need to patch up the install path and
            # version information.
            #
            info "Creating dynamic libraries for Qwt . . ."

            fulllibname="${QWT_INSTALL_DIR}/lib/qwt.framework/Versions/6/qwt"

            install_name_tool -id $fulllibname $fulllibname

            if [[ $? != 0 ]] ; then
                warn "Qwt dynamic library build failed.  Giving up"
                return 1
            fi
        else
            # Static build. For whatever reason, it was not installing headers.
            mkdir "${QWT_INSTALL_DIR}/include"
            cp -f src/*.h "${QWT_INSTALL_DIR}/include"
        fi
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/qwt"
        chgrp -R ${GROUP} "$VISITDIR/qwt"
    fi
    cd "$START_DIR"
    info "Done with Qwt"
    return 0
}

function bv_qwt_is_enabled
{
    if [[ "$DO_SERVER_COMPONENTS_ONLY" == "yes" ]]; then
        return 0
    fi
    if [[ $DO_QWT == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_qwt_is_installed
{
    check_if_installed "qwt" $QWT_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_qwt_build
{
    if [[ "$USE_SYSTEM_QWT" == "yes" || "$USE_ALT_QWT" == "yes" ]]; then
        return
    fi

    cd "$START_DIR"

    if [[ "$DO_QWT" == "yes" && "$DO_SERVER_COMPONENTS_ONLY" == "no" ]] ; then
        check_if_installed "qwt" $QWT_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Qwt build. Qwt is already installed."
        else
            info "Building Qwt (~3 minutes)"
            build_qwt
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Qwt. Bailing out."
            fi
            info "Done building Qwt"
        fi
    fi
}
function bv_silo_initialize
{
    export DO_SILO="no"
    export DO_SILEX="no"
    add_extra_commandline_args "silo" "silex" 0 "Enable silex when building Silo"
}

function bv_silo_enable
{
    DO_SILO="yes"
}

function bv_silo_disable
{
    DO_SILO="no"
}

function bv_silo_silex
{
    info "Enabling silex in Silo build"
    DO_SILEX="yes"
    bv_silo_enable
}

function bv_silo_depends_on
{
    local depends_on=""

    if [[ "$DO_ZLIB" == "yes" ]] ; then
        depends_on="zlib"
    fi

    if [[ "$DO_HDF5" == "yes" ]] ; then
        depends_on="$depends_on hdf5"
    fi
    
    if [[ "$DO_SZIP" == "yes" ]] ; then
        depends_on="$depends_on szip"
    fi


    echo $depends_on
}

function bv_silo_info
{
    export SILO_VERSION=${SILO_VERSION:-"4.10.2"}
    export SILO_FILE=${SILO_FILE:-"silo-${SILO_VERSION}-w-unix-line-endings.tar.gz"}
    export SILO_COMPATIBILITY_VERSION=${SILO_COMPATIBILITY_VERSION:-"4.10.2"}
    export SILO_BUILD_DIR=${SILO_BUILD_DIR:-"silo-${SILO_VERSION}"}
    export SILO_SHA256_CHECKSUM="db5e4fb6a4c313b9c596f09df307659079d51c36f013933dd957fe9412d37761"
}

function bv_silo_print
{
    printf "%s%s\n" "SILO_FILE=" "${SILO_FILE}"
    printf "%s%s\n" "SILO_VERSION=" "${SILO_VERSION}"
    printf "%s%s\n" "SILO_COMPATIBILITY_VERSION=" "${SILO_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "SILO_BUILD_DIR=" "${SILO_BUILD_DIR}"
}

function bv_silo_print_usage
{
    printf "%-20s %s [%s]\n" "--silo" "Build Silo support" "$DO_SILO"
    printf "%-20s %s [%s]\n" "--silex" "Enable silex when building Silo" "$DO_SILEX"
}

function bv_silo_host_profile
{
    if [[ "$DO_SILO" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Silo" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_SILO_DIR \${VISITHOME}/silo/$SILO_VERSION/\${VISITARCH})" \
            >> $HOSTCONF

        libdep=""
        if [[ "$DO_HDF5" == "yes" ]] ; then
            libdep="HDF5_LIBRARY_DIR hdf5 \${VISIT_HDF5_LIBDEP}"
        fi
        libdep="$libdep ZLIB_LIBRARY_DIR z"
        if [[ -n "$libdep" ]]; then
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_SILO_LIBDEP $libdep TYPE STRING)" \
                >> $HOSTCONF
        fi
    fi
}

function bv_silo_ensure
{
    if [[ "$DO_SILO" == "yes" ]] ; then
        ensure_built_or_ready "silo" $SILO_VERSION $SILO_BUILD_DIR $SILO_FILE $SILO_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_SILO="no"
            error "Unable to build Silo.  ${SILO_FILE} not found."
        fi
    fi
}

function apply_silo_4102_fpzip_patch
{
    info "Patching silo for fpzip DOMAIN and RANGE symbols"
    patch --verbose -p0 << \EOF
Index: src/fpzip/codec.h
===================================================================
--- src/fpzip/codec.h   (revision 809)
+++ src/fpzip/codec.h   (working copy)
@@ -16,13 +16,13 @@
 // identity map for integer arithmetic
 template <typename T, unsigned width>
 struct PCmap<T, width, T> {
-  typedef T DOMAIN;
-  typedef T RANGE;
+  typedef T FPZIP_Domain_t;
+  typedef T FPZIP_Range_t;
   static const unsigned bits = width;
   static const T        mask = ~T(0) >> (bitsizeof(T) - bits);
-  RANGE forward(DOMAIN d) const { return d & mask; }
-  DOMAIN inverse(RANGE r) const { return r & mask; }
-  DOMAIN identity(DOMAIN d) const { return d & mask; }
+  FPZIP_Range_t forward(FPZIP_Domain_t d) const { return d & mask; }
+  FPZIP_Domain_t inverse(FPZIP_Range_t r) const { return r & mask; }
+  FPZIP_Domain_t identity(FPZIP_Domain_t d) const { return d & mask; }
 };
 #endif
 
Index: src/fpzip/pcdecoder.inl
===================================================================
--- src/fpzip/pcdecoder.inl (revision 809)
+++ src/fpzip/pcdecoder.inl (working copy)
@@ -19,7 +19,7 @@
 T PCdecoder<T, M, false>::decode(T pred, unsigned context)
 {
   // map type T to unsigned integer type
-  typedef typename M::RANGE U;
+  typedef typename M::FPZIP_Range_t U;
   U p = map.forward(pred);
   // entropy decode d = r - p
   U r = p + rd->decode(rm[context]) - bias;
@@ -46,7 +46,7 @@
 template <typename T, class M>
 T PCdecoder<T, M, true>::decode(T pred, unsigned context)
 {
-  typedef typename M::RANGE U;
+  typedef typename M::FPZIP_Range_t U;
   unsigned s = rd->decode(rm[context]);
   if (s > bias) {      // underprediction
     unsigned k = s - bias - 1;
Index: src/fpzip/pcencoder.inl
===================================================================
--- src/fpzip/pcencoder.inl (revision 809)
+++ src/fpzip/pcencoder.inl (working copy)
@@ -18,7 +18,7 @@
 T PCencoder<T, M, false>::encode(T real, T pred, unsigned context)
 {
   // map type T to unsigned integer type
-  typedef typename M::RANGE U;
+  typedef typename M::FPZIP_Range_t U;
   U r = map.forward(real);
   U p = map.forward(pred);
   // entropy encode d = r - p
@@ -47,7 +47,7 @@
 T PCencoder<T, M, true>::encode(T real, T pred, unsigned context)
 {
   // map type T to unsigned integer type
-  typedef typename M::RANGE U;
+  typedef typename M::FPZIP_Range_t U;
   U r = map.forward(real);
   U p = map.forward(pred);
   // compute (-1)^s (2^k + m) = r - p, entropy code (s, k),
Index: src/fpzip/pcmap.h
===================================================================
--- src/fpzip/pcmap.h   (revision 809)
+++ src/fpzip/pcmap.h   (working copy)
@@ -14,53 +14,53 @@
 // specialized for integer-to-integer map
 template <typename T, unsigned width>
 struct PCmap<T, width, void> {
-  typedef T DOMAIN;
-  typedef T RANGE;
-  static const unsigned bits = width;                    // RANGE bits
-  static const unsigned shift = bitsizeof(RANGE) - bits; // DOMAIN\RANGE bits
-  RANGE forward(DOMAIN d) const { return d >> shift; }
-  DOMAIN inverse(RANGE r) const { return r << shift; }
-  DOMAIN identity(DOMAIN d) const { return inverse(forward(d)); }
+  typedef T FPZIP_Domain_t;
+  typedef T FPZIP_Range_t;
+  static const unsigned bits = width;                    // FPZIP_Range_t bits
+  static const unsigned shift = bitsizeof(FPZIP_Range_t) - bits; // FPZIP_Domain_t\FPZIP_Range_t bits
+  FPZIP_Range_t forward(FPZIP_Domain_t d) const { return d >> shift; }
+  FPZIP_Domain_t inverse(FPZIP_Range_t r) const { return r << shift; }
+  FPZIP_Domain_t identity(FPZIP_Domain_t d) const { return inverse(forward(d)); }
 };
 
 // specialized for float type
 template <unsigned width>
 struct PCmap<float, width, void> {
-  typedef float    DOMAIN;
-  typedef unsigned RANGE;
+  typedef float    FPZIP_Domain_t;
+  typedef unsigned FPZIP_Range_t;
   union UNION {
-    UNION(DOMAIN d) : d(d) {}
-    UNION(RANGE r) : r(r) {}
-    DOMAIN d;
-    RANGE r;
+    UNION(FPZIP_Domain_t d) : d(d) {}
+    UNION(FPZIP_Range_t r) : r(r) {}
+    FPZIP_Domain_t d;
+    FPZIP_Range_t r;
   };
-  static const unsigned bits = width;                    // RANGE bits
-  static const unsigned shift = bitsizeof(RANGE) - bits; // DOMAIN\RANGE bits
-  RANGE fcast(DOMAIN d) const;
-  DOMAIN icast(RANGE r) const;
-  RANGE forward(DOMAIN d) const;
-  DOMAIN inverse(RANGE r) const;
-  DOMAIN identity(DOMAIN d) const;
+  static const unsigned bits = width;                    // FPZIP_Range_t bits
+  static const unsigned shift = bitsizeof(FPZIP_Range_t) - bits; // FPZIP_Domain_t\FPZIP_Range_t bits
+  FPZIP_Range_t fcast(FPZIP_Domain_t d) const;
+  FPZIP_Domain_t icast(FPZIP_Range_t r) const;
+  FPZIP_Range_t forward(FPZIP_Domain_t d) const;
+  FPZIP_Domain_t inverse(FPZIP_Range_t r) const;
+  FPZIP_Domain_t identity(FPZIP_Domain_t d) const;
 };
 
 // specialized for double type
 template <unsigned width>
 struct PCmap<double, width, void> {
-  typedef double             DOMAIN;
-  typedef unsigned long long RANGE;
+  typedef double             FPZIP_Domain_t;
+  typedef unsigned long long FPZIP_Range_t;
   union UNION {
-    UNION(DOMAIN d) : d(d) {}
-    UNION(RANGE r) : r(r) {}
-    DOMAIN d;
-    RANGE r;
+    UNION(FPZIP_Domain_t d) : d(d) {}
+    UNION(FPZIP_Range_t r) : r(r) {}
+    FPZIP_Domain_t d;
+    FPZIP_Range_t r;
   };
-  static const unsigned bits = width;                    // RANGE bits
-  static const unsigned shift = bitsizeof(RANGE) - bits; // DOMAIN\RANGE bits
-  RANGE fcast(DOMAIN d) const;
-  DOMAIN icast(RANGE r) const;
-  RANGE forward(DOMAIN d) const;
-  DOMAIN inverse(RANGE r) const;
-  DOMAIN identity(DOMAIN d) const;
+  static const unsigned bits = width;                    // FPZIP_Range_t bits
+  static const unsigned shift = bitsizeof(FPZIP_Range_t) - bits; // FPZIP_Domain_t\FPZIP_Range_t bits
+  FPZIP_Range_t fcast(FPZIP_Domain_t d) const;
+  FPZIP_Domain_t icast(FPZIP_Range_t r) const;
+  FPZIP_Range_t forward(FPZIP_Domain_t d) const;
+  FPZIP_Domain_t inverse(FPZIP_Range_t r) const;
+  FPZIP_Domain_t identity(FPZIP_Domain_t d) const;
 };
 
 #include "pcmap.inl"
Index: src/fpzip/pcmap.inl
===================================================================
--- src/fpzip/pcmap.inl (revision 809)
+++ src/fpzip/pcmap.inl (working copy)
@@ -3,12 +3,12 @@
 PCmap<float, width, void>::fcast(float d) const
 {
 #ifdef WITH_REINTERPRET_CAST
-  return reinterpret_cast<const RANGE&>(d);
+  return reinterpret_cast<const FPZIP_Range_t&>(d);
 #elif defined WITH_UNION
   UNION shared(d);
   return shared.r;
 #else
-  RANGE r;
+  FPZIP_Range_t r;
   memcpy(&r, &d, sizeof(r));
   return r;
 #endif
@@ -19,12 +19,12 @@
 PCmap<float, width, void>::icast(unsigned r) const
 {
 #ifdef WITH_REINTERPRET_CAST
-  return reinterpret_cast<const DOMAIN&>(r);
+  return reinterpret_cast<const FPZIP_Domain_t&>(r);
 #elif defined WITH_UNION
   UNION shared(r);
   return shared.d;
 #else
-  DOMAIN d;
+  FPZIP_Domain_t d;
   memcpy(&d, &r, sizeof(d));
   return d;
 #endif
@@ -37,7 +37,7 @@
 unsigned
 PCmap<float, width, void>::forward(float d) const
 {
-  RANGE r = fcast(d);
+  FPZIP_Range_t r = fcast(d);
   r = ~r;
   r >>= shift;
   r ^= -(r >> (bits - 1)) >> (shift + 1);
@@ -61,7 +61,7 @@
 float
 PCmap<float, width, void>::identity(float d) const
 {
-  RANGE r = fcast(d);
+  FPZIP_Range_t r = fcast(d);
   r >>= shift;
   r <<= shift;
   return icast(r);
@@ -72,12 +72,12 @@
 PCmap<double, width, void>::fcast(double d) const
 {
 #ifdef WITH_REINTERPRET_CAST
-  return reinterpret_cast<const RANGE&>(d);
+  return reinterpret_cast<const FPZIP_Range_t&>(d);
 #elif defined WITH_UNION
   UNION shared(d);
   return shared.r;
 #else
-  RANGE r;
+  FPZIP_Range_t r;
   memcpy(&r, &d, sizeof(r));
   return r;
 #endif
@@ -88,12 +88,12 @@
 PCmap<double, width, void>::icast(unsigned long long r) const
 {
 #ifdef WITH_REINTERPRET_CAST
-  return reinterpret_cast<const DOMAIN&>(r);
+  return reinterpret_cast<const FPZIP_Domain_t&>(r);
 #elif defined WITH_UNION
   UNION shared(r);
   return shared.d;
 #else
-  DOMAIN d;
+  FPZIP_Domain_t d;
   memcpy(&d, &r, sizeof(d));
   return d;
 #endif
@@ -106,7 +106,7 @@
 unsigned long long
 PCmap<double, width, void>::forward(double d) const
 {
-  RANGE r = fcast(d);
+  FPZIP_Range_t r = fcast(d);
   r = ~r;
   r >>= shift;
   r ^= -(r >> (bits - 1)) >> (shift + 1);
@@ -130,7 +130,7 @@
 double
 PCmap<double, width, void>::identity(double d) const
 {
-  RANGE r = fcast(d);
+  FPZIP_Range_t r = fcast(d);
   r >>= shift;
   r <<= shift;
   return icast(r);
Index: src/fpzip/read.cpp
===================================================================
--- src/fpzip/read.cpp  (revision 809)
+++ src/fpzip/read.cpp  (working copy)
@@ -103,7 +103,7 @@
 {
   // initialize decompressor
   typedef PCmap<T, bits> TMAP;
-  typedef typename TMAP::RANGE U;
+  typedef typename TMAP::FPZIP_Range_t U;
   typedef PCmap<U, bits, U> UMAP;
   RCmodel* rm = new RCqsmodel(false, PCdecoder<U, UMAP>::symbols);
   PCdecoder<U, UMAP>* fd = new PCdecoder<U, UMAP>(rd, &rm);
Index: src/fpzip/write.cpp
===================================================================
--- src/fpzip/write.cpp (revision 809)
+++ src/fpzip/write.cpp (working copy)
@@ -103,7 +103,7 @@
 {
   // initialize compressor
   typedef PCmap<T, bits> TMAP;
-  typedef typename TMAP::RANGE U;
+  typedef typename TMAP::FPZIP_Range_t U;
   typedef PCmap<U, bits, U> UMAP;
   RCmodel* rm = new RCqsmodel(true, PCencoder<U, UMAP>::symbols);
   PCencoder<U, UMAP>* fe = new PCencoder<U, UMAP>(re, &rm);
EOF
    if [[ $? != 0 ]] ; then
        return 1
    fi
}

function apply_silo_patch
{
    info "Patching silo . . ."

    compare_version_strings $SILO_VERSION 4.10.3 -le
    if [[ $? -eq 0 ]]; then
        apply_silo_4102_fpzip_patch
        if [[ $? != 0 ]] ; then
            if [[ $untarred_silo == 1 ]] ; then
                warn "Giving up on Silo build because the patch failed."
                return 1
            else
                warn "Patch failed, but continuing.  I believe that this script\n" \
                     "tried to apply a patch to an existing directory that had\n" \
                     "already been patched ... that is, the patch is\n" \
                     "failing harmlessly on a second application."
            fi
        fi
    fi
    return 0
}

# *************************************************************************** #
#                            Function 8, build_silo
#
# Modfications:
#   Mark C. Miller, Wed Feb 18 22:57:25 PST 2009
#   Added logic to build silex and copy bins on Mac. Removed disablement of
#   browser.
#
#   Mark C. Miller Mon Jan  7 10:31:46 PST 2013
#   PDB/SCORE lite headers are now handled in Silo and require additional
#   configure option to ensure they are installed.
#
#   Brad Whitlock, Tue Apr  9 12:20:22 PDT 2013
#   Add support for custom zlib.
#
#   Kathleen Biagas, Tue Jun 10 08:21:33 MST 2014
#   Disable silex for static builds.
#
# *************************************************************************** #

function build_silo
{
    #
    # Prepare build dir
    #
    prepare_build_dir $SILO_BUILD_DIR $SILO_FILE
    untarred_silo=$?
    if [[ $untarred_silo == -1 ]] ; then
        warn "Unable to prepare Silo build directory. Giving Up!"
        return 1
    fi
    
    #
    # Call configure
    #
    info "Configuring Silo . . ."
    cd $SILO_BUILD_DIR || error "Can't cd to Silo build dir."

    apply_silo_patch || return 1
    info "Invoking command to configure Silo"
    if [[ "$DO_HDF5" == "yes" ]] ; then
        HDF5INCLUDE="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/include"
        HDF5LIB="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/lib"
        WITHHDF5ARG="--with-hdf5=$HDF5INCLUDE,$HDF5LIB"
    else
        WITHHDF5ARG="--without-hdf5"
    fi
    if [[ "$DO_SZIP" == "yes" ]] ; then
        SZIPDIR="$VISITDIR/szip/$SZIP_VERSION/$VISITARCH"
        WITHSZIPARG="--with-szlib=$SZIPDIR"
    else
        WITHSZIPARG="--without-szlib"
    fi
    if [[ "$DO_ZLIB" == "no" ]]; then
        WITH_HZIP_AND_FPZIP="--disable-hzip --disable-fpzip"
    else
        ZLIBARGS="--with-zlib=${VISITDIR}/zlib/${ZLIB_VERSION}/${VISITARCH}/include,${VISITDIR}/zlib/${ZLIB_VERSION}/${VISITARCH}/lib"
    fi
    WITHSHAREDARG="--enable-shared"
    if [[ "$DO_STATIC_BUILD" == "yes" ]] ; then
        WITHSHAREDARG="--disable-shared"
    fi
    WITHSILOQTARG='--disable-silex'

    if [[ "$FC_COMPILER" == "no" ]] ; then
        FORTRANARGS="--disable-fortran"
    else
        FORTRANARGS="FC=\"$FC_COMPILER\" F77=\"$FC_COMPILER\" FCFLAGS=\"$FCFLAGS\" FFLAGS=\"$FCFLAGS\""
    fi

    extra_ac_flags=""
    # detect coral and NVIDIA Grace CPU (ARM) systems, which older versions of 
    # autoconf don't detect
    if [[ "$(uname -m)" == "ppc64le" ]] ; then
         extra_ac_flags="ac_cv_build=powerpc64le-unknown-linux-gnu"
    elif [[ "$(uname -m)" == "aarch64" ]] ; then
         extra_ac_flags="ac_cv_build=aarch64-unknown-linux-gnu"
    fi 

    set -x
    # In order to ensure $FORTRANARGS is expanded to build the arguments to
    # configure, we wrap the invokation in 'sh -c "..."' syntax
    sh -c "./configure CXX=\"$CXX_COMPILER\" CC=\"$C_COMPILER\" \
        CFLAGS=\"$CFLAGS $C_OPT_FLAGS\" CXXFLAGS=\"$CXXFLAGS $CXX_OPT_FLAGS\" \
        $FORTRANARGS \
        --prefix=\"$VISITDIR/silo/$SILO_VERSION/$VISITARCH\" \
        $WITHHDF5ARG $WITHSZIPARG $WITHSILOQTARG $WITHSHAREDARG $WITH_HZIP_AND_FPZIP\
        --enable-install-lite-headers --without-readline \
        $ZLIBARGS $SILO_EXTRA_OPTIONS ${extra_ac_flags}"
    set +x

    if [[ $? != 0 ]] ; then
        warn "Silo configure failed.  Giving up"
        return 1
    fi

    #
    # Build Silo
    #
    info "Building Silo . . . (~2 minutes)"
    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        $MAKE $MAKE_OPT_FLAGS LIBS=-lstdc++
        if [[ $? != 0 ]] ; then
            warn "Silo build failed.  Giving up"
            return 1
        fi
    fi

    #
    # Install into the VisIt third party location.
    #
    info "Installing Silo"

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "Silo install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/silo"
        chgrp -R ${GROUP} "$VISITDIR/silo"
    fi
    cd "$START_DIR"
    info "Done with Silo"
    return 0
}

function bv_silo_is_enabled
{
    if [[ $DO_SILO == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_silo_is_installed
{
    check_if_installed "silo" $SILO_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_silo_build
{
    cd "$START_DIR"
    if [[ "$DO_SILO" == "yes" ]] ; then
        check_if_installed "silo" $SILO_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Silo build.  Silo is already installed."
        else
            info "Building Silo (~2 minutes)"
            build_silo
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Silo.  Bailing out."
            fi
            info "Done building Silo"
        fi
    fi
}
function bv_szip_initialize
{
    export DO_SZIP="no"
}

function bv_szip_enable
{
    DO_SZIP="yes"
}

function bv_szip_disable
{
    DO_SZIP="no"
}

function bv_szip_depends_on
{
    echo ""
}

function bv_szip_info
{
    export SZIP_FILE=${SZIP_FILE:-"szip-2.1.tar.gz"}
    export SZIP_VERSION=${SZIP_VERSION:-"2.1"}
    export SZIP_COMPATIBILITY_VERSION=${SZIP_COMPATIBILITY_VERSION:-"2.0"}
    export SZIP_BUILD_DIR=${SZIP_BUILD_DIR:-"szip-2.1"}
    export SZIP_SHA256_CHECKSUM="90f103d6bb3d48e1ab32284d35a34411217b138d45efd830b2cb42a29c5c8d5c"
}

function bv_szip_print
{
    printf "%s%s\n" "SZIP_FILE=" "${SZIP_FILE}"
    printf "%s%s\n" "SZIP_VERSION=" "${SZIP_VERSION}"
    printf "%s%s\n" "SZIP_COMPATIBILITY_VERSION=" "${SZIP_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "SZIP_BUILD_DIR=" "${SZIP_BUILD_DIR}"
}

function bv_szip_print_usage
{
    printf "%-20s %s [%s]\n" "--szip" "Build with SZIP" "$DO_SZIP"  
}

function bv_szip_host_profile
{
    if [[ "$DO_SZIP" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## SZIP" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_SZIP_DIR \${VISITHOME}/szip/$SZIP_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi
}

function bv_szip_ensure
{    
    if [[ "$DO_SZIP" == "yes" ]] ; then
        ensure_built_or_ready "szip" $SZIP_VERSION $SZIP_BUILD_DIR $SZIP_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_SZIP="no"
            error "Unable to build SZIP.  ${SZIP_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                          Function 8.0, build_szip                           #
# *************************************************************************** #

function build_szip
{
    #
    # Prepare build dir
    #
    prepare_build_dir $SZIP_BUILD_DIR $SZIP_FILE
    untarred_szip=$?
    if [[ $untarred_szip == -1 ]] ; then
        warn "Unable to prepare SZip build directory. Giving Up!"
        return 1
    fi

    #
    info "Configuring SZIP . . ."
    cd ${SZIP_BUILD_DIR} || error "Can't cd to szip build dir."
    info "Invoking command to configure SZIP"
    cf_szip=""
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        cf_szip="--disable-shared --enable-static"
    fi
    if [[ "$VISIT_BUILD_MODE" == "Debug" ]]; then
        cf_szip="$cf_szip --disable-production"
    fi

    extra_ac_flags=""
    # detect coral and NVIDIA Grace CPU (ARM) systems, which older versions of 
    # autoconf don't detect
    if [[ "$(uname -m)" == "ppc64le" ]] ; then
         extra_ac_flags="ac_cv_build=powerpc64le-unknown-linux-gnu"
    elif [[ "$(uname -m)" == "aarch64" ]] ; then
         extra_ac_flags="ac_cv_build=aarch64-unknown-linux-gnu"
    fi

    set -x
    ./configure CXX="$CXX_COMPILER" CC="$C_COMPILER" LIBS="-lm" \
                CFLAGS="$CFLAGS $C_OPT_FLAGS" CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
                --prefix="$VISITDIR/szip/$SZIP_VERSION/$VISITARCH" ${cf_szip} \
                ${extra_ac_flags}
    set +x

    if [[ $? != 0 ]] ; then
        warn "SZIP configure failed.  Giving up"
        return 1
    fi

    #
    # Build SZIP
    #
    info "Building SZIP . . . (~1 minutes)"

    $MAKE
    if [[ $? != 0 ]] ; then
        warn "SZIP build failed.  Giving up"
        return 1
    fi
    #
    # Install into the VisIt third party location.
    #
    info "Installing SZIP . . ."

    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "SZIP install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        #
        # Make dynamic executable, need to patch up the install path and
        # version information.
        #
        info "Creating dynamic libraries for SZIP . . ."
        INSTALLNAMEPATH="$VISITDIR/szip/${SZIP_VERSION}/$VISITARCH/lib"

        ## go back to gcc bacause if "external relocation entries" restFP saveFP
        ##      /usr/bin/libtool -o libsz.${SO_EXT} -dynamic src/.libs/libsz.a \
        ##      -lSystem -lz -headerpad_max_install_names \
        ##      -install_name $INSTALLNAMEPATH/libsz.${SO_EXT} \
        ##      -compatibility_version $SZIP_COMPATIBILITY_VERSION \
        ##      -current_version $SZIP_VERSION
        $C_COMPILER -dynamiclib -o libsz.${SO_EXT} src/*.o \
                    -Wl,-headerpad_max_install_names \
                    -Wl,-twolevel_namespace,-undefined,dynamic_lookup \
                    -Wl,-install_name,$INSTALLNAMEPATH/libsz.${SO_EXT} \
                    -Wl,-compatibility_version,$SZIP_COMPATIBILITY_VERSION \
                    -Wl,-current_version,$SZIP_VERSION -lSystem 
        if [[ $? != 0 ]] ; then
            warn "SZIP dynamic library build failed.  Giving up"
            return 1
        fi
        rm -f "$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib/libsz.${SO_EXT}"
        cp libsz.${SO_EXT} "$VISITDIR/szip/$SZIP_VERSION/$VISITARCH/lib"
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/szip"
        chgrp -R ${GROUP} "$VISITDIR/szip"
    fi
    cd "$START_DIR"
    info "Done with SZIP"
    return 0
}

function bv_szip_is_enabled
{
    if [[ $DO_SZIP == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_szip_is_installed
{
    check_if_installed "szip" $SZIP_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_szip_build
{
    cd "$START_DIR"
    if [[ "$DO_SZIP" == "yes" ]] ; then
        check_if_installed "szip" $SZIP_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping SZIP build.  SZIP is already installed."
        else
            info "Building SZIP (~2 minutes)"
            build_szip
            if [[ $? != 0 ]] ; then
                error "Unable to build or install SZIP.  Bailing out."
            fi
            info "Done building SZIP"
        fi
    fi
}
function bv_uintah_initialize
{
    export DO_UINTAH="no"
    export USE_SYSTEM_UINTAH="no"
    add_extra_commandline_args "uintah" "alt-uintah-dir" 1 "Use alternative directory for uintah"
}

function bv_uintah_enable
{
    DO_UINTAH="yes"
}

function bv_uintah_disable
{
    DO_UINTAH="no"
}

function bv_uintah_alt_uintah_dir
{
    echo "Using alternate Uintah directory"

    # Check to make sure the directory or a particular include file exists.
    [ ! -e "$1/../src/VisIt/interfaces/datatypes.h" ] && error "Uintah not found in $1"

    bv_uintah_enable
    USE_SYSTEM_UINTAH="yes"
    UINTAH_INSTALL_DIR="$1"
}

function bv_uintah_depends_on
{
    if [[ "$USE_SYSTEM_UINTAH" == "yes" ]]; then
        echo ""
    else
        echo "zlib"
    fi
}

function bv_uintah_initialize_vars
{
    if [[ "$parallel" == "no" ]]; then
        bv_uintah_disable
        warn "Uintah requested by default but the parallel flag has not been set. Uintah will not be built."
        return
    fi

    if [[ "$USE_SYSTEM_UINTAH" == "no" ]]; then
        UINTAH_INSTALL_DIR="${VISITDIR}/uintah/$UINTAH_VERSION/$VISITARCH"
    fi
}

function bv_uintah_info
{
    export UINTAH_VERSION=${UINTAH_VERSION:-"2.6.3"}
    export UINTAH_FILE=${UINTAH_FILE:-"Uintah-${UINTAH_VERSION}.tar.gz"}
    export UINTAH_COMPATIBILITY_VERSION=${UINTAH_COMPATIBILITY_VERSION:-"2.6"}
    export UINTAH_BUILD_DIR=${UINTAH_BUILD_DIR:-"Uintah-${UINTAH_VERSION}"}
    export UINTAH_SHA256_CHECKSUM="1b98cd31d4d216239b23a2a42f84623f3d999cdc32da6893499508879f2e4e91"
}

function bv_uintah_print
{
    printf "%s%s\n" "UINTAH_FILE=" "${UINTAH_FILE}"
    printf "%s%s\n" "UINTAH_VERSION=" "${UINTAH_VERSION}"
    printf "%s%s\n" "UINTAH_COMPATIBILITY_VERSION=" "${UINTAH_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "UINTAH_BUILD_DIR=" "${UINTAH_BUILD_DIR}"
}

function bv_uintah_print_usage
{
    printf "%-20s %s [%s]\n" "--uintah" "Build Uintah" "${DO_UINTAH}"
    printf "%-20s %s [%s]\n" "--alt-uintah-dir" "Use Uintah from an alternative directory"
}

function bv_uintah_host_profile
{
    if [[ "$DO_UINTAH" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Uintah" >> $HOSTCONF
        echo "##" >> $HOSTCONF

        if [[ "$USE_SYSTEM_UINTAH" == "yes" ]]; then
            warn "Assuming version 2.7.0 for Uintah"
            echo "SETUP_APP_VERSION(UINTAH 2.7.0)" >> $HOSTCONF
            echo "VISIT_OPTION_DEFAULT(VISIT_UINTAH_DIR $UINTAH_INSTALL_DIR)" >> $HOSTCONF 
            echo "SET(VISIT_USE_SYSTEM_UINTAH TRUE)" >> $HOSTCONF
        else
            echo "SETUP_APP_VERSION(UINTAH $UINTAH_VERSION)" >> $HOSTCONF
            echo \
                "VISIT_OPTION_DEFAULT(VISIT_UINTAH_DIR \${VISITHOME}/uintah/\${UINTAH_VERSION}/\${VISITARCH})" \
                >> $HOSTCONF 
        fi
    fi
}

function bv_uintah_ensure
{
    if [[ "$DO_UINTAH" == "yes" && "$USE_SYSTEM_UINTAH" == "no" ]] ; then
        ensure_built_or_ready "uintah" $UINTAH_VERSION $UINTAH_BUILD_DIR $UINTAH_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_UINTAH="no"
            error "Unable to build UINTAH.  ${UINTAH_FILE} not found."
        fi
    fi
}

function bv_uintah_dry_run
{
    if [[ "$DO_UINTAH" == "yes" ]] ; then
        echo "Dry run option not set for uintah."
    fi
}


# **************************************************************************** #
#                          Function 8.1, build_uintah                          #
#                                                                              #
# Kevin Griffin, Mon Nov 24 12:33:02 PST 2014                                  #
# Changed the -showme:compile to -show for OS X Mavericks. The -showme:compile #
# was being reported as an invalid option.                                     #
#                                                                              #
# Kevin Griffin, Wed Aug 28 10:25:30 PDT 2019                                  #
# Added the --with-libxml2 option to ensure that the /usr/lib/ version is used #
#                                                                              #
# Todd Harman, Thu Jun 15 15:31:51 MDT 2023                                    #
# replaced the cp commands for installing the libs & headers with              #
#   $MAKE install-visit                                                        #
# **************************************************************************** #

function build_uintah
{
    if [[ "$OPSYS" == "Linux"  ]]; then
        if [[ "$PAR_COMPILER" == "" || "$PAR_COMPILER_CXX" == "" || "$PAR_INCLUDE" == "" ]]; then
            warn "For Linux builds the PAR_COMPILER, PAR_COMPILER_CXX, and PAR_INCLUDE environment variables must be set."
            if [[ "$PAR_COMPILER" == "" ]]; then
                warn "PAR_COMPILER should be of the form \"/path/to/mpi/bin/mpicc\""
            fi
            if [[ "$PAR_COMPILER_CXX" == "" ]]; then
                warn "PAR_COMPILER_CXX should be of the form \"/path/to/mpi/bin/mpicxx\""
            fi
            if [[ "$PAR_INCLUDE" == "" ]]; then
                warn "PAR_INCLUDE should be of the form \"-I/path/to/mpi/include\""
            fi
            warn "Giving Up!"
            return 1
        fi
    fi

    PAR_INCLUDE_STRING=""
    if [[ "$PAR_INCLUDE" != "" ]] ; then
        PAR_INCLUDE_STRING=$PAR_INCLUDE
    fi

    if [[ "$PAR_COMPILER" != "" ]] ; then
        if [[ "$OPSYS" == "Darwin" && "$PAR_COMPILER" == "/usr/bin/mpicc" ]]; then
            PAR_INCLUDE_STRING="-I/usr/include/"
        elif [[ "$OPSYS" == "Linux" && "$PAR_COMPILER" == "mpixlc" ]]; then
            PAR_INCLUDE_STRING=`$PAR_COMPILER -show`
        else
            if [[ -z "$PAR_INCLUDE_STRING" ]]; then
                if [[ "$OPSYS" == "Darwin" && `sw_vers -productVersion` == 10.9.[0-9]* ]] ; then
                    PAR_INCLUDE_STRING=`$PAR_COMPILER -show`
                else
                    PAR_INCLUDE_STRING=`$PAR_COMPILER -showme:compile`
                    if [[ $? != 0 ]] ; then
                        PAR_INCLUDE_STRING=`$PAR_COMPILER -show`
                    fi
                fi
            fi
        fi
    fi

    if [[ "$PAR_INCLUDE_STRING" == "" ]] ; then
        warn "You must set either the PAR_COMPILER or PAR_INCLUDE environment variables."
        warn "PAR_COMPILER should be of the form \"/path/to/mpi/bin/mpicc\""
        warn "PAR_INCLUDE should be of the form \"-I/path/to/mpi/include\""
        warn "Giving Up!"
        return 1
    fi

    # Uintah's config doesn't take the compiler options, but rather the
    # paths to the root, and then it tries to build all of the appropriate
    # options itself.  Because we only have the former, we need to guess at the
    # latter.
    # Our current guess is to take the first substring in PAR_INCLUDE, assume
    # it's the appropriate -I option, and use it with the "-I" removed.  This
    # is certainly not ideal -- for example, it will break if the user's
    # MPI setup requires multiple include directories.

    # Search all of the -I directories and take the first one containing mpi.h
    PAR_INCLUDE_DIR=""
    for arg in $PAR_INCLUDE_STRING ; do
        if [[ "$arg" != "${arg#-I}" ]] ; then
            if test -e "${arg#-I}/mpi.h" ; then
                PAR_INCLUDE_DIR=${arg#-I}
                break
            fi
        fi
    done
    # If we did not get a valid include directory, take the first -I directory.
    if test -z "${PAR_INCLUDE_DIR}"  ; then
        for arg in $PAR_INCLUDE_STRING ; do
            if [[ "$arg" != "${arg#-I}" ]] ; then
                PAR_INCLUDE_DIR=${arg#-I}
                break
            fi
        done
    fi

    if test -z "${PAR_INCLUDE_DIR}"  ; then
        if test -n "${PAR_INCLUDE}" ; then
            warn "This script believes you have defined PAR_INCLUDE as: $PAR_INCLUDE"
            warn "However, to build Uintah, this script expects to parse a -I/path/to/mpi out of PAR_INCLUDE"
        fi
        warn "Could not determine the MPI include information which is needed to compile Uintah."
        if test -n "${PAR_INCLUDE}" ; then
            error "Please re-run with the required \"-I\" option included in PAR_INCLUDE"
        else
            error "You need to specify either PAR_COMPILER or PAR_INCLUDE variable.  On many "
            " systems, the output of \"mpicc -showme\" is good enough."
            error ""
        fi
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $UINTAH_BUILD_DIR $UINTAH_FILE
    untarred_uintah=$?
    if [[ $untarred_uintah == -1 ]] ; then
        warn "Unable to prepare UINTAH Build Directory. Giving Up"
        return 1
    fi

    # move back up to the start dir
    cd "$START_DIR"

    #
    # Configure Uintah
    #
    info "Configuring UINTAH . . ."

    UINTAH_BUILD_DIR="${UINTAH_BUILD_DIR}/optimized"
    if [[ ! -d $UINTAH_BUILD_DIR ]] ; then
        echo "Making build directory $UINTAH_BUILD_DIR"
        mkdir $UINTAH_BUILD_DIR
    fi

    cd $UINTAH_BUILD_DIR || error "Can't cd to UINTAH build dir."

    cf_darwin=""
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        cf_build_type="--enable-static"
    else
        cf_build_type="--disable-static"
    fi

    if [[ "$OPSYS" == "Darwin" ]]; then
        sdk_root=`xcrun --show-sdk-path`

        info "Invoking command to configure UINTAH"
        set -x
        sh -c "../src/configure CXX=\"$CXX_COMPILER\" CC=\"$C_COMPILER\" \
        CFLAGS=\"$CFLAGS $C_OPT_FLAGS -headerpad_max_install_names\" CXXFLAGS=\"$CXXFLAGS $CXX_OPT_FLAGS\" \
        MPI_EXTRA_LIB_FLAG=\"$PAR_LIBRARY_NAMES\" \
        --with-zlib=\"$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH\" \
        --prefix=\"$VISITDIR/uintah/$UINTAH_VERSION/$VISITARCH\" \
        ${cf_darwin} \
        ${cf_build_type} \
        --enable-minimal --enable-optimize \
        --with-fortran=no --with-petsc=no --with-hypre=no \
        --with-lapack=no --with-blas=no \
        --with-mpi=\"$PAR_INCLUDE_DIR/..\" \
        --with-libxml2=\"$sdk_root/usr\" "

        #        --with-mpi-include="${PAR_INCLUDE_DIR}/" \
        #        --with-mpi-lib="${PAR_INCLUDE_DIR}/../lib" "
        set +x

    else

        info "Invoking command to configure UINTAH"
        set -x
        sh -c "../src/configure CXX=\"$PAR_COMPILER_CXX\" CC=\"$PAR_COMPILER\" \
        CFLAGS=\"$CFLAGS $C_OPT_FLAGS\" CXXFLAGS=\"$CXXFLAGS $CXX_OPT_FLAGS\" \
        MPI_EXTRA_LIB_FLAG=\"$PAR_LIBRARY_NAMES\" \
        --with-zlib=\"$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH\" \
        --prefix=\"$VISITDIR/uintah/$UINTAH_VERSION/$VISITARCH\" \
        ${cf_build_type} \
        --enable-minimal --enable-optimize \
        --with-fortran=no --with-petsc=no --with-hypre=no \
        --with-lapack=no --with-blas=no \
        --with-mpi=built-in"
        set +x
    fi


    if [[ $? != 0 ]] ; then
        warn "UINTAH configure failed.  Giving up"
        return 1
    fi

    #
    # Build UINTAH
    #
    info "Making UINTAH . . ."
    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "UINTAH build failed.  Giving up"
        return 1
    fi
    #
    # Install into the VisIt third party location.
    #
    info "Installing UINTAH . . ."

    if [[ ! -e $VISITDIR/uintah/$UINTAH_VERSION/$VISITARCH ]] ; then
        mkdir -p $VISITDIR/uintah/$UINTAH_VERSION/$VISITARCH || error "Can't make UINTAH install dir."
    else        
        rm -rf $VISITDIR/uintah/$UINTAH_VERSION/$VISITARCH/* || error "Can't remove old UINTAH install dir."
    fi


    $MAKE install-visit
    
    if [[ $? != 0 ]] ; then
        warn "UINTAH install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" == "no" && "$OPSYS" == "Darwin" ]]; then
        #
        # Make dynamic executable, need to patch up the install path and
        # version information.
        #
        info "Creating dynamic libraries for UINTAH . . ."
        INSTALLNAMEPATH="${UINTAH_INSTALL_DIR}/lib"

        libs=`ls ${INSTALLNAMEPATH}/*.${SO_EXT}`

        for lib in $libs;
        do
            # Get the library path right
            install_name_tool -id $lib $lib

            # Find all the dependent libraries (more or less)
            deplibs=`otool -L $lib | sed "s/(.*)//g"`

            for deplib in $deplibs;
            do
                # Only get the libraries related to Uintah
                if [[ `echo $deplib | grep -c ${UINTAH_BUILD_DIR}` == 1 ]] ; then

                    # Get the library name sans the directory path
                    deplibname=`echo $deplib | sed "s/.*\///"`

                    # Finally set the library path
                    install_name_tool -change \
                                      $deplib ${INSTALLNAMEPATH}/$deplibname $lib
                fi
            done
        done
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/uintah"
        chgrp -R ${GROUP} "$VISITDIR/uintah"
    fi
    cd "$START_DIR"
    info "Done with UINTAH"
    return 0
}

function bv_uintah_is_enabled
{
    if [[ $DO_UINTAH == "yes" ]]; then
        return 1    
    fi
    return 0
}

function bv_uintah_is_installed
{
    if [[ "$USE_SYSTEM_UINTAH" == "yes" ]]; then
        return 1
    fi

    check_if_installed "uintah" $UINTAH_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_uintah_build
{
    cd "$START_DIR"

    if [[ "$DO_UINTAH" == "yes" && "$USE_SYSTEM_UINTAH" == "no" ]] ; then
        check_if_installed "uintah" $UINTAH_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping UINTAH build.  UINTAH is already installed."
        else
            info "Building UINTAH (~10 minutes)"
            build_uintah
            if [[ $? != 0 ]] ; then
                error "Unable to build or install UINTAH.  Bailing out."
            fi
            info "Done building UINTAH"
        fi
    fi
}
function bv_vtk_initialize
{
    info "bv_vtk_initialize"
    export DO_VTK="yes"
}

function bv_vtk_enable
{
    info "bv_vtk_enable"
    DO_VTK="yes"

}

function bv_vtk_disable
{
    DO_VTK="no"
}


function bv_vtk_depends_on
{
    depends_on="cmake zlib"

    if [[ "$DO_PYTHON" == "yes" ]]; then
        depends_on="${depends_on} python"
    fi

    if [[ "$DO_MESAGL" == "yes" ]]; then
        depends_on="${depends_on} mesagl glu"
    #elif [[ "$DO_OSMESA" == "yes" ]]; then
    #    depends_on="${depends_on} osmesa"
    fi

    if [[ "$DO_OSPRAY" == "yes" ]]; then
        depends_on="${depends_on} ospray"
    fi

    if [[ "$DO_ANARI" == "yes" ]]; then
        depends_on="${depends_on} anari"
    fi

    # Only depend on Qt if we're not doing server-only builds.
    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        if [[ "$DO_ENGINE_ONLY" != "yes" ]]; then
            if [[ "$DO_SERVER_COMPONENTS_ONLY" != "yes" ]]; then
                depends_on="${depends_on} qt"
            fi
        fi
    fi

    echo ${depends_on}
}

function bv_vtk_info
{
    info "setting up vtk for version 9.5.0"
    export VTK_VERSION=${VTK_VERSION:-"9.5.0"}
    export VTK_SHORT_VERSION=${VTK_SHORT_VERSION:-"9.5"}
    export VTK_SHA256_CHECKSUM="04ae86246b9557c6b61afbc534a6df099244fbc8f3937f82e6bc0570953af87d"
    export VTK_URL=""
    export VTK_FILE=${VTK_FILE:-"VTK-${VTK_VERSION}.tar.gz"}
    export VTK_COMPATIBILITY_VERSION=${VTK_SHORT_VERSION}
    export VTK_BUILD_DIR=${VTK_BUILD_DIR:-"VTK-${VTK_VERSION}"}
    export VTK_INSTALL_DIR=${VTK_INSTALL_DIR:-"vtk"}
}

function bv_vtk_print
{
    printf "%s%s\n" "VTK_FILE=" "${VTK_FILE}"
    printf "%s%s\n" "VTK_VERSION=" "${VTK_VERSION}"
    printf "%s%s\n" "VTK_BUILD_DIR=" "${VTK_BUILD_DIR}"
}

function bv_vtk_print_usage
{
    printf "%-20s %s\n" "--vtk" "Build VTK"
}

function bv_vtk_host_profile
{
    echo >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## VTK" >> $HOSTCONF
    echo "##" >> $HOSTCONF

    echo "SETUP_APP_VERSION(VTK $VTK_VERSION)" >> $HOSTCONF
    echo "VISIT_OPTION_DEFAULT(VISIT_VTK_DIR \${VISITHOME}/${VTK_INSTALL_DIR}/\${VTK_VERSION}/\${VISITARCH})" >> $HOSTCONF
}

function bv_vtk_initialize_vars
{
    info "initalizing vtk vars"
}

function bv_vtk_ensure
{
    if [[ "$DO_VTK" == "yes" ]] ; then
        ensure_built_or_ready $VTK_INSTALL_DIR $VTK_VERSION $VTK_BUILD_DIR $VTK_FILE $VTK_URL
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi
}


function apply_vtk95_vtkRectilinearGridReader_patch
{
  # patch vtkRectilinearGridReader.cxx, per this issue:
  # https://gitlab.kitware.com/vtk/vtk/-/issues/18447
   patch -p0 << \EOF
--- IO/Legacy/vtkRectilinearGridReader.cxx.orig	2025-05-15 13:43:55.914685000 -0700
+++ IO/Legacy/vtkRectilinearGridReader.cxx	2025-05-15 13:45:09.376599000 -0700
@@ -83,8 +83,14 @@
       {
         break;
       }
+      // Have to read field data because it may be binary.
+      if (!strncmp(this->LowerCase(line), "field", 5))
+      {
+        vtkFieldData* fd = this->ReadFieldData();
+        fd->Delete();
+      }

-      if (!strncmp(this->LowerCase(line), "dimensions", 10) && !dimsRead)
+      else if (!strncmp(this->LowerCase(line), "dimensions", 10) && !dimsRead)
       {
         int dim[3];
         if (!(this->Read(dim) && this->Read(dim + 1) && this->Read(dim + 2)))
@@ -116,6 +122,22 @@

         dimsRead = true;
       }
+
+      // if the coordinates have been reached, should be no reason
+      // to keep reading
+      else if (strncmp(this->LowerCase(line), "x_coordinate", 12) == 0)
+      {
+        break;
+      }
+      else if (strncmp(this->LowerCase(line), "y_coordinate", 12) == 0)
+      {
+        break;
+      }
+      else if (strncmp(this->LowerCase(line), "z_coordinate", 12) == 0)
+      {
+        break;
+      }
+
     }
   }

EOF

    if [[ $? != 0 ]] ; then
        warn "vtk patch for vtkRectilinearGridReader.cxx failed."
        return 1
    fi
}

function apply_vtk95_vtkdatawriter_patch
{
  # patch vtkDataWriter to fix a bug when writing a vtkBitArray
  # Make it use the same calculation as the reader.
   patch -p0 << \EOF
--- IO/Legacy/vtkDataWriter.cxx.orig	2025-05-15 13:43:55.914685000 -0700
+++ IO/Legacy/vtkDataWriter.cxx	2025-05-15 13:45:09.376599000 -0700
@@ -1121,7 +1121,7 @@
       else
       {
         unsigned char* cptr = static_cast<vtkBitArray*>(data)->GetPointer(0);
-        fp->write(reinterpret_cast<char*>(cptr), (sizeof(unsigned char)) * ((num - 1) / 8 + 1));
+        fp->write(reinterpret_cast<char*>(cptr), (sizeof(unsigned char)) * ((num*numComp+7)/8));
       }
       *fp << "\n";
     }
EOF

    if [[ $? != 0 ]] ; then
      warn "vtk patch for vtkDataWriter.cxx failed."
      return 1
    fi
    return 0;

}

function apply_vtk95_vtkospray_patches
{
    count_patches=3
    # patch vtkOSPRay files:

    # 1) expose vtkViewNodeFactory via vtkOSPRayPass.h
    current_patch=1
    patch -p0 << \EOF
--- Rendering/RayTracing/vtkOSPRayPass.h.orig	2025-05-15 13:50:01.170625000 -0700
+++ Rendering/RayTracing/vtkOSPRayPass.h	2025-05-15 13:52:33.330669000 -0700
@@ -39,6 +39,8 @@
 class vtkRenderPassCollection;
 class vtkSequencePass;
 class vtkVolumetricPass;
+// Used by VisIt
+class vtkViewNodeFactory;

 class VTKRENDERINGRAYTRACING_EXPORT vtkOSPRayPass : public vtkRenderPass
 {
@@ -65,6 +67,11 @@
    */
   virtual void RenderInternal(const vtkRenderState* s);

+  /**
+   * Called by VisIt
+   */
+  virtual vtkViewNodeFactory* GetViewNodeFactory();
+
   ///@{
   /**
    * Wrapper around ospray's init and shutdown that protect
EOF
    if [[ $? != 0 ]] ; then
        warn "vtk 9.5 patch ${current_patch}/${count_patches} for vtkOSPRayPass.h failed."
        return 1
    fi

    # 2) expose vtkViewNodeFactory via vtkOSPRayPass.cxx
    ((current_patch++))
    patch -p0 << \EOF
--- Rendering/RayTracing/vtkOSPRayPass.cxx.orig	2025-05-15 13:55:03.700624000 -0700
+++ Rendering/RayTracing/vtkOSPRayPass.cxx	2025-05-15 13:55:50.006697000 -0700
@@ -417,6 +417,12 @@
 }

 //------------------------------------------------------------------------------
+vtkViewNodeFactory* vtkOSPRayPass::GetViewNodeFactory()
+{
+  return this->Internal->Factory;
+}
+
+//------------------------------------------------------------------------------
 bool vtkOSPRayPass::IsSupported()
 {
   static bool detected = false;
EOF

    if [[ $? != 0 ]] ; then
        warn "vtk 9.5 patch ${current_patch}/${count_patches} for vtkOSPRayPass.cxx failed."
        return 1
    fi

    # 3) Set the samples in the VolumeMapper
    ((current_patch++))
    patch -p0 << \EOF
--- Rendering/RayTracing/vtkOSPRayVolumeMapper.cxx.orig	2025-05-15 13:57:16.832663000 -0700
+++ Rendering/RayTracing/vtkOSPRayVolumeMapper.cxx	2025-05-15 13:58:31.661593000 -0700
@@ -61,6 +61,10 @@
   {
     this->Init();
   }
+  vtkOSPRayRendererNode::SetSamplesPerPixel(
+    vtkOSPRayRendererNode::GetSamplesPerPixel(ren), this->InternalRenderer);
+  vtkOSPRayRendererNode::SetAmbientSamples(
+    vtkOSPRayRendererNode::GetAmbientSamples(ren), this->InternalRenderer);
   this->InternalRenderer->SetRenderWindow(ren->GetRenderWindow());
   this->InternalRenderer->SetActiveCamera(ren->GetActiveCamera());
   this->InternalRenderer->SetBackground(ren->GetBackground());
EOF
    if [[ $? != 0 ]] ; then
        warn "vtk 9.5 patch $current_patch/$count_patches for vtkOSPRayVolumeMapper.cxx failed."
        return 1
    fi
}

function apply_vtk95_vktanari_patches
{
    count_patches=2
    # patch vtkAnari files:
   
    # 1) support panning and zooming
    current_patch=1
    patch -p0 << \EOF
*** Rendering/ANARI/vtkAnariCameraNode.cxx.orig  2025-06-23 14:12:36.000000000 -0500
--- Rendering/ANARI/vtkAnariCameraNode.cxx	2025-08-14 10:10:09.887501406 -0500
***************
*** 144,155 ****
      right = true;
    }
  
!   int* const ts = this->Internals->RendererNode->GetScale();
  
    if (this->Internals->IsParallelProjection)
    {
      // height of the image plane in world units
!     double height = cam->GetParallelScale() * 2 * ts[0];
      anari::setParameter(this->Internals->AnariDevice, this->Internals->AnariCamera, "height",
        static_cast<float>(height));
    }
--- 144,164 ----
      right = true;
    }
  
!   int* const ts = this->Internals->RendererNode->GetScale();  
!   vtkHomogeneousTransform* transform = cam->GetUserTransform();
!   double zoomFactor = 1.0;
!   
!   // Support zooming
!   if (transform != nullptr)
!   {
!     auto matrix = transform->GetMatrix();
!     zoomFactor = matrix->GetElement(0, 0);
!   }
  
    if (this->Internals->IsParallelProjection)
    {
      // height of the image plane in world units
!     double height = (cam->GetParallelScale() * 2 * ts[0]) / zoomFactor;
      anari::setParameter(this->Internals->AnariDevice, this->Internals->AnariCamera, "height",
        static_cast<float>(height));
    }
***************
*** 157,162 ****
--- 166,172 ----
    {
      // The field of view (angle in radians) of the frame's height
      float fovyDegrees = static_cast<float>(cam->GetViewAngle()) * static_cast<float>(ts[0]);
+     fovyDegrees /= static_cast<float>(zoomFactor);
      float fovyRadians = vtkMath::RadiansFromDegrees(fovyDegrees);
      anari::setParameter(
        this->Internals->AnariDevice, this->Internals->AnariCamera, "fovy", fovyRadians);
***************
*** 234,261 ****
      static_cast<float>(myFocalPoint[2] - shiftedCamPos[2]) };
    anari::setParameter(
      this->Internals->AnariDevice, this->Internals->AnariCamera, "direction", cameraDirection);
! 
!   // Additional world-space transformation matrix
!   vtkHomogeneousTransform* transform = cam->GetUserTransform();
! 
!   if (transform != nullptr)
!   {
!     double* matrix = transform->GetMatrix()->GetData();
!     float matrixF[16];
! 
!     for (int i = 0; i < 16; i++)
!     {
!       matrixF[i] = static_cast<float>(matrix[i]);
!     }
! 
!     anari::setParameter(
!       this->Internals->AnariDevice, this->Internals->AnariCamera, "transform", matrixF);
!   }
! 
    // Region of the sensor in normalized screen-space coordinates
    double viewPort[4] = { 0, 0, 1, 1 };
    this->Internals->RendererNode->GetViewport(viewPort);
  
    box2 imageRegion = { vec2{ static_cast<float>(viewPort[0]), static_cast<float>(viewPort[1]) },
      vec2{ static_cast<float>(viewPort[2]), static_cast<float>(viewPort[3]) } };
    anari::setParameter(
--- 244,274 ----
      static_cast<float>(myFocalPoint[2] - shiftedCamPos[2]) };
    anari::setParameter(
      this->Internals->AnariDevice, this->Internals->AnariCamera, "direction", cameraDirection);
!     
    // Region of the sensor in normalized screen-space coordinates
    double viewPort[4] = { 0, 0, 1, 1 };
    this->Internals->RendererNode->GetViewport(viewPort);
  
+   // Support image panning in applications (e.g. VisIt)
+   if(!cam->GetUseExplicitProjectionTransformMatrix())
+   {
+     // Convert VTK camera window center in viewport coordinates (range is: [-1,+1],[-1,+1])
+     // to normalized screen-space coordinates (range is: [0,1],[0,1]).
+     auto windowCenter = cam->GetWindowCenter();
+     double wcx = windowCenter[0] / 2.0 + 0.5;
+     double wcy = windowCenter[1] / 2.0 + 0.5;
+ 
+     // Offset based on the width of the current viewport
+     double offsetX = (viewPort[2] - viewPort[0]) / 2.0;
+     double offsetY = (viewPort[3] - viewPort[1]) / 2.0;
+ 
+     // Adjust viewport to center around window center
+     viewPort[0] = wcx - offsetX;
+     viewPort[1] = wcy - offsetY;
+     viewPort[2] = wcx + offsetX;
+     viewPort[3] = wcy + offsetY;
+   }
+ 
    box2 imageRegion = { vec2{ static_cast<float>(viewPort[0]), static_cast<float>(viewPort[1]) },
      vec2{ static_cast<float>(viewPort[2]), static_cast<float>(viewPort[3]) } };
    anari::setParameter(
EOF
    if [[ $? != 0 ]] ; then
        warn "vtk 9.5 ANARI patch ${current_patch}/${count_patches} for vtkAnariCameraNode.cxx failed."
        return 1
    fi
    
    # 2) expose internal vtkAnariPass via vtkAnariVolumeMapper
    ((current_patch++))
    patch -p0 << \EOF
*** Rendering/ANARI/vtkAnariVolumeMapper.h.orig	 2025-06-23 14:12:36.000000000 -0500
--- Rendering/ANARI/vtkAnariVolumeMapper.h	2025-08-06 16:10:00.556764266 -0500
***************
*** 52,57 ****
--- 52,62 ----
     * Allow vtkAnariSceneGraph properties to be set on the internal vtkRenderer.
     */
    vtkRenderer* GetInternalRenderer() const { return this->InternalRenderer; }
+   
+   /**
+    * Get the internal ANARI render pass.
+    */
+   vtkAnariPass* GetAnariPass() const { return this->InternalAnariPass; }
  
    //@{
    /**
EOF
    if [[ $? != 0 ]] ; then
        warn "vtk 9.5 ANARI patch $current_patch/$count_patches for vtkAnariVolumeMapper.h failed."
        return 1
    fi
}

function apply_vtk_patch
{
    if [[ ${VTK_VERSION} == 9.5.0 ]] ; then
        apply_vtk95_vtkospray_patches
        if [[ $? != 0 ]] ; then
            return 1
        fi

        apply_vtk95_vtkdatawriter_patch
        if [[ $? != 0 ]] ; then
           return 1
        fi

        # should submit a ticket to kitware
        apply_vtk95_vtkRectilinearGridReader_patch
        if [[ $? != 0 ]] ; then
            return 1
        fi
        
        # MR will be submitted to kitware for these updates
        # Will need to remove after next VTK update
        apply_vtk95_vktanari_patches
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0
}

function build_vtk
{
    # Extract the sources
    if [[ -d $VTK_BUILD_DIR ]] ; then
        if [[ ! -f $VTK_FILE ]] ; then
            warn "The directory VTK exists, deleting before uncompressing"
            rm -Rf $VTK_BUILD_DIR
            ensure_built_or_ready $VTK_INSTALL_DIR    $VTK_VERSION    $VTK_BUILD_DIR    $VTK_FILE
        fi
    fi

    #
    # Prepare the build dir using src file.
    #
    prepare_build_dir $VTK_BUILD_DIR $VTK_FILE
    untarred_vtk=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_vtk == -1 ]] ; then
        warn "Unable to prepare VTK build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching VTK . . ."
    cd $VTK_BUILD_DIR || error "Can't cd to VTK build dir."
    apply_vtk_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_vtk == 1 ]] ; then
            warn "Giving up on VTK build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    # move back up to the start dir
    cd "$START_DIR"

    #
    # Configure VTK
    #
    info "Configuring VTK . . ."

    # Make a build directory for an out-of-source build. Change the
    # VTK_BUILD_DIR variable to represent the out-of-source build directory.
    VTK_SRC_DIR=$VTK_BUILD_DIR
    VTK_BUILD_DIR="${VTK_SRC_DIR}-build"
    if [[ ! -d $VTK_BUILD_DIR ]] ; then
        echo "Making build directory $VTK_BUILD_DIR"
        mkdir $VTK_BUILD_DIR
    fi

    #
    # Remove the CMakeCache.txt files ... existing files sometimes prevent
    # fields from getting overwritten properly.
    #
    rm -Rf ${VTK_BUILD_DIR}/CMakeCache.txt ${VTK_BUILD_DIR}/*/CMakeCache.txt

    #
    # Setup paths and libs for python for the VTK build.
    #
    if [[ "$OPSYS" == "Darwin" ]]; then
        if [[ "${VISIT_PYTHON_DIR}/lib" != "/usr/lib" ]]; then
            export DYLD_LIBRARY_PATH="${VISIT_PYTHON_DIR}/lib/:$DYLD_LIBRARY_PATH"
        fi
    else
        export LD_LIBRARY_PATH="${VISIT_PYTHON_DIR}/lib/:$LD_LIBRARY_PATH"
    fi

    export VTK_PY_LIBS="-lpthread"
    if [[ "$OPSYS" == "Linux" ]]; then
        export VTK_PY_LIBS="$VTK_PY_LIBS -ldl -lutil -lm"
    fi

    vopts=""
    vtk_build_mode="${VISIT_BUILD_MODE}"
    vtk_inst_path="${VISITDIR}/${VTK_INSTALL_DIR}/${VTK_VERSION}/${VISITARCH}"
    vtk_debug_leaks="false"

    # Some linker flags.
    lf=""
    if test "${OPSYS}" = "Darwin" ; then
        lf="-Wl,-headerpad_max_install_names"
        lf="${lf},-compatibility_version,${VTK_COMPATIBILITY_VERSION}"
        lf="${lf},-current_version,${VTK_VERSION}"
    fi
    # normal stuff
    vopts="${vopts} -DCMAKE_BUILD_TYPE:STRING=${vtk_build_mode}"
    vopts="${vopts} -DCMAKE_INSTALL_PREFIX:PATH=${vtk_inst_path}"
    if test "x${DO_STATIC_BUILD}" = "xyes" ; then
        vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    else
        vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=ON"
    fi
    vopts="${vopts} -DVTK_DEBUG_LEAKS:BOOL=${vtk_debug_leaks}"
    vopts="${vopts} -DVTK_LEGACY_REMOVE:BOOL=true"
    vopts="${vopts} -DCMAKE_C_COMPILER:STRING=${C_COMPILER}"
    vopts="${vopts} -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}"
    vopts="${vopts} -DCMAKE_C_FLAGS:STRING=\"${C_OPT_FLAGS}\""
    vopts="${vopts} -DCMAKE_CXX_FLAGS:STRING=\"${CXX_OPT_FLAGS}\""
    vopts="${vopts} -DCMAKE_EXE_LINKER_FLAGS:STRING=${lf}"
    vopts="${vopts} -DCMAKE_MODULE_LINKER_FLAGS:STRING=${lf}"
    vopts="${vopts} -DCMAKE_SHARED_LINKER_FLAGS:STRING=${lf}"
    vopts="${vopts} -DVTK_BUILD_TESTING:STRING=OFF"
    vopts="${vopts} -DVTK_BUILD_DOCUMENTATION:BOOL=OFF"
    vopts="${vopts} -DVTK_FORBID_DOWNLOADS:BOOL=ON"
    # setting this to true causes errors when building debug versions of
    # visit, so set it to false
    vopts="${vopts} -DVTK_REPORT_OPENGL_ERRORS:BOOL=false"

    if test "${OPSYS}" = "Darwin" ; then

        vopts="${vopts} -DVTK_USE_COCOA:BOOL=ON"
        vopts="${vopts} -DCMAKE_INSTALL_NAME_DIR:PATH=${vtk_inst_path}/lib"

        if test "${MACOSX_DEPLOYMENT_TARGET}" = "10.10"; then
            # If building on 10.10 (Yosemite) check if we are building with Xcode 7 ...
            XCODE_VER=$(xcodebuild -version | head -n 1 | awk '{print $2}')
            if test ${XCODE_VER%.*} == 7; then
                # Workaround for Xcode 7 not having a 10.10 SDK: Prevent CMake from linking to 10.11 SDK
                # by using Frameworks installed in root directory.
                echo "Xcode 7 on MacOS 10.10 detected: Enabling CMake workaround"
                vopts="${vopts} -DCMAKE_OSX_DEPLOYMENT_TARGET:STRING=\"\" -DCMAKE_OSX_SYSROOT:STRING=/"
            fi
        elif test "${MACOSX_DEPLOYMENT_TARGET}" = "10.12"; then
            # If building on 10.12 (Sierra) check if we are building with Xcode 9 ...
            XCODE_VER=$(xcodebuild -version | head -n 1 | awk '{print $2}')
            if test ${XCODE_VER%.*} == 9; then
                # Workaround for Xcode 9 not having a 10.12 SDK: Prevent CMake from linking to 10.13 SDK
                # by using Frameworks installed in root directory.
                echo "Xcode 9 on MacOS 10.12 detected: Enabling CMake workaround"
                vopts="${vopts} -DCMAKE_OSX_DEPLOYMENT_TARGET:STRING=\"\" -DCMAKE_OSX_SYSROOT:STRING=/"
            fi
        fi
    fi

    # allow VisIt to override any of vtk's classes
    vopts="${vopts} -DVTK_ALL_NEW_OBJECT_FACTORY:BOOL=true"
    # disable downloads (also disables testing)
    vopts="${vopts} -DVTK_FORBID_DOWNLOADS:BOOL=true"

    # Turn off module groups
    vopts="${vopts} -DVTK_GROUP_ENABLE_Imaging:STRING=DONT_WANT"
    vopts="${vopts} -DVTK_GROUP_ENABLE_MPI:STRING=DONT_WANT"
    vopts="${vopts} -DVTK_GROUP_ENABLE_Qt:STRING=DONT_WANT"
    vopts="${vopts} -DVTK_GROUP_ENABLE_Rendering:STRING=DONT_WANT"
    vopts="${vopts} -DVTK_GROUP_ENABLE_StandAlone:STRING=DONT_WANT"
    # one of the vtk modules introduced this case for StandALone
    # Probably a mistake, but guard against it anyways as it shows up
    # in the Cache.
    vopts="${vopts} -DVTK_GROUP_ENABLE_STANDALONE:STRING=DONT_WANT"
    vopts="${vopts} -DVTK_GROUP_ENABLE_Views:STRING=DONT_WANT"
    vopts="${vopts} -DVTK_GROUP_ENABLE_Web:STRING=DONT_WANT"

    # Turn on individual modules. dependent modules are turned on automatically
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_CommonCore:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_FiltersFlowPaths:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_FiltersHybrid:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_FiltersModeling:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_FiltersVerdict:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_GeovisCore:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_IOEnSight:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_IOGeometry:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_IOLegacy:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_IOPLY:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_IOXML:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_InteractionStyle:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingAnnotation:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingFreeType:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingOpenGL2:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingVolumeOpenGL2:STRING=YES"
    vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_libxml2:STRING=YES"
    vopts="${vopts} -DVTK_ENABLE_REMOTE_MODULES:BOOL=OFF"

    # Tell VTK where to locate qmake if we're building graphical support. We
    # do not add graphical support for server-only builds.
    if [[ "$DO_QT" == "yes" ]] ; then
        vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_GUISupportQt:STRING=YES"
        vopts="${vopts} -DQt6_DIR:PATH=${QT_INSTALL_DIR}/lib/cmake/Qt6"
        vopts="${vopts} -DQt6CoreTools_DIR:PATH=${QT_INSTALL_DIR}/lib/cmake/Qt6CoreTools"
        vopts="${vopts} -DQt6GuiTools_DIR:PATH=${QT_INSTALL_DIR}/lib/cmake/Qt6GuiTools"
        vopts="${vopts} -DQt6WidgetsTools_DIR:PATH=${QT_INSTALL_DIR}/lib/cmake/Qt6WidgetsTools"
    fi

    # Add python wrapping
    if [[ "$DO_DBIO_ONLY" != "yes" ]]; then
        # python... but static libs and python filters are incompatible.
        if [[ "$DO_STATIC_BUILD" != "yes" ]]; then
            py="${PYTHON_COMMAND}"
            pyinc="${PYTHON_INCLUDE_DIR}"
            pylib="${PYTHON_LIBRARY}"

            vopts="${vopts} -DVTK_WRAP_PYTHON:BOOL=true"
            vopts="${vopts} -DPython3_EXECUTABLE:FILEPATH=${py}"
            vopts="${vopts} -DPython3_EXTRA_LIBS:STRING=\"${VTK_PY_LIBS}\""
            vopts="${vopts} -DPython3_INCLUDE_DIR:PATH=${pyinc}"
            vopts="${vopts} -DPython3_LIBRARY:FILEPATH=${pylib}"
        else
            warn "Forgetting python filters because we are doing a static build."
        fi
    fi

    # For now, turn off EGL (Our large-image regression tests fail)
    vopts="${vopts} -DOPENGL_EGL_INCLUDE_DIR:PATH=\"\""
    vopts="${vopts} -DOPENGL_egl_LIBRARY:FILEPATH=\"\""
    vopts="${vopts} -DVTK_OPENGL_HAS_EGL:BOOL=OFF"

    if [[ "$OPSYS" == "Linux" ]]; then
        vopts="${vopts} -DVTK_USE_X:BOOL=ON"
    fi

    # Use Mesa as GL?
    if [[ "$DO_MESAGL" == "yes" ]] ; then
        vopts="${vopts} -DOPENGL_INCLUDE_DIR:PATH=${MESAGL_INCLUDE_DIR}"
        vopts="${vopts} -DOPENGL_gl_LIBRARY:STRING=${MESAGL_OPENGL_LIB}"
        vopts="${vopts} -DOPENGL_opengl_LIBRARY:STRING="
        vopts="${vopts} -DOPENGL_glu_LIBRARY:FILEPATH=${MESAGL_GLU_LIB}"
        # for now, until Mesa can be updated to a version that supports GLVND,
        # set LEGACY preference
        vopts="${vopts} -DOpenGL_GL_PREFERENCE:STRING=LEGACY"
        vopts="${vopts} -DVTK_OPENGL_HAS_OSMESA:BOOL=ON"
        vopts="${vopts} -DOSMESA_LIBRARY:STRING=${MESAGL_OSMESA_LIB}"
        vopts="${vopts} -DOSMESA_INCLUDE_DIR:PATH=${MESAGL_INCLUDE_DIR}"

    #elif [[ "$DO_OSMESA" == "yes" ]] ; then
    #    # Is there a use-case where VTK-9.5 would need to build against only OSMesa?
    #    vopts="${vopts} -DOPENGL_INCLUDE_DIR:PATH="
    #    vopts="${vopts} -DOPENGL_gl_LIBRARY:STRING="
    #    vopts="${vopts} -DOPENGL_opengl_LIBRARY:STRING="
    #    vopts="${vopts} -DOPENGL_glu_LIBRARY:FILEPATH="
    #    vopts="${vopts} -DVTK_OPENGL_HAS_OSMESA:BOOL=ON"
    #    vopts="${vopts} -DOSMESA_LIBRARY:STRING=\"${OSMESA_LIB}\""
    #    vopts="${vopts} -DOSMESA_INCLUDE_DIR:PATH=${OSMESA_INCLUDE_DIR}"
    #    vopts="${vopts} -DVTK_USE_X:BOOL=OFF"
    fi

    # Use OSPRay?
    if [[ "$DO_OSPRAY" == "yes" ]] ; then
        vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingRayTracing:STRING=YES"
        if [[ -d ${OSPRAY_INSTALL_DIR}/ospray/lib ]] ; then
            vopts="${vopts} -Dospray_DIR=${OSPRAY_INSTALL_DIR}/ospray/lib/cmake/ospray-${OSPRAY_VERSION}"
        elif [[ -d ${OSPRAY_INSTALL_DIR}/ospray/lib64 ]] ; then
            vopts="${vopts} -Dospray_DIR=${OSPRAY_INSTALL_DIR}/ospray/lib64/cmake/ospray-${OSPRAY_VERSION}"
        else
            warn "Disabling ospray because its lib dir couldn't be found"
            vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingRayTracing:STRING=NO"
        fi
    fi

    # Use ANARI?
    if [[ "$DO_ANARI" == "yes" ]] ; then
        vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_RenderingAnari:STRING=YES"
        vopts="${vopts} -DVTK_MODULE_ENABLE_VTK_FiltersTexture:STRING=YES"
        if [[ -d ${VISITDIR}/anari/${ANARI_VERSION}/${VISITARCH}/lib64 ]] ; then
            vopts="${vopts} -Danari_DIR=${VISITDIR}/anari/${ANARI_VERSION}/${VISITARCH}/lib64/cmake/anari-${ANARI_VERSION}"
        else
            vopts="${vopts} -Danari_DIR=${VISITDIR}/anari/${ANARI_VERSION}/${VISITARCH}/lib/cmake/anari-${ANARI_VERSION}"
        fi

        if [[ "$DO_ANARI_NVTX" == "yes" ]] ; then
            vopts="${vopts} -DVTK_ANARI_ENABLE_NVTX:BOOL=ON"
        fi
    fi

    # zlib support, use the one we build
    vopts="${vopts} -DVTK_MODULE_USE_EXTERNAL_VTK_zlib:BOOL=ON"
    vopts="${vopts} -DZLIB_INCLUDE_DIR:PATH=${ZLIB_INCLUDE_DIR}"
    if [[ "$VISIT_BUILD_MODE" == "Release" ]] ; then
        vopts="${vopts} -DZLIB_LIBRARY_RELEASE:FILEPATH=${ZLIB_LIBRARY}"
    else
        vopts="${vopts} -DZLIB_LIBRARY_DEBUG:FILEPATH=${ZLIB_LIBRARY}"
    fi

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"
    cd ${VTK_BUILD_DIR}

    if [[ "$DO_MESAGL" == "yes" || "$DO_OSMESA" == "yes"  ]] ; then
        export LD_LIBRARY_PATH="${LLVM_LIB_DIR}:$LD_LIBRARY_PATH"
    fi

    #
    # Several platforms have had problems with the VTK cmake configure command
    # issued simply via "issue_command".  This was first discovered on
    # BGQ and then showed up in random cases for both OSX and Linux machines.
    # Brad resolved this on BGQ  with a simple work around - we write a simple
    # script that we invoke with bash which calls cmake with all of the proper
    # arguments. We are now using this strategy for all platforms.
    #

    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\"" ${vopts} ../${VTK_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "VTK configuration failed."

    #
    # Now build VTK.
    #
    info "Building VTK . . . (~20 minutes)"
    env DYLD_LIBRARY_PATH=`pwd`/bin ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS || \
        error "VTK did not build correctly.  Giving up."

    info "Installing VTK . . . "
    ${CMAKE_COMMAND} --install . || error "VTK did not install correctly."

    # Filter out an include that references the user's VTK build directory
    configdir="${vtk_inst_path}/lib/cmake/vtk-${VTK_SHORT_VERSION}"
    cat ${configdir}/VTKConfig.cmake | grep -v "vtkTestingMacros" > ${configdir}/VTKConfig.cmake.new
    mv ${configdir}/VTKConfig.cmake.new ${configdir}/VTKConfig.cmake

    chmod -R ug+w,a+rX ${VISITDIR}/${VTK_INSTALL_DIR}
    if [[ "$DO_GROUP" == "yes" ]] ; then
        chgrp -R ${GROUP} "$VISITDIR/${VTK_INSTALL_DIR}"
    fi
    cd "$START_DIR"
    info "Done with VTK"
    return 0
}

function bv_vtk_is_enabled
{
    if [[ $DO_VTK == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_vtk_is_installed
{
    check_if_installed "$VTK_INSTALL_DIR" $VTK_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_vtk_build
{
    #
    # Build VTK
    #
    cd "$START_DIR"

    if [[ "$DO_VTK" == "yes" ]] ; then
        check_if_installed $VTK_INSTALL_DIR $VTK_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping VTK build.  VTK is already installed."
        else
            info "Building VTK (~20 minutes)"
            build_vtk
            if [[ $? != 0 ]] ; then
                error "Unable to build or install VTK.  Bailing out."
            fi
        fi
        info "Done building VTK"
    fi
}
function bv_vtkm_initialize
{
    export DO_VTKM="no"
    export USE_SYSTEM_VTKM="no"
    add_extra_commandline_args "vtkm" "alt-vtkm-dir" 1 "Use alternative directory for VTKm"
}

function bv_vtkm_enable
{
    DO_VTKM="yes"
}

function bv_vtkm_disable
{
    DO_VTKM="no"
}

function bv_vtkm_alt_vtkm_dir
{
    bv_vtkm_enable
    USE_SYSTEM_VTKM="yes"
    VTKM_INSTALL_DIR="$1"
    info "Using Alternate VTKM: $VTKM_INSTALL_DIR"
}

function bv_vtkm_depends_on
{
    depends_on="cmake"

    echo ${depends_on}
}

function bv_vtkm_initialize_vars
{
    if [[ "$USE_SYSTEM_VTKM" == "no" ]]; then
        VTKM_INSTALL_DIR="\${VISITHOME}/vtkm/$VTKM_VERSION/\${VISITARCH}"
    fi
}

function bv_vtkm_info
{
    export VTKM_VERSION=${VTKM_VERSION:-"v2.3.0"}
    export VTKM_FILE=${VTKM_FILE:-"vtk-m-${VTKM_VERSION}.tar.gz"}
    export VTKM_BUILD_DIR=${VTKM_BUILD_DIR:-"vtk-m-${VTKM_VERSION}"}
    export VTKM_SHA256_CHECKSUM="63f1a0273227463a1be38c046630ea6f606ed958543fe6ff64eb6bb6513a6013"
}

function bv_vtkm_print
{
    printf "%s%s\n" "VTKM_FILE=" "${VTKM_FILE}"
    printf "%s%s\n" "VTKM_VERSION=" "${VTKM_VERSION}"
    printf "%s%s\n" "VTKM_BUILD_DIR=" "${VTKM_BUILD_DIR}"
}

function bv_vtkm_print_usage
{
    printf "%-20s %s [%s]\n" "--vtkm" "Build VTKm support" "$DO_VTKM"
    printf "%-20s %s [%s]\n" "--alt-vtkm-dir" "Use VTKm from an alternative directory"
}

function bv_vtkm_host_profile
{
    if [[ "$DO_VTKM" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## VTKM" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_VTKM_DIR ${VTKM_INSTALL_DIR})" \
            >> $HOSTCONF
    fi
}

function bv_vtkm_ensure
{
    if [[ "$DO_VTKM" == "yes" && "$USE_SYSTEM_VTKM" == "no" ]] ; then
        ensure_built_or_ready "vtkm" $VTKM_VERSION $VTKM_BUILD_DIR $VTKM_FILE $VTKM_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_VTKM="no"
            error "Unable to build VTKm. ${VTKM_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_vtkm
#
#
# *************************************************************************** #
function apply_patch_1
{
   patch -p0 << \EOF
diff -c ./vtkm/cont/arg/TransportTagTopologyFieldIn.h.orig ./vtkm/cont/arg/TransportTagTopologyFieldIn.h
*** ./vtkm/cont/arg/TransportTagTopologyFieldIn.h.orig	Tue Dec  8 12:55:32 2020
--- ./vtkm/cont/arg/TransportTagTopologyFieldIn.h	Tue Dec  8 12:55:49 2020
***************
*** 90,96 ****
--- 90,98 ----
    {
      if (object.GetNumberOfValues() != detail::TopologyDomainSize(inputDomain, TopologyElementTag()))
      {
+ #if 0
        throw vtkm::cont::ErrorBadValue("Input array to worklet invocation the wrong size.");
+ #endif
      }

      return object.PrepareForInput(Device(), token);
EOF

    if [[ $? != 0 ]] ; then
      warn "vtkm patch 1 failed."
      return 1
    fi
    return 0;
}

function apply_vtkm_patch
{
    info "Patching VTKm . . ."

    apply_patch_1
    if [[ $? != 0 ]] ; then
       return 1
    fi

    return 0
}

function build_vtkm
{
    #
    # Extract the sources
    #
    if [[ -d $VTKM_BUILD_DIR ]] ; then
        if [[ ! -f $VTKM_FILE ]] ; then
            warn "The directory VTKM exists, deleting before uncompressing"
            rm -Rf $VTKM_BUILD_DIR
            ensure_built_or_ready $VTKM_INSTALL_DIR $VTKM_VERSION $VTKM_BUILD_DIR $VTKM_FILE
        fi
    fi

    #
    # Prepare build dir
    #
    prepare_build_dir $VTKM_BUILD_DIR $VTKM_FILE
    untarred_vtkm=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_vtkm == -1 ]] ; then
        warn "Unable to prepare VTKm build directory. Giving Up!"
        return 1
    fi

    #
    # Apply patches
    #
    cd $VTKM_BUILD_DIR || error "Can't cd to VTKm build dir."
    apply_vtkm_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_vtkm == 1 ]] ; then
            warn "Giving up on VTKm build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi
    # move back up to the start dir
    cd "$START_DIR"

    #
    # Configure VTKM
    #
    info "Configuring VTKm . . ."

    CMAKE_BIN="${CMAKE_INSTALL}/cmake"

    # Make a build directory for an out-of-source build.. Change the
    # VTKM_BUILD_DIR variable to represent the out-of-source build directory.
    VTKM_SRC_DIR=$VTKM_BUILD_DIR
    VTKM_BUILD_DIR="${VTKM_SRC_DIR}-build"
    if [[ ! -d $VTKM_BUILD_DIR ]] ; then
        echo "Making build directory $VTKM_BUILD_DIR"
        mkdir $VTKM_BUILD_DIR
    fi

    cd $VTKM_BUILD_DIR || error "Can't cd to VTKm build dir."

    vopts=""
    vopts="${vopts} -DCMAKE_INSTALL_PREFIX:PATH=${VISITDIR}/vtkm/${VTKM_VERSION}/${VISITARCH}"
    vopts="${vopts} -DVTKm_ENABLE_TESTING:BOOL=OFF"
    vopts="${vopts} -DVTKm_ENABLE_TESTING_LIBRARY:BOOL=ON"
    vopts="${vopts} -DVTKm_ENABLE_RENDERING:BOOL=ON"
    vopts="${vopts} -DVTKm_USE_64BIT_IDS:BOOL=OFF"
    vopts="${vopts} -DVTKm_USE_DOUBLE_PRECISION:BOOL=ON"
    vopts="${vopts} -DVTKm_USE_DEFAULT_TYPES_FOR_VTK:BOOL=ON"
    vopts="${vopts} -DCMAKE_BUILD_TYPE:STRING=${VISIT_BUILD_MODE}"
    vopts="${vopts} -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON"
    vopts="${vopts} -DBUILD_SHARED_LIBS:BOOL=OFF"
    # Disable CUDA support for now since it requires using the CUDA compiler
    # to build all of VisIt, which we don't want to do.
    #if [[ -d $CUDA_HOME ]]; then
    #    echo "Building with CUDA support."
    #    vopts="${vopts} -DVTKm_ENABLE_CUDA:BOOL=ON"
    #    vopts="${vopts} -DVTKm_CUDA_Architecture=kepler"
    #fi

    #
    # Several platforms have had problems with the VTK cmake configure
    # command issued simply via "issue_command".  This was first discovered
    # on BGQ and then showed up in random cases for both OSX and Linux
    # machines. Brad resolved this on BGQ  with a simple work around - we
    # write a simple script that we invoke with bash which calls cmake with
    # all of the properly arguments. We are now using this strategy for all
    # platforms.
    #
    if test -e bv_run_cmake.sh ; then
        rm -f bv_run_cmake.sh
    fi
    echo "\"${CMAKE_BIN}\"" ${vopts} ../${VTKM_SRC_DIR} > bv_run_cmake.sh
    cat bv_run_cmake.sh
    issue_command bash bv_run_cmake.sh || error "VTKm configuration failed."

    #
    # Build vtkm
    #
    info "Building VTKm . . . (~2 minutes)"
    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS || error "VTKm did not build correctly. Giving up."

    info "Installing VTKm . . . (~2 minutes)"
    ${CMAKE_COMMAND} --install . || error "VTKm did not install correctly."

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/vtkm"
        chgrp -R ${GROUP} "$VISITDIR/vtkm"
    fi
    cd "$START_DIR"
    info "Done with vtkm"
    return 0
}

function bv_vtkm_is_enabled
{
    if [[ $DO_VTKM == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_vtkm_is_installed
{
    if [[ "$USE_SYSTEM_VTKM" == "yes" ]]; then
        return 1
    fi

    check_if_installed "vtkm" $VTKM_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_vtkm_build
{
    cd "$START_DIR"
    if [[ "$DO_VTKM" == "yes" && "$USE_SYSTEM_VTKM" == "no" ]] ; then
        check_if_installed "vtkm" $VTKM_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping VTKm build. VTKm is already installed."
        else
            info "Building VTKm (~2 minutes)"
            build_vtkm
            if [[ $? != 0 ]] ; then
                error "Unable to build or install VTKm.  Bailing out."
            fi
            info "Done building VTKm"
        fi
    fi
}
function bv_xcb_initialize
{
    export DO_XCB="no"
}

function bv_xcb_enable
{
    DO_XCB="yes"
}

function bv_xcb_disable
{
    DO_XCB="no"
}

function bv_xcb_depends_on
{
    local depends_on=""

    echo ${depends_on}
}

function bv_xcb_initialize_vars
{
    XCB_INSTALL_DIR="${VISITDIR}/xcb/$XCB_VERSION/${VISITARCH}"
}

function bv_xcb_info
{
    export XCB_VERSION=${XCB_VERSION:-"0.4.1"}
    export XCB_IMAGE_VERSION=${XCB_IMAGE_VERSION:-"0.4.1"}
    export XCB_IMAGE_FILE=${XCB_IMAGE_FILE:-"libxcb-image-xcb-util-image-${XCB_IMAGE_VERSION}.tar.gz"}
    export XCB_IMAGE_BUILD_DIR=${XCB_IMAGE_BUILD_DIR:-"libxcb-image-xcb-util-image-${XCB_IMAGE_VERSION}"}
    export XCB_IMAGE_SHA256_CHECKSUM="f8aea5230dcf736aa86a005ba486f58b689f183006c26ecc44b91ed6b11598d4"
    export XCB_KEYSYMS_VERSION=${XCB_KEYSYMS_VERSION:-"0.4.1"}
    export XCB_KEYSYMS_FILE=${XCB_KEYSYMS_FILE:-"libxcb-keysyms-xcb-util-keysyms-${XCB_KEYSYMS_VERSION}.tar.gz"}
    export XCB_KEYSYMS_BUILD_DIR=${XCB_KEYSYMS_BUILD_DIR:-"libxcb-keysyms-xcb-util-keysyms-${XCB_KEYSYMS_VERSION}"}
    export XCB_KEYSYMS_SHA256_CHECKSUM="2780db069685a95f132a48d637e7f66ffd0a2483e960157536f58f4671d93f5c"
    export XCB_M4_VERSION=${XCB_M4_VERSION:-"0.4.1"}
    export XCB_M4_FILE=${XCB_M4_FILE:-"libxcb-m4-xcb-util-m4-${XCB_M4_VERSION}.tar.gz"}
    export XCB_M4_BUILD_DIR=${XCB_M4_BUILD_DIR:-"libxcb-m4-xcb-util-m4-${XCB_M4_VERSION}"}
    export XCB_M4_SHA256_CHECKSUM="f60369c3bad234798867b768fc01183395a20f74c521a48e5e996f938df2d45a"
    export XCB_RENDERUTIL_VERSION=${XCB_RENDERUTIL_VERSION:-"0.3.10"}
    export XCB_RENDERUTIL_FILE=${XCB_RENDERUTIL_FILE:-"libxcb-render-util-xcb-util-renderutil-${XCB_RENDERUTIL_VERSION}.tar.gz"}
    export XCB_RENDERUTIL_BUILD_DIR=${XCB_RENDERUTIL_BUILD_DIR:-"libxcb-render-util-xcb-util-renderutil-${XCB_RENDERUTIL_VERSION}"}
    export XCB_RENDERUTIL_SHA256_CHECKSUM="160017e3e8e61acb8ddfbce885f294623a46f92f20c5f5066ee6d1b720971548"
    export XCB_UTIL_VERSION=${XCB_UTIL_VERSION:-"0.4.1"}
    export XCB_UTIL_FILE=${XCB_UTIL_FILE:-"libxcb-util-xcb-util-${XCB_UTIL_VERSION}.tar.gz"}
    export XCB_UTIL_BUILD_DIR=${XCB_UTIL_BUILD_DIR:-"libxcb-util-xcb-util-${XCB_UTIL_VERSION}"}
    export XCB_UTIL_SHA256_CHECKSUM="7b56592b339d47809cbefb9f46721705c662de1a001bc773d335975cd2eba34f"
    export XCB_WM_VERSION=${XCB_WM_VERSION:-"0.4.2"}
    export XCB_WM_FILE=${XCB_WM_FILE:-"libxcb-wm-xcb-util-wm-${XCB_WM_VERSION}.tar.gz"}
    export XCB_WM_BUILD_DIR=${XCB_WM_BUILD_DIR:-"libxcb-wm-xcb-util-wm-${XCB_WM_VERSION}"}
    export XCB_WM_SHA256_CHECKSUM="c1b792306874c36b535413a33edc71a0ac46e78adcf6ddb1a34090a07393d717"
    export XORG_MACROS_VERSION=${XORG_MACROS_VERSION:-"1.20.2"}
    export XORG_MACROS_FILE=${XORG_MACROS_FILE:-"macros-util-macros-${XORG_MACROS_VERSION}.tar.gz"}
    export XORG_MACROS_BUILD_DIR=${XORG_MACROS_BUILD_DIR:-"macros-util-macros-${XORG_MACROS_VERSION}"}
    export XORG_MACROS_SHA256_CHECKSUM="beac7e00e5996bd0c9d9bd8cf62704583b22dbe8613bd768626b95fcac955744"
}

function bv_xcb_print
{
    printf "%s%s\n" "XCB_VERSION=" "${XCB_VERSION}"
    printf "%s%s\n" "XCB_IMAGE_FILE=" "${XCB_IMAGE_FILE}"
    printf "%s%s\n" "XCB_IMAGE_VERSION=" "${XCB_IMAGE_VERSION}"
    printf "%s%s\n" "XCB_IMAGE_BUILD_DIR=" "${XCB_IMAGE_BUILD_DIR}"
    printf "%s%s\n" "XCB_KEYSYMS_FILE=" "${XCB_KEYSYMS_FILE}"
    printf "%s%s\n" "XCB_KEYSYMS_VERSION=" "${XCB_KEYSYMS_VERSION}"
    printf "%s%s\n" "XCB_KEYSYMS_BUILD_DIR=" "${XCB_KEYSYMS_BUILD_DIR}"
    printf "%s%s\n" "XCB_M4_FILE=" "${XCB_M4_FILE}"
    printf "%s%s\n" "XCB_M4_VERSION=" "${XCB_M4_VERSION}"
    printf "%s%s\n" "XCB_M4_BUILD_DIR=" "${XCB_M4_BUILD_DIR}"
    printf "%s%s\n" "XCB_RENDERUTIL_FILE=" "${XCB_RENDERUTIL_FILE}"
    printf "%s%s\n" "XCB_RENDERUTIL_VERSION=" "${XCB_RENDERUTIL_VERSION}"
    printf "%s%s\n" "XCB_RENDERUTIL_BUILD_DIR=" "${XCB_RENDERUTIL_BUILD_DIR}"
    printf "%s%s\n" "XCB_UTIL_FILE=" "${XCB_UTIL_FILE}"
    printf "%s%s\n" "XCB_UTIL_VERSION=" "${XCB_UTIL_VERSION}"
    printf "%s%s\n" "XCB_UTIL_BUILD_DIR=" "${XCB_UTIL_BUILD_DIR}"
    printf "%s%s\n" "XCB_WM_FILE=" "${XCB_WM_FILE}"
    printf "%s%s\n" "XCB_WM_VERSION=" "${XCB_WM_VERSION}"
    printf "%s%s\n" "XCB_WM_BUILD_DIR=" "${XCB_WM_BUILD_DIR}"
    printf "%s%s\n" "XORG_MACROS_FILE=" "${XORG_MACROS_FILE}"
    printf "%s%s\n" "XORG_MACROS_VERSION=" "${XORG_MACROS_VERSION}"
    printf "%s%s\n" "XORG_MACROS_BUILD_DIR=" "${XORG_MACROS_BUILD_DIR}"
}

function bv_xcb_print_usage
{
    printf "%-20s %s [%s]\n" "--xcb" "Build xcb support" "$DO_XCB"
}

function bv_xcb_host_profile
{
    if [[ "$DO_XCB" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Xcb" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_XCB_DIR \${VISITHOME}/xcb/$XCB_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi
}

function bv_xcb_ensure
{
    if [[ "$DO_XCB" == "yes" ]] ; then
        INSTALL_DIR=$VISITDIR/xcb/$XCB_VERSION/$VISITARCH

        # check if individual libs/components have been installed
        PATTERN=(${INSTALL_DIR}/lib/*xcb-image.*)
        ensure_built_or_ready_component "xcb" $XCB_VERSION $XCB_IMAGE_FILE $PATTERN
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XCB="no"
            error "Unable to build xcb image. ${XCB_IMAGE_FILE} not found."
        fi

        PATTERN=(${INSTALL_DIR}/lib/*xcb-keysyms.*)
        ensure_built_or_ready_component "xcb" $XCB_VERSION $XCB_KEYSYMS_FILE $PATTERN
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XCB="no"
            error "Unable to build xcb keysyms. ${XCB_KEYSYMS_FILE} not found."
        fi

        PATTERN=(${INSTALL_DIR}/lib/*xcb-render-util.*)
        ensure_built_or_ready_component "xcb" $XCB_VERSION $XCB_RENDERUTIL_FILE $PATTERN
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XCB="no"
            error "Unable to build xcb renderutil. ${XCB_RENDERUTIL_FILE} not found."
        fi

        PATTERN=(${INSTALL_DIR}/lib/*xcb-util.*)
        ensure_built_or_ready_component "xcb"  $XCB_VERSION $XCB_UTIL_FILE $PATTERN
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XCB="no"
            error "Unable to build xcb util. ${XCB_UTIL_FILE} not found."
        fi

        PATTERN=(${INSTALL_DIR}/lib/*xcb-ewmh.*)
        ensure_built_or_ready_component "xcb" $XCB_VERSION $XCB_WM_FILE $PATTERN
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XCB="no"
            error "Unable to build xcb wm. ${XCB_WM_FILE} not found."
        fi

        # if XCB_IMAGE_FILE was downloaded, assume we need the utils as well
        if [[ -e ${XCB_IMAGE_FILE} ]] ; then
            if [[ ! -e ${XORG_MACROS_FILE} ]] ; then
                download_file $XORG_MACROS_FILE
            fi
            if [[ ! -e ${XCB_M4_FILE} ]] ; then
                download_file $XCB_M4_FILE
            fi
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_xcb
#
# Modifications:
#
# *************************************************************************** #
function build_xcb
{
    # QT6 requires the following XCB modules
    # The modules marked with an asterisk are being built by build_visit.
    # The remaining ones come from XCB proper and are usually installed on
    # the system. If we run across a system that doesn't have any XCB
    # stuff installed we can add building XCB. It can be found at
    # https://gitlab.freedesktop.org/xorg/lib/libxcb.
    #
    # XCB
    # ICCCM       *
    # SHM
    # IMAGE       *
    # KEYSYMS     *
    # RENDER
    # RENDERUTIL  *
    # RANDR
    # SHAPE
    # SYNC
    # XFIXES
    # XKB
    # GLX
    # XINPUT

    # XORG MACROS
    # https://gitlab.freedesktop.org/xorg/util/macros
    # Provides m4 macros needed as part of configure process by other packages.
    #
    # Prepare build dir
    #
    prepare_build_dir $XORG_MACROS_BUILD_DIR $XORG_MACROS_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xorg macros build directory. Giving Up!"
        return 1
    fi

    #
    # Configure and install
    #
    info "Configuring and installing xorg macros . . . (~1 minute)"
    cd $XORG_MACROS_BUILD_DIR || error "Can't cd to xorg macros build dir."

    ./autogen.sh

    cd ..

    # XCB M4
    # https://gitlab.freedesktop.org/xorg/util/xcb-util-m4
    # Provides m4 macros needed as part of configure process by other packages.
    #
    # Prepare build dir
    #
    prepare_build_dir $XCB_M4_BUILD_DIR $XCB_M4_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xcb m4 build directory. Giving Up!"
        return 1
    fi

    #
    # Nothing else to do since all we do is untar the file.
    #

    # XCB UTIL
    # https://gitlab.freedesktop.org/xorg/lib/libxcb-util
    # Provides aux, atom, event
    #
    # Prepare build dir
    #
    prepare_build_dir $XCB_UTIL_BUILD_DIR $XCB_UTIL_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xcb util build directory. Giving Up!"
        return 1
    fi

    #
    # Configure and install
    #
    info "Configuring and installing xcb util . . . (~1 minute)"
    cd $XCB_UTIL_BUILD_DIR || error "Can't cd to xcb util build dir."
    cd m4
    cp ../../macros-util-macros-1.20.2/* .
    cp ../../libxcb-m4-xcb-util-m4-0.4.1/* .
    cd ..

    ./autogen.sh --prefix=${XCB_INSTALL_DIR}

    make install
    cd ..

    # Add the pkgconfig directory to the PKG_CONFIG_PATH so that pkg-config
    # can find xcb util needed by the rest of the xcb packages and qt6.
    export PKG_CONFIG_PATH=${XCB_INSTALL_DIR}/lib/pkgconfig:$PKG_CONFIG_PATH

    # XCB IMAGE
    # https://gitlab.freedesktop.org/xorg/lib/libxcb-image
    # Provides image
    #
    # Prepare build dir
    #
    prepare_build_dir $XCB_IMAGE_BUILD_DIR $XCB_IMAGE_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xcb image build directory. Giving Up!"
        return 1
    fi

    #
    # Configure and install
    #
    info "Configuring and installing xcb image . . . (~1 minute)"
    cd $XCB_IMAGE_BUILD_DIR || error "Can't cd to xcb image build dir."
    cd m4
    cp ../../macros-util-macros-1.20.2/* .
    cp ../../libxcb-m4-xcb-util-m4-0.4.1/* .
    cd ..

    ./autogen.sh --prefix=${XCB_INSTALL_DIR}
    make install
    cd ..

    # XCB KEYSYMS
    # https://gitlab.freedesktop.org/xorg/lib/libxcb-keysyms
    # Provides keysyms
    #
    # Prepare build dir
    #
    prepare_build_dir $XCB_KEYSYMS_BUILD_DIR $XCB_KEYSYMS_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xcb keysyms build directory. Giving Up!"
        return 1
    fi

    #
    # Configure and install
    #
    info "Configuring and installing xcb keysyms . . . (~1 minute)"
    cd $XCB_KEYSYMS_BUILD_DIR || error "Can't cd to xcb keysyms build dir."
    cd m4
    cp ../../macros-util-macros-1.20.2/* .
    cp ../../libxcb-m4-xcb-util-m4-0.4.1/* .
    cd ..

    ./autogen.sh --prefix=${XCB_INSTALL_DIR}
    make install
    cd ..

    # XCB WM
    # https://gitlab.freedesktop.org/xorg/lib/libxcb-wm
    # Provides ewmh, icccm
    #
    # Prepare build dir
    #
    prepare_build_dir $XCB_WM_BUILD_DIR $XCB_WM_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xcb wm build directory. Giving Up!"
        return 1
    fi

    #
    # Configure and install
    #
    info "Configuring and installing xcb wm . . . (~1 minute)"
    cd $XCB_WM_BUILD_DIR || error "Can't cd to xcb wm build dir."
    cd m4
    cp ../../macros-util-macros-1.20.2/* .
    cp ../../libxcb-m4-xcb-util-m4-0.4.1/* .
    cd ..

    ./autogen.sh --prefix=${XCB_INSTALL_DIR}
    make install
    cd ..

    # XCB RENDERUTIL
    # https://gitlab.freedesktop.org/xorg/lib/libxcb-render-util
    # Provides renderutil
    #
    # Prepare build dir
    #
    prepare_build_dir $XCB_RENDERUTIL_BUILD_DIR $XCB_RENDERUTIL_FILE
    untarred_xcb=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xcb == -1 ]] ; then
        warn "Unable to prepare xcb renderutil build directory. Giving Up!"
        return 1
    fi

    #
    # Configure and install
    #
    info "Configuring and installing xcb renderutil . . . (~1 minute)"
    cd $XCB_RENDERUTIL_BUILD_DIR || error "Can't cd to xcb renderutil build dir."
    cd m4
    cp ../../macros-util-macros-1.20.2/* .
    cp ../../libxcb-m4-xcb-util-m4-0.4.1/* .
    cd ..

    ./autogen.sh --prefix=${XCB_INSTALL_DIR}
    make install
    cd ..

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/xcb"
        chgrp -R ${GROUP} "$VISITDIR/xcb"
    fi
    cd "$START_DIR"
    info "Done with xcb"
    return 0
}

function bv_xcb_is_enabled
{
    if [[ $DO_XCB == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_xcb_is_installed
{
    check_if_installed "xcb" $XCB_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_xcb_build
{
    cd "$START_DIR"
    if [[ "$DO_XCB" == "yes" ]] ; then
        check_if_installed "xcb" $XCB_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping xcb build. Xcb is already installed."
        else
            info "Building xcb (~5 minutes)"
            build_xcb
            if [[ $? != 0 ]] ; then
                error "Unable to build or install xcb.  Bailing out."
            fi
            info "Done building xcb"
        fi
    fi
}
function bv_xdmf_initialize
{
    export DO_XDMF="no"
}

function bv_xdmf_enable
{
    DO_XDMF="yes"

    #xdmf is dependent on HDF5
    DO_HDF5="yes"
}

function bv_xdmf_disable
{
    DO_XDMF="no"
}

function bv_xdmf_depends_on
{
    echo "cmake vtk hdf5 zlib"
}

function bv_xdmf_info
{
    export XDMF_FILE=${XDMF_FILE:-"Xdmf-2.1.1.tar.gz"}
    export XDMF_VERSION=${XDMF_VERSION:-"2.1.1"}
    export XDMF_COMPATIBILITY_VERSION=${XDMF_COMPATIBILITY_VERSION:-"2.1.1"}
    export XDMF_BUILD_DIR=${XDMF_BUILD_DIR:-"Xdmf"}
    export XDMF_SHA256_CHECKSUM="4f0c2011d1d6f86052b102b25b36276168a31e191b4206a8d0c9d716ebced7e1"
}

function bv_xdmf_print
{
    printf "%s%s\n" "XDMF_FILE=" "${XDMF_FILE}"
    printf "%s%s\n" "XDMF_VERSION=" "${XDMF_VERSION}"
    printf "%s%s\n" "XDMF_COMPATIBILITY_VERSION=" "${XDMF_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "XDMF_BUILD_DIR=" "${XDMF_BUILD_DIR}"
}

function bv_xdmf_print_usage
{
    printf "%-20s %s [%s]\n" "--xdmf" "Build Xdmf" "$DO_XDMF"
}

function bv_xdmf_host_profile
{
    if [[ "$DO_XDMF" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Xdmf" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_XDMF_DIR \${VISITHOME}/Xdmf/$XDMF_VERSION/\${VISITARCH})" \
            >> $HOSTCONF

        xml64=""
        xmlsep="-"
        if test -e $VISITDIR/${VTK_INSTALL_DIR}/$VTK_VERSION/$VISITARCH/lib64 ; then
            xml64="64"
        fi
        if test -e $VISITDIR/${VTK_INSTALL_DIR}/$VTK_VERSION/$VISITARCH/lib${xml64}/libvtklibxml2.${VTK_SHORT_VERSION}.${SO_EXT}; then
            xmlsep="."
        fi
        echo \
            "VISIT_OPTION_DEFAULT(VISIT_XDMF_LIBDEP HDF5_LIBRARY_DIR hdf5 ${VISIT_HDF5_LIBDEP} \${VISIT_VTK_DIR}/lib${xml64} vtklibxml2${xmlsep}\${VTK_MAJOR_VERSION}.\${VTK_MINOR_VERSION} TYPE STRING)"\
                >> $HOSTCONF
    fi
}

function bv_xdmf_ensure
{
    if [[ "$DO_XDMF" == "yes" ]] ; then
        ensure_built_or_ready "Xdmf" $XDMF_VERSION $XDMF_BUILD_DIR $XDMF_FILE
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XDMF="no"
            error "Unable to build XDMF.  ${XDMF_FILE} not found."
        fi
    fi
}


# *************************************************************************** #
#                         Function 8.19, build_xdmf                           #
# *************************************************************************** #

function apply_xdmf_patch1
{
   patch -p0 << \EOF
diff -c a/libsrc/FXdmfValuesBinary.cxx Xdmf/libsrc/XdmfValuesBinary.cxx
*** a/libsrc/XdmfValuesBinary.cxx
--- Xdmf/libsrc/XdmfValuesBinary.cxx
***************
*** 282,288 ****
      }
      FullFileName << DataSetName << ends;
      char * path = FullFileName.rdbuf()->str();
!     XdmfDebug("Opening Binary Data for Reading : " << FullFileName);


      //char * path = new char [ strlen(this->DOM->GetWorkingDirectory())+strlen(DataSetName) + 1 ];
--- 282,288 ----
      }
      FullFileName << DataSetName << ends;
      char * path = FullFileName.rdbuf()->str();
!     XdmfDebug("Opening Binary Data for Reading : " << path);


      //char * path = new char [ strlen(this->DOM->GetWorkingDirectory())+strlen(DataSetName) + 1 ];
EOF
    if [[ $? != 0 ]] ; then
        warn "Xdmf patch1 failed."
        return 1
    fi

    return 0;

}

function apply_xdmf_patch2
{
    info "Patching Xdmf 2.1.1 for null ptr fix . . ."
    patch -p0 << \EOF
diff -c Xdmf/libsrc/XdmfDsmComm.cxx.orig Xdmf/libsrc/XdmfDsmComm.cxx
*** Xdmf/libsrc/XdmfDsmComm.cxx.orig    Thu Aug 23 22:05:42 2018
--- Xdmf/libsrc/XdmfDsmComm.cxx         Thu Aug 23 21:27:43 2018
***************
*** 50,56 ****
          XdmfErrorMessage("Cannot Receive Message of Length = " << Msg->Length);
          return(XDMF_FAIL);
      }
!     if(Msg->Data <= 0 ){
          XdmfErrorMessage("Cannot Receive Message into Data Buffer = " << Msg->Length);
          return(XDMF_FAIL);
      }
--- 50,56 ----
          XdmfErrorMessage("Cannot Receive Message of Length = " << Msg->Length);
          return(XDMF_FAIL);
      }
!     if(Msg->Data == (void *) NULL ){
          XdmfErrorMessage("Cannot Receive Message into Data Buffer = " << Msg->Length);
          return(XDMF_FAIL);
      }
***************
*** 64,70 ****
          XdmfErrorMessage("Cannot Send Message of Length = " << Msg->Length);
          return(XDMF_FAIL);
      }
!     if(Msg->Data <= 0 ){
          XdmfErrorMessage("Cannot Send Message from Data Buffer = " << Msg->Length);
          return(XDMF_FAIL);
      }
--- 64,70 ----
          XdmfErrorMessage("Cannot Send Message of Length = " << Msg->Length);
          return(XDMF_FAIL);
      }
!     if(Msg->Data == (void *) NULL ){
          XdmfErrorMessage("Cannot Send Message from Data Buffer = " << Msg->Length);
          return(XDMF_FAIL);
      }
EOF
    if [[ $? != 0 ]] ; then
        warn "Xdmf 2.1.1 null ptr patch failed."
        return 1
    fi

    return 0;
}

function apply_xdmf_patch
{
    if [[ ${XDMF_VERSION} == 2.1.1 ]] ; then
        apply_xdmf_patch1
        if [[ $? != 0 ]] ; then
            return 1
        fi

        apply_xdmf_patch2
        if [[ $? != 0 ]] ; then
            return 1
        fi
    fi

    return 0;
}

function build_xdmf
{
    CMAKE_BIN="${CMAKE_COMMAND}"

    #
    # Prepare build dir
    #
    prepare_build_dir $XDMF_BUILD_DIR $XDMF_FILE
    untarred_xdmf=$?
    if [[ $untarred_xdmf == -1 ]] ; then
        warn "Unable to prepare Xdmf Build Directory. Giving up"
        return 1
    fi

    #
    # Apply patches
    #
    info "Patching Xdmf . . ."
    apply_xdmf_patch
    if [[ $? != 0 ]] ; then
        if [[ $untarred_xdmf == 1 ]] ; then
            warn "Giving up on Xdmf build because the patch failed."
            return 1
        else
            warn "Patch failed, but continuing.  I believe that this script\n" \
                 "tried to apply a patch to an existing directory that had\n" \
                 "already been patched ... that is, the patch is\n" \
                 "failing harmlessly on a second application."
        fi
    fi

    cd $XDMF_BUILD_DIR || error "Can't cd to Xdmf build dir."
    rm -f CMakeCache.txt #remove any CMakeCache that may have existed

    #
    # Configure Xdmf
    #
    info "Executing CMake on Xdmf"
    if [[ "$DO_STATIC_BUILD" == "yes" ]]; then
        XDMF_SHARED_LIBS="OFF"
        LIBEXT="a"
    else
        XDMF_SHARED_LIBS="ON"
        LIBEXT="${SO_EXT}"
    fi

    xml64=""
    xmlsep="-"
    xmlinc=$VISITDIR/${VTK_INSTALL_DIR}/$VTK_VERSION/$VISITARCH/include/vtk-${VTK_SHORT_VERSION}/vtklibxml2/include
    if test -e $VISITDIR/${VTK_INSTALL_DIR}/$VTK_VERSION/$VISITARCH/lib64 ; then
        xml64="64"
    fi
    if test -e $VISITDIR/${VTK_INSTALL_DIR}/$VTK_VERSION/$VISITARCH/lib${xml64}/libvtklibxml2.${VTK_SHORT_VERSION}.${SO_EXT}; then
        xmlsep="."
    fi
    xmllib=$VISITDIR/${VTK_INSTALL_DIR}/$VTK_VERSION/$VISITARCH/lib${xml64}/libvtklibxml2${xmlsep}${VTK_SHORT_VERSION}.${SO_EXT}

    set -x
    ${CMAKE_BIN} -DCMAKE_INSTALL_PREFIX:PATH="$VISITDIR/Xdmf/${XDMF_VERSION}/${VISITARCH}"\
                 -DCMAKE_BUILD_TYPE:STRING="${VISIT_BUILD_MODE}" \
                 -DCMAKE_BUILD_WITH_INSTALL_RPATH:BOOL=ON \
                 -DBUILD_SHARED_LIBS:BOOL=${XDMF_SHARED_LIBS}\
                 -DCMAKE_CXX_FLAGS:STRING="${CXXFLAGS} ${CXX_OPT_FLAGS}"\
                 -DCMAKE_CXX_COMPILER:STRING=${CXX_COMPILER}\
                 -DCMAKE_C_FLAGS:STRING="${CFLAGS} ${C_OPT_FLAGS}"\
                 -DCMAKE_C_COMPILER:STRING=${C_COMPILER}\
                 -DBUILD_TESTING:BOOL=OFF \
                 -DXDMF_BUILD_MPI:BOOL=OFF \
                 -DXDMF_BUILD_VTK:BOOL=OFF \
                 -DXDMF_BUILD_UTILS:BOOL=OFF \
                 -DXDMF_SYSTEM_HDF5:BOOL=ON \
                 -DHDF5_INCLUDE_PATH:PATH="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/include" \
                 -DHDF5_LIBRARY:FILEPATH="$VISITDIR/hdf5/$HDF5_VERSION/$VISITARCH/lib/libhdf5.${SO_EXT}" \
                 -DXDMF_SYSTEM_ZLIB:BOOL=ON \
                 -DZLIB_INCLUDE_DIR:PATH=${ZLIB_INCLUDE_DIR} \
                 -DZLIB_LIBRARY:FILEPATH=${ZLIB_LIBRARY} \
                 -DXDMF_SYSTEM_LIBXML2:BOOL=ON \
                 -DLIBXML2_INCLUDE_PATH:PATH="${xmlinc}" \
                 -DLIBXML2_LIBRARY:FILEPATH="${xmllib}" \
                 .
    set +x

    if [[ $? != 0 ]] ; then
        warn "Xdmf configure failed.  Giving up"
        return 1
    fi

    #
    # Build Xdmf
    #
    info "Building Xdmf . . . (~3 minutes)"

    ${CMAKE_COMMAND} --build . $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "Xdmf build failed.  Giving up"
        return 1
    fi

    # Install Xdmf
    info "Installing Xdmf"
    ${CMAKE_COMMAND} --install .
    if [[ $? != 0 ]] ; then
        warn "Xdmf install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_STATIC_BUILD" != "yes" && "$OPSYS" == "Darwin" ]]; then
        LIBDIR="$VISITDIR/Xdmf/${XDMF_VERSION}/${VISITARCH}/lib"
        install_name_tool -id $LIBDIR/libXdmf.dylib $LIBDIR/libXdmf.dylib
    fi


    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/Xdmf"
        chgrp -R ${GROUP} "$VISITDIR/Xdmf"
    fi

    cd "$START_DIR"
    info "Done with Xdmf"
    return 0
}

function bv_xdmf_is_enabled
{
    if [[ $DO_XDMF == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_xdmf_is_installed
{
    check_if_installed "Xdmf" $XDMF_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_xdmf_build
{
    cd "$START_DIR"
    if [[ "$DO_XDMF" == "yes" ]] ; then
        check_if_installed "Xdmf" $XDMF_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping Xdmf build.  Xdmf is already installed."
        else
            info "Building Xdmf (~2 minutes)"
            build_xdmf
            if [[ $? != 0 ]] ; then
                error "Unable to build or install Xdmf.  Bailing out."
            fi
            info "Done building Xdmf"
        fi
    fi
}
function bv_xkbcommon_initialize
{
    export DO_XKBCOMMON="no"
}

function bv_xkbcommon_enable
{
    DO_XKBCOMMON="yes"
}

function bv_xkbcommon_disable
{
    DO_XKBCOMMON="no"
}

function bv_xkbcommon_depends_on
{
    local depends_on="meson"

    echo ${depends_on}
}

function bv_xkbcommon_initialize_vars
{
    XKBCOMMON_INSTALL_DIR="${VISITDIR}/xkbcommon/$XKBCOMMON_VERSION/${VISITARCH}"
}

function bv_xkbcommon_info
{
    export XKBCOMMON_VERSION=${XKBCOMMON_VERSION:-"1.7.0"}
    export XKBCOMMON_FILE=${XKBCOMMON_FILE:-"libxkbcommon-${XKBCOMMON_VERSION}.tar.xz"}
    export XKBCOMMON_BUILD_DIR=${XKBCOMMON_BUILD_DIR:-"libxkbcommon-${XKBCOMMON_VERSION}"}
    export XKBCOMMON_SHA256_CHECKSUM="65782f0a10a4b455af9c6baab7040e2f537520caa2ec2092805cdfd36863b247"
}

function bv_xkbcommon_print
{
    printf "%s%s\n" "XKBCOMMON_FILE=" "${XKBCOMMON_FILE}"
    printf "%s%s\n" "XKBCOMMON_VERSION=" "${XKBCOMMON_VERSION}"
    printf "%s%s\n" "XKBCOMMON_BUILD_DIR=" "${XKBCOMMON_BUILD_DIR}"
}

function bv_xkbcommon_print_usage
{
    printf "%-20s %s [%s]\n" "--xkbcommon" "Build xkbcommon support" "$DO_XKBCOMMON"
}

function bv_xkbcommon_host_profile
{
    if [[ "$DO_XKBCOMMON" == "yes" ]] ; then
        echo >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "## Xkbcommon" >> $HOSTCONF
        echo "##" >> $HOSTCONF
        echo "VISIT_OPTION_DEFAULT(VISIT_XKBCOMMON_DIR \${VISITHOME}/xkbcommon/$XKBCOMMON_VERSION/\${VISITARCH})" \
            >> $HOSTCONF
    fi
}

function bv_xkbcommon_ensure
{
    if [[ "$DO_XKBCOMMON" == "yes" ]] ; then
        ensure_built_or_ready "xkbcommon" $XKBCOMMON_VERSION $XKBCOMMON_BUILD_DIR $XKBCOMMON_FILE $XKBCOMMON_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            DO_XKBCOMMON="no"
            error "Unable to build xkbcommon. ${XKBCOMMON_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_xkbcommon
#
#
# *************************************************************************** #
function build_xkbcommon
{
    #
    # Prepare build dir
    #
    prepare_build_dir $XKBCOMMON_BUILD_DIR $XKBCOMMON_FILE
    untarred_xkbcommon=$?
    # 0, already exists, 1 untarred src, 2 error

    if [[ $untarred_xkbcommon == -1 ]] ; then
        warn "Unable to prepare xkbcommon build directory. Giving Up!"
        return 1
    fi

    #
    # Configure XKBCOMMON
    #
    info "Configuring xkbcommon . . ."

    cd $XKBCOMMON_BUILD_DIR || error "Can't cd to xkbcommon build dir."

    export PATH=$MESON_INSTALL_DIR/bin:$NINJA_INSTALL_DIR/bin:$PATH

    meson setup build --prefix $XKBCOMMON_INSTALL_DIR -Denable-wayland=false || error "Xkbcommon did not configure correctly. Giving up."

    #
    # Build xkbcommon
    #
    info "Building xkbcommon . . . (~1 minutes)"
    meson compile -C build || error "Xkbcommon did not build correctly. Giving up."

    info "Installing xkbcommon . . . (~1 minutes)"
    # Manually installing xkbcommon since "meson install -C build" gave
    # an error with an unhandled python OSError.

    # The libraries
    if [[ ! -d ${XKBCOMMON_INSTALL_DIR}/lib64 ]] ; then
        mkdir -p ${XKBCOMMON_INSTALL_DIR}/lib64
	ln -s lib64 ${XKBCOMMON_INSTALL_DIR}/lib
    fi
    cp build/libxkbcommon.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib
    ln -s libxkbcommon.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib/libxkbcommon.so
    ln -s libxkbcommon.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib/libxkbcommon.so.0
    cp build/libxkbcommon-x11.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib
    ln -s libxkbcommon-x11.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib/libxkbcommon-x11.so
    ln -s libxkbcommon-x11.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib/libxkbcommon-x11.so.0
    cp build/libxkbregistry.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib
    ln -s libxkbregistry.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib/libxkbregistry.so
    ln -s libxkbregistry.so.0.0.0 ${XKBCOMMON_INSTALL_DIR}/lib/libxkbregistry.so.0

    # The header files
    if [[ ! -d ${XKBCOMMON_INSTALL_DIR}/include/xkbcommon ]] ; then
        mkdir -p ${XKBCOMMON_INSTALL_DIR}/include/xkbcommon
    fi
    cp include/xkbcommon/* ${XKBCOMMON_INSTALL_DIR}/include/xkbcommon

    # The pkg-config files
    if [[ ! -d ${XKBCOMMON_INSTALL_DIR}/lib/pkgconfig ]] ; then
        mkdir -p ${XKBCOMMON_INSTALL_DIR}/lib/pkgconfig
    fi
    cp build/meson-private/xkbcommon.pc ${XKBCOMMON_INSTALL_DIR}/lib/pkgconfig
    cp build/meson-private/xkbcommon-x11.pc ${XKBCOMMON_INSTALL_DIR}/lib/pkgconfig
    cp build/meson-private/xkbregistry.pc ${XKBCOMMON_INSTALL_DIR}/lib/pkgconfig

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/xkbcommon"
        chgrp -R ${GROUP} "$VISITDIR/xkbcommon"
    fi
    cd "$START_DIR"
    info "Done with xkbcommon"
    return 0
}

function bv_xkbcommon_is_enabled
{
    if [[ $DO_XKBCOMMON == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_xkbcommon_is_installed
{
    check_if_installed "xkbcommon" $XKBCOMMON_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_xkbcommon_build
{
    cd "$START_DIR"
    if [[ "$DO_XKBCOMMON" == "yes" ]] ; then
        check_if_installed "xkbcommon" $XKBCOMMON_VERSION
        if [[ $? == 0 ]] ; then
            info "Skipping xkbcommon build. Xkbcommon is already installed."
        else
            info "Building xkbcommon (~2 minutes)"
            build_xkbcommon
            if [[ $? != 0 ]] ; then
                error "Unable to build or install xkbcommon.  Bailing out."
            fi
            info "Done building xkbcommon"
        fi
    fi
}
function bv_zlib_initialize
{
    export DO_ZLIB="yes"
}

function bv_zlib_enable
{
    DO_ZLIB="yes"
}

function bv_zlib_disable
{
    DO_ZLIB="no"
}

function bv_zlib_depends_on
{
    local depends_on=""

    echo $depends_on
}

function bv_zlib_info
{
    export ZLIB_VERSION=${ZLIB_VERSION:-"1.3.1"}
    export ZLIB_FILE=${ZLIB_FILE:-"zlib-${ZLIB_VERSION}.tar.xz"}
    export ZLIB_COMPATIBILITY_VERSION=${ZLIB_COMPATIBILITY_VERSION:-"1.3"}
    export ZLIB_BUILD_DIR=${ZLIB_BUILD_DIR:-"zlib-${ZLIB_VERSION}"}
    export ZLIB_SHA256_CHECKSUM="38ef96b8dfe510d42707d9c781877914792541133e1870841463bfa73f883e32"
}

function bv_zlib_print
{
    printf "%s%s\n" "ZLIB_FILE=" "${ZLIB_FILE}"
    printf "%s%s\n" "ZLIB_VERSION=" "${ZLIB_VERSION}"
    printf "%s%s\n" "ZLIB_COMPATIBILITY_VERSION=" "${ZLIB_COMPATIBILITY_VERSION}"
    printf "%s%s\n" "ZLIB_BUILD_DIR=" "${ZLIB_BUILD_DIR}"
}

function bv_zlib_print_usage
{
    printf "%-20s %s [%s]\n" "--zlib" "Build ZLIB support" "$DO_ZLIB"
}

function bv_zlib_host_profile
{
    echo >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "## ZLIB" >> $HOSTCONF
    echo "##" >> $HOSTCONF
    echo "SETUP_APP_VERSION(ZLIB $ZLIB_VERSION)" >> $HOSTCONF
    echo \
        "VISIT_OPTION_DEFAULT(VISIT_ZLIB_DIR \${VISITHOME}/zlib/\${ZLIB_VERSION}/\${VISITARCH})" \
        >> $HOSTCONF
}

function bv_zlib_initialize_vars
{
    export VISIT_ZLIB_DIR=${VISIT_ZLIB_DIR:-"$VISITDIR/zlib/${ZLIB_VERSION}/${VISITARCH}"}
    export ZLIB_LIBRARY_DIR="${VISIT_ZLIB_DIR}/lib"
    export ZLIB_INCLUDE_DIR="${VISIT_ZLIB_DIR}/include"
    export ZLIB_LIBRARY="${ZLIB_LIBRARY_DIR}/libz.${SO_EXT}"
}

function bv_zlib_ensure
{
    if [[ $DO_ZLIB == "yes" ]]; then
        ensure_built_or_ready "zlib" $ZLIB_VERSION $ZLIB_BUILD_DIR $ZLIB_FILE $ZLIB_URL
        if [[ $? != 0 ]] ; then
            ANY_ERRORS="yes"
            error "Unable to build ZLIB.  ${ZLIB_FILE} not found."
        fi
    fi
}

# *************************************************************************** #
#                            Function 8, build_zlib
#
# Modfications:
#
# *************************************************************************** #

function build_zlib
{
    #
    # Prepare build dir
    #
    prepare_build_dir $ZLIB_BUILD_DIR $ZLIB_FILE
    untarred_zlib=$?
    if [[ $untarred_zlib == -1 ]] ; then
        warn "Unable to prepare ZLIB build directory. Giving Up!"
        return 1
    fi

    #
    # Call configure
    #
    info "Configuring ZLIB . . ."
    cd $ZLIB_BUILD_DIR || error "Can't cd to ZLIB build dir."
    info "Invoking command to configure ZLIB"

    STATICARGS="--static"
    if [[ "$DO_STATIC_BUILD" == "no" ]] ; then
        STATICARGS=""
    fi

    # Call configure
    set -x
    env CXX=$CXX_COMPILER CC=$C_COMPILER \
        CFLAGS="$CFLAGS $C_OPT_FLAGS" \
        CXXFLAGS="$CXXFLAGS $CXX_OPT_FLAGS" \
        ./configure \
        --prefix=$VISITDIR/zlib/$ZLIB_VERSION/$VISITARCH $STATIC_ARGS
    set +x

    if [[ $? != 0 ]] ; then
        warn "ZLIB configure failed.  Giving up"
        return 1
    fi

    #
    # Build ZLIB
    #
    info "Building ZLIB . . . (~1 minute)"
    $MAKE $MAKE_OPT_FLAGS
    if [[ $? != 0 ]] ; then
        warn "ZLIB build failed.  Giving up"
        return 1
    fi
    #
    # Install into the VisIt third party location.
    #
    info "Installing ZLIB"
    $MAKE install
    if [[ $? != 0 ]] ; then
        warn "ZLIB install failed.  Giving up"
        return 1
    fi

    if [[ "$DO_GROUP" == "yes" ]] ; then
        chmod -R ug+w,a+rX "$VISITDIR/zlib"
        chgrp -R ${GROUP} "$VISITDIR/zlib"
    fi
    cd "$START_DIR"
    info "Done with ZLIB"
    return 0
}

function bv_zlib_is_enabled
{
    if [[ $DO_ZLIB == "yes" ]]; then
        return 1
    fi
    return 0
}

function bv_zlib_is_installed
{
    check_if_installed "zlib" $ZLIB_VERSION
    if [[ $? == 0 ]] ; then
        return 1
    fi
    return 0
}

function bv_zlib_build
{
    cd "$START_DIR"
    check_if_installed "zlib" $ZLIB_VERSION
    if [[ $? == 0 ]] ; then
        info "Skipping ZLIB build.  ZLIB is already installed."
    else
        info "Building ZLIB (~1 minute)"
        build_zlib
        if [[ $? != 0 ]] ; then
            error "Unable to build or install ZLIB.  Bailing out."
        fi
        info "Done building ZLIB"
    fi
}
xmlp_filecontents[0]="<modules>"
xmlp_filecontents[1]="<license name=\"bsd|mit|lgpl\">"
xmlp_filecontents[2]="<group name=\"required\" comment=\"All required libraries, built by default. Entire group can be disabled by '--no-thirdparty'. Individual libraries in the group can be disabled via --no-name flag, e.g. --no-python.\" enabled=\"yes\">"
xmlp_filecontents[3]="<lib name=\"cmake\"/>"
xmlp_filecontents[4]="<lib name=\"zlib\"/>"
xmlp_filecontents[5]="<lib name=\"python\"/>"
xmlp_filecontents[6]="<lib name=\"qt\"/>"
xmlp_filecontents[7]="<lib name=\"vtk\"/>"
xmlp_filecontents[8]="<lib name=\"osmesa\"/>"
xmlp_filecontents[9]="<lib name=\"llvm\"/>"
xmlp_filecontents[10]="</group>"
xmlp_filecontents[11]="<group name=\"optional\" comment=\"Optional libraries, the entire group is disabled by default, and can be enabled via --optional flag or. Individual libraries can be enabled via --name, e.g. --conduit.\" enabled=\"no\">"
xmlp_filecontents[12]="<lib name=\"adios\"/>"
xmlp_filecontents[13]="<lib name=\"adios2\"/>"
xmlp_filecontents[14]="<lib name=\"advio\"/>"
xmlp_filecontents[15]="<lib name=\"blosc2\"/>"
xmlp_filecontents[16]="<lib name=\"boost\"/>"
xmlp_filecontents[17]="<lib name=\"boxlib\"/>"
xmlp_filecontents[18]="<lib name=\"cfitsio\"/>"
xmlp_filecontents[19]="<lib name=\"cgns\"/>"
xmlp_filecontents[20]="<lib name=\"conduit\"/>"
xmlp_filecontents[21]="<lib name=\"fms\"/>"
xmlp_filecontents[22]="<lib name=\"gdal\"/>"
xmlp_filecontents[23]="<lib name=\"h5part\"/>"
xmlp_filecontents[24]="<lib name=\"hdf5\"/>"
xmlp_filecontents[25]="<lib name=\"icet\"/>"
xmlp_filecontents[26]="<lib name=\"mfem\"/>"
xmlp_filecontents[27]="<lib name=\"mili\"/>"
xmlp_filecontents[28]="<lib name=\"moab\"/>"
xmlp_filecontents[29]="<lib name=\"netcdf\"/>"
xmlp_filecontents[30]="<lib name=\"openexr\"/>"
xmlp_filecontents[31]="<lib name=\"ospray\"/>"
xmlp_filecontents[32]="<lib name=\"pidx\"/>"
xmlp_filecontents[33]="<lib name=\"qwt\"/>"
xmlp_filecontents[34]="<lib name=\"silo\"/>"
xmlp_filecontents[35]="<lib name=\"szip\"/>"
xmlp_filecontents[36]="<lib name=\"uintah\"/>"
xmlp_filecontents[37]="<lib name=\"vtkm\"/>"
xmlp_filecontents[38]="<lib name=\"xdmf\"/>"
xmlp_filecontents[39]="</group>"
xmlp_filecontents[40]="<group name=\"explicit\" comment=\"Libraries that can only be enabled individually, the group cannot be enabled as a whole. This list can include mutually exclusive libraries like 'mesgal' and 'osmesa', or libraries only needed on specific platforms, or libraries with problematic builds.\" enabled=\"no\">"
xmlp_filecontents[41]="<lib name=\"anari\"/>"
xmlp_filecontents[42]="<lib name=\"glu\"/>"
xmlp_filecontents[43]="<lib name=\"mesagl\"/>"
xmlp_filecontents[44]="<lib name=\"meson\"/>"
xmlp_filecontents[45]="<lib name=\"mpich\"/>"
xmlp_filecontents[46]="<lib name=\"nektarpp\"/>"
xmlp_filecontents[47]="<lib name=\"ninja\"/>"
xmlp_filecontents[48]="<lib name=\"xcb\"/>"
xmlp_filecontents[49]="<lib name=\"xkbcommon\"/>"
xmlp_filecontents[50]="</group>"
xmlp_filecontents[51]="</license>"
xmlp_filecontents[52]="</modules>"
xmlp_licenses[0]="bsd|mit|lgpl"
xmlp_licenses_range[0]="1 51"
defaultLicenses=$(xmlp_get_license "$@")
for license in `echo $defaultLicenses`
do
  info "Processing $license license."
  parseXmlModuleContents $license
  reqlibs=(`echo "${reqlibs[@]} ${xmlp_reqlibs[@]}" | xargs -n 1 | sort -u | xargs`)
  optlibs=(`echo "${optlibs[@]} ${xmlp_optlibs[@]}" | xargs -n 1 | sort -u | xargs`)
  explicitlibs=(`echo "${explicitlibs[@]} ${xmlp_explicitlibs[@]}" | xargs -n 1 | sort -u | xargs`)
for (( bv_i = 0; bv_i < ${#xmlp_grouplibs_name[*]}; ++bv_i ))
do
  match=0
  for (( bv_j = 0; bv_j < ${#grouplibs_name[*]}; ++bv_j ))
  do
    if [[ "${grouplibs_name[$bv_j]}" == "${xmlp_grouplibs_name[$bv_i]}" ]]; then
      match=1
      grouplibs_deps[$bv_j]=`echo "${grouplibs_deps[$bv_j]} ${xmlp_grouplibs_deps[$bv_i]}" | xargs -n 1 | sort -u | xargs`
      break
    fi
  done
  if [[ match -eq 0 ]]; then
    grouplibs_name[${#grouplibs_name[*]}]="${xmlp_grouplibs_name[$bv_i]}"
    grouplibs_deps[${#grouplibs_deps[*]}]="${xmlp_grouplibs_deps[$bv_i]}"
    grouplibs_comment[${#grouplibs_comment[*]}]="${xmlp_grouplibs_comment[$bv_i]}"
    grouplibs_enabled[${#grouplibs_enabled[*]}]="${xmlp_grouplibs_enabled[$bv_i]}"
  fi
  done
done
check_default_args () 
{ 
    if [[ $(quick_check_for_help $@) -eq 0 ]]; then
        usage;
        exit 2;
    fi;
    for arg in "$@";
    do
        if [[ "$arg" == "--write-unified-file" ]]; then
            next_arg="write-unified-file";
        else
            if [[ "$next_arg" == "write-unified-file" ]]; then
                bv_write_unified_file "$arg";
                exit 0;
            fi;
        fi;
    done
}
function bv_write_unified_file
{
  echo "Writing to File: $@"
  cat $0 > $@
  cat $0 > $@
  chmod 755 $@
}
check_for_versioning "$@"
if [[ "$build_version" != "" ]]; then
    call_build_visit
fi
check_default_args "$@"
initialize_build_visit "$@"
run_build_visit "$@"